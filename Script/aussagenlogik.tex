\chapter{Aussagenlogik}
\section{\"{U}berblick}
Die Aussagenlogik besch\"{a}ftigt sich mit der Verkn\"{u}pfung einfacher Aussagen durch
\emph{Junktoren}.  Dabei sind Junktoren Worte wie ``\textsl{und}'', ``\textsl{oder}'',
``\textsl{nicht}'', ``\textsl{wenn $\cdots$, dann}'', und ``\textsl{genau dann, wenn}''.
Einfache Aussagen sind dabei S\"{a}tze, die 
\begin{itemize}
\item einen Tatbestand ausdr\"{u}cken, der entweder wahr oder falsch ist und 
\item selber keine Junktoren enthalten.
\end{itemize}
Beispiele f\"{u}r einfache Aussagen sind
\begin{enumerate}
\item ``\textsl{Die Sonne scheint.}''
\item ``\textsl{Es regnet.}''
\item ``\textsl{Am Himmel ist ein Regenbogen.}''
\end{enumerate}
Einfache Aussagen dieser Art bezeichnen wir auch als \emph{atomare} Aussagen, weil sie sich nicht weiter in Teilaussagen
zerlegen lassen.  Atomare Aussagen lassen sich mit Hilfe der eben angegebenen Junktoren zu 
\emph{zusammengesetzten Aussagen} verkn\"{u}pfen.  
Ein Beispiel f\"{u}r eine zusammengesetzte Aussage w\"{a}re \\[0.2cm]
\hspace*{1.3cm} \textsl{Wenn die Sonne scheint und es regnet, dann ist ein Regenbogen am Himmel.} 
\hspace*{\fill} (1)
\\[0.2cm]
Die Aussage ist aus den drei atomaren Aussagen ``\textsl{Die Sonne scheint.}'', ``\textsl{Es regnet.}'', und
 ``\textsl{Am Himmel ist ein Regenbogen.}'' mit Hilfe der Junktoren ``\textsl{und}'' und ``\textsl{wenn $\cdots$, dann}''
aufgebaut worden.
Die Aussagenlogik untersucht, wie sich der Wahrheitswert zusammengesetzter Aussagen
aus dem Wahrheitswert der einzelnen Teilaussagen berechnen l\"{a}sst.  Darauf
aufbauend wird dann gefragt, in welcher Art und Weise wir aus gegebenen Aussagen neue 
Aussagen logisch folgern k\"{o}nnen.

Um die Struktur komplexerer Aussagen \"{u}bersichtlich werden zu lassen, f\"{u}hren wir in der Aussagenlogik zun\"{a}chst sogenannte
\emph{Aussage-Variablen} ein.  Diese stehen f\"{u}r atomare Aussagen.
Zus\"{a}tzlich f\"{u}hren wir f\"{u}r die Junktoren
``\textsl{nicht}'', ``\textsl{und}'', ``\textsl{oder}'', ``\textsl{wenn, $\cdots$ dann}'', und ``\textsl{genau dann, wenn}'' die
folgenden Abk\"{u}rzungen ein:
\begin{enumerate}
\item $\neg a$ \quad\quad\ f\"{u}r \quad \textsl{nicht} $a$ 
\item $a \wedge b$ \,\quad\ f\"{u}r \quad $a$ \textsl{und} $b$
\item $a \vee b$ \,\quad\ f\"{u}r \quad $a$ \textsl{oder} $b$
\item $a \rightarrow b$   \quad f\"{u}r \quad \textsl{wenn} $a$, \textsl{dann} $b$
\item $a \leftrightarrow b$ \quad f\"{u}r \quad  $a$ \textsl{genau dann, wenn} $b$
\end{enumerate}
Aussagenlogische Formeln werden aus Aussage-Variablen mit Hilfe von Junktoren aufgebaut
und k\"{o}nnen beliebig komplex sein.  Die Aussage (1) k\"{o}nnen wir mit Hilfe der Junktoren  k\"{u}rzer als
 \\[0.2cm]
\hspace*{1.3cm} $\mathtt{SonneScheint} \wedge \mathtt{EsRegnet} \rightarrow \mathtt{Regenbogen}$ \\[0.2cm]
schreiben.   Das \emph{Beweis-Prinzip}, das wir oben
verwendet haben, ist dabei wie folgt: Aus den Aussagen
\begin{enumerate}
\item \texttt{SonneScheint}
\item \texttt{EsRegnet}
\item $\mathtt{SonneScheint} \wedge \mathtt{EsRegnet} \rightarrow \mathtt{Regenbogen}$
\end{enumerate}
\emph{folgt logisch} die Aussage \\[0.2cm]
\hspace*{1.3cm}  \texttt{Regenbogen}. \\[0.2cm]
 Um Beweis-Prinzipien \"{u}bersichtlicher angeben zu k\"{o}nnen,
f\"{u}hren wir die folgende Notation ein: 
$$ \schluss{\mathtt{SonneScheint} \quad\quad \mathtt{EsRegnet} \quad\quad \mathtt{SonneScheint} \wedge \mathtt{EsRegnet} \rightarrow
       \mathtt{Regenbogen}}{\mathtt{Regenbogen}} 
$$
Die Aussagen \"{u}ber dem Bruchstrich bezeichnen wir als \emph{Pr\"{a}missen}, die Aussage unter dem Bruchstrich ist die \emph{Konklusion}.
Statt Beweis-Prinzip sagen wir oft auch \emph{Schluss-Regel}.

 Wir stellen fest, dass die obige Schluss-Regel unabh\"{a}ngig von dem Wahrheitswert der Aussagen in dem folgenden Sinne
g\"{u}ltig ist: Wenn alle Pr\"{a}missen g\"{u}ltig sind, dann folgt aus logischen Gr\"{u}nden auch die G\"{u}ltigkeit der Konklusion.
 Um dieses weiter formalisieren zu k\"{o}nnen, ersetzen wir die Aussage-Variablen
 \texttt{SonneScheint}, \texttt{EsRegnet} und \texttt{Regenbogen} durch die
 \emph{Meta-Variablen} $p$, $q$ und $r$, die f\"{u}r beliebige aussagenlogische Formeln stehen.
  Die obige Schluss-Regel ist dann eine Instanz der folgenden allgemeinen Schluss-Regel:
$$ \schluss{p \quad q \quad p \wedge q \rightarrow r}{r}  $$

\exercise
Formalisieren Sie die Schluss-Regel, die in dem folgenden Argument verwendet wird.
\begin{center}
\begin{minipage}[c]{7.9cm}
\textsl{Wenn es regnet, ist die Stra\3e nass.  Es regnet nicht.  Also ist die Stra\3e nicht nass. \eox} 
\end{minipage}  
\end{center}

\solution
Es wird die folgende Schluss-Regel verwendet: \\[0.2cm]
\hspace*{1.3cm} $\schluss{p \rightarrow q \quad\quad \neg p}{\neg q}$\\[0.2cm]
Diese Schluss-Regel ist nicht korrekt.  Wenn Sie das nicht einsehen, sollten Sie bei strahlendem Sonnenschein einen Eimer Wasser
auf die Stra\3e kippen.  \qed
\vspace*{0.1cm}

Dadurch, dass wir ausgehend von Beobachtungen und als wahr erkannten Tatsachen und Zusammenh\"{a}ngen
mehrere \emph{logische Schl\"{u}sse} aneinander f\"{u}gen, erhalten wir einen \emph{Beweis}. 
Die als wahr erkannten Tatsachen und Beobachtungen bezeichnet wir dabei als \emph{Axiome}.
Wir verwenden in diesem Zusammenhang die folgende  Notation: \\[0.2cm]
\hspace*{1.3cm} $M \vdash r$. \\[0.2cm]
Hierbei gilt:
\begin{itemize}
\item $M$ ist eine Menge von Aussagen.
\item $\vdash$ bezeichnet ein System von Schluss-Regeln.  Eine solches System bezeichnen wir auch als \emph{Kalk\"{u}l}.
\item $r$ ist eine Aussage.  
\end{itemize}
Die Schreibweise $M \vdash r$ w\"{a}re dann als \\[0.2cm]
\hspace*{1.3cm} ``\emph{Aus den Axiomen der Menge $M$ kann die Aussage $r$ hergeleitet werden}'' \\[0.2cm]
zu interpretieren.  Wir lesen  $M \vdash r$ als ``\emph{$M$ leitet $r$ her}''.
Damit ist gemeint, dass wir ausgehend von den Axiomen in $M$ durch sukzessives
Anwenden verschiedener Schluss-Regeln die Aussage $r$ beweisen k\"{o}nnen.
Das Zeichen $\vdash$ steht f\"{u}r die Menge aller Schluss-Regeln und symbolisiert damit den
\emph{Herleitungs-Begriff}, den wir auch als \emph{Kalk\"{u}l} bezeichnen.  Wir werden  in einem
sp\"{a}teren Abschnitt den Kalk\"{u}l formal definieren.
Parallel zu dem Herleitungsbegriff, der seiner Natur nach syntaktisch ist, gibt es auch
einen \emph{semantischen}, also inhaltlichen \emph{Folgerungs-Begriff}.  Wir schreiben \\[0.2cm]
\hspace*{1.3cm} $M \models r$, \\[0.2cm]
wenn die Aussage $r$ logisch aus den Aussagen $M$ folgt.  
Die Notation $M \models r$ wird gelesen als ``\emph{$r$ folgt aus $M$}''.
Das k\"{o}nnen wir anders auch so
formulieren:  Immer wenn alle Aussagen aus $M$ wahr sind, dann ist auch die Aussage $r$ wahr.
Wir k\"{o}nnen den Begriff der \emph{logischen Folgerung} aber
erst dann pr\"{a}zise definieren, wenn wir die Semantik der Junktoren mathematisch festgelegt haben.

Ziel der Aussagenlogik ist es, einen
Herleitungsbegriff zu finden, der die folgenden beiden Bedingungen erf\"{u}llt:
\begin{enumerate}
\item Der Herleitungsbegriff sollte {\bf korrekt} sein, es sollte also nicht m\"{o}glich sein,
      Unsinn zu beweisen.  Es sollte also gelten \\[0.2cm]
      \hspace*{1.3cm} Aus $M \vdash r$ folgt $M \models r$. 
      \\[0.2cm]
      Wenn wir die Aussage $r$ aus den Axiomen der Menge $M$ herleiten k\"{o}nnen, dann 
      soll $r$ auch aus $M$ folgen.
\item Der Herleitungsbegriff sollte {\bf vollst\"{a}ndig} sein, d.h.~wenn eine Aussage $r$
      aus einer Menge von anderen Aussagen $M$ logisch folgt, dann sollte sie
      auch aus $M$ beweisbar sein: \\[0.2cm]
      \hspace*{1.3cm} Aus $M \models r$ folgt $M \vdash r$. 
      \\[0.2cm]
      Wenn die Aussage $r$ aus $M$ folgt, dann soll $r$ auch aus der Menge $M$
      hergeleitet werden k\"{o}nnen.
\end{enumerate}

Bestimmte aussagenlogische Formeln sind offenbar immer wahr, egal was
 wir f\"{u}r die einzelnen Teilaussagen einsetzen.  Beispielsweise ist eine Formel der Art
\\[0.2cm]
\hspace*{1.3cm}
$p \vee \neg p$
\\[0.2cm]
unabh\"{a}ngig von dem Wahrheitswert der Aussage $p$ immer wahr.  Eine aussagenlogische
Formel, die immer wahr ist, bezeichnen wir als eine \emph{Tautologie}.  Andere
aussagenlogische Formeln sind nie wahr, beispielsweise ist die Formel
\\[0.2cm]
\hspace*{1.3cm}
$p \wedge \neg p$
\\[0.2cm]
immer falsch.  Eine Formel hei\3t \emph{erf\"{u}llbar}, wenn es wenigstens eine M\"{o}glichkeit
gibt, bei der die Formel wahr wird.  Im Rahmen der Vorlesung werden wir verschiedene Verfahren
entwickeln, mit denen es m\"{o}glich ist zu entscheiden, ob eine aussagenlogische Formel eine
Tautologie ist oder ob Sie wenigstens erf\"{u}llbar ist.  Solche Verfahren spielen
in der Praxis eine wichtige Rolle.

\section{Anwendungen der Aussagenlogik}
Die Aussagenlogik bildet nicht nur die Grundlage f\"{u}r die Pr\"{a}dikatenlogik, sondern sie hat auch wichtige praktische
Anwendungen.  Aus der gro\3en Zahl der industriellen Anwendungen m\"{o}chte ich stellvertretend vier Beispiele nennen:
\begin{enumerate}
\item Analyse und Design digitaler Schaltungen.

      Komplexe digitale Schaltungen bestehen heute aus bis zu einer Milliarden logischen
      Gattern.\footnote{Die Seite 
      \href{https://en.wikipedia.org/wiki/Transistor_count}{\texttt{https://en.wikipedia.org/wiki/Transistor\_count}}
      gibt einen \"{U}berblick \"{u}ber die Komplexit\"{a}t moderner Prozessoren.}
      Ein Gatter ist dabei, aus logischer Sicht betrachtet, ein Baustein, der einen
      der logischen Junktoren wie ``\textsl{und}'', ``\textsl{oder}'', ``\textsl{nicht}'',
      etc.~auf elektronischer Ebene repr\"{a}sentiert. 
  
      Die Komplexit\"{a}t solcher Schaltungen w\"{a}re ohne den Einsatz
      rechnergest\"{u}tzter Verfahren zur Verifikation nicht mehr beherrschbar.  Die
      dabei eingesetzten Verfahren sind Anwendungen der Aussagenlogik. 

      Eine ganz konkrete Anwendung ist der Schaltungs-Vergleich.  Hier werden zwei
      digitale Schaltungen als aussagenlogische Formeln dargestellt.
      Anschlie\3end wird versucht, mit aussagenlogischen Mitteln die \"{A}quivalenz dieser
      Formeln zu zeigen. Software-Werkzeuge, die f\"{u}r die Verifikation digitaler
      Schaltungen eingesetzt werden, kosten heutzutage \"{u}ber $100\,000\,\symbol{36}$\footnote{
        Die Firma Magma bietet beispielsweise den \emph{Equivalence-Checker}
        \textsl{Quartz Formal} zum Preis von $150\,000\, \symbol{36}$ pro Lizenz an.
      Eine solche Lizenz ist dann drei Jahre lang g\"{u}ltig.}.
      Dies zeigt die wirtschaftliche Bedeutung der Aussagenlogik.

\item Erstellung von Einsatzpl\"{a}nen (\emph{crew sheduling}).

      International t\"{a}tige Fluggesellschaften m\"{u}ssen bei der Einteilung ihrer Crews
      einerseits gesetzlich vorgesehene Ruhezeiten einhalten, wollen aber ihr Personal
      m\"{o}glichst effizient einsetzen.  Das f\"{u}hrt zu Problemen, die sich mit Hilfe
      aussagenlogischer Formeln beschreiben und l\"{o}sen lassen.
\item Erstellung von Verschlusspl\"{a}nen f\"{u}r die Weichen und Signale von Bahnh\"{o}fen.

      Bei einem gr\"{o}\3eren Bahnhof gibt es einige hundert Weichen und Signale, die st\"{a}ndig
      neu eingestellt werden m\"{u}ssen, um sogenannte \emph{Fahrstra\3en} f\"{u}r die Z\"{u}ge zu
      realisieren.  Verschiedene Fahrstra\3en d\"{u}rfen sich aus Sicherheitsgr\"{u}nden nicht kreuzen.  
      Die einzelnen Fahrstra\3en werden durch sogenannte \emph{Verschlusspl\"{a}ne} beschrieben.
      Die Korrektheit solcher Verschlusspl\"{a}ne kann durch aussagenlogische Formeln ausgedr\"{u}ckt werden.
\item Eine Reihe kombinatorischer Puzzles lassen sich als aussagenlogische Formeln
      kodieren und k\"{o}nnen dann mit Hilfe aussagenlogischer Methoden l\"{o}sen.  Als ein
      Beispiel werden wir in der Vorlesung das 8-Damen-Problem behandeln.  Dabei geht es um die Frage,
      ob 8 Damen so auf einem Schachbrett angeordnet werden k\"{o}nnen, dass keine der Damen
      eine andere Dame bedroht.
\end{enumerate}

\section{Formale Definition der aussagenlogischen Formeln}
Wir behandeln zun\"{a}chst die \emph{Syntax} der Aussagenlogik und besprechen anschlie\3end die
\emph{Semantik}.  Die \textsl{Syntax} gibt an, wie Formeln geschrieben werden.
Die \emph{Semantik} befasst sich mit der Bedeutung der Formeln.
Nachdem wir die Semantik der aussagenlogischen Formeln definiert haben, zeigen wir,
wie sich diese Semantik in \textsc{SetlX} implementieren l\"{a}sst.

\subsection{Syntax der aussagenlogischen Formeln}
Wir betrachten eine Menge $\mathcal{P}$ von  \emph{Aussage-Variablen} als gegeben.
Aussagenlogische Formeln sind dann W\"{o}rter, die aus dem Alphabet
\[ \mathcal{A} := \mathcal{P} \cup \bigl\{ \verum, \falsum, \neg, \vee, \wedge,
   \rightarrow, \leftrightarrow, (, ) \bigr\}
\]
gebildet werden.  Wir definieren die Menge der aussagenlogischen Formeln
$\mathcal{F}$ durch eine induktive Definition:
\begin{enumerate}
\item $\verum \in \mathcal{F}$ und $\mathtt{\falsum} \in \mathcal{F}$.

      Hier steht $\verum$ f\"{u}r die Formel, die immer wahr ist, w\"{a}hrend $\falsum$ f\"{u}r die 
      Formel steht, die immer falsch ist.  Die Formel $\verum$ tr\"{a}gt auch den Namen \textsl{Verum},
      f\"{u}r $\falsum$ sagen wir auch \textsl{Falsum}.
\item Ist $p \in \mathcal{P}$, so gilt auch $p \in \mathcal{F}$.

      Jede aussagenlogische Variable ist also eine aussagenlogische Formel.
\item Ist $f \in \mathcal{F}$, so gilt auch $\neg f \in \mathcal{F}$.
\item Sind $f_1, f_2 \in \mathcal{F}$, so gilt auch
      \begin{tabbing}
        $(f_1 \vee f_2) \in \mathcal{F}$ \hspace*{0.5cm} \= (\textsl{gelesen}: \quad \= $f_1$ oder $f_2$),            \\
        $(f_1 \wedge f_2) \in \mathcal{F}$                 \> (\textsl{gelesen}:       \> $f_1$ und $f_2$),             \\
        $(f_1 \rightarrow f_2) \in \mathcal{F}$                \> (\textsl{gelesen}:       \> wenn $f_1$, dann $f_2$),      \\
        $(f_1 \leftrightarrow f_2) \in \mathcal{F}$                \> (\textsl{gelesen}:       \> $f_1$ genau dann, wenn $f_2$).
      \end{tabbing}
\end{enumerate}
Die Menge $\mathcal{F}$ ist nun die kleinste Teilmenge der aus dem Alphabet $\mathcal{A}$
gebildeten W\"{o}rter, die den oben aufgestellten Forderungen gen\"{u}gt.

\example 
Gilt $\mathcal{P} = \{ p, q, r \}$, so haben wir beispielsweise:
\begin{enumerate}
\item $p \in \mathcal{F}$,
\item $(p \wedge q) \in \mathcal{F}$,
\item $((\neg p \rightarrow q) \vee (q \rightarrow \neg p)) \in \mathcal{F}$.  \qed
\end{enumerate}

\noindent
Um Klammern zu sparen, vereinbaren wir:
\begin{enumerate}
\item \"{A}u\3ere Klammern werden weggelassen, wir schreiben also beispielsweise \\[0.2cm]
      \hspace*{1.3cm} $p \wedge q$ \quad statt \quad $(p \wedge q)$.
\item Die Junktoren  $\vee$ und $\wedge$ werden implizit links geklammert, d.h.~wir
      schreiben 
      \\[0.2cm]
      \hspace*{1.3cm} $p \wedge q \wedge r$ \quad statt \quad $(p \wedge q) \wedge r$.
      \\[0.2cm]
      Operatoren, die implizit nach links geklammert werden, nennen wir \emph{links-assoziativ}.
\item Der Junktor $\rightarrow$ wird implizit rechts geklammert, d.h.~wir
      schreiben \\[0.2cm]
      \hspace*{1.3cm} $p \rightarrow q \rightarrow r$ \quad statt \quad $p \rightarrow (q \rightarrow r)$.
      \\[0.2cm]
      Operatoren, die implizit nach rechts geklammert werden, nennen wir \emph{rechts-assoziativ}.
\item Die Junktoren $\vee$ und $\wedge$ binden st\"{a}rker als $\rightarrow$, wir schreiben
      also \\[0.2cm]
      \hspace*{1.3cm} $p \wedge q \rightarrow r$ \quad statt \quad $(p \wedge q) \rightarrow r$

      \textbf{Beachten} Sie, dass die Junktoren $\wedge$ und $\vee$ gleich stark binden.  Dies ist
      anders als in der Sprache \textsc{SetlX}, denn dort bindet der Operator ``\texttt{\&\&}'' st\"{a}rker als
      der Operator ``\texttt{||}''.
\item Der Junktor $\rightarrow$ bindet st\"{a}rker als $\leftrightarrow$, wir schreiben
      also \\[0.2cm]
      \hspace*{1.3cm} $p \rightarrow q \leftrightarrow r$ \quad statt \quad $(p \rightarrow q) \leftrightarrow r$.
\end{enumerate}

\remark
Wir werden im Rest dieser Vorlesung eine Reihe von Beweisen f\"{u}hren, bei denen es darum geht,
mathematische Aussagen \"{u}ber Formeln nachzuweisen.  Bei diesen Beweisen werden wir nat\"{u}rlich
ebenfalls aussagenlogische Junktoren wie ``\emph{genau dann, wenn}'' oder 
``\emph{wenn $\cdots$,  dann}'' verwenden.  Dabei entsteht dann die Gefahr, dass wir die Junktoren,
die wir in unseren Beweisen verwenden, mit den Junktoren, die in den aussagenlogischen Formeln
auftreten, verwechseln.  Um dieses Problem zu umgehen vereinbaren wir:
\begin{enumerate}
\item Innerhalb einer aussagenlogischen Formel wird der Junktor  
      ``\emph{wenn $\cdots$,  dann}'' als ``$\rightarrow$''  geschrieben.
\item Bei den Beweisen, die wir \"{u}ber aussagenlogische Formeln f\"{u}hren, schreiben wir f\"{u}r diesen
      Junktor statt dessen ``$\Rightarrow$''.
\end{enumerate}
Analog wird der Junktor ``\emph{genau dann, wenn}'' innerhalb einer aussagenlogischen Formel als
``$\leftrightarrow$'' geschrieben, aber wenn wir dieser Junktor als Teil eines Beweises verwenden,
schreiben wir statt dessen ``$\Leftrightarrow$''. \eox

\subsection{Semantik der aussagenlogischen Formeln}
Um aussagenlogischen Formeln einen Wahrheitswert zuordnen zu k\"{o}nnen, definieren wir
zun\"{a}chst die Menge $\mathbb{B}$ der Wahrheitswerte:  \\[0.2cm] 
\hspace*{1.3cm} $\mathbb{B} := \{ \mathtt{true}, \mathtt{false} \}$. \\[0.2cm]
Damit k\"{o}nnen wir nun
den Begriff einer \emph{aussagenlogischen Interpretation} festlegen.

\begin{Definition}[Aussagenlogische Interpretation]
  Eine \emph{aussagenlogische Interpretation} ist eine Funktion \\[0.2cm]
  \hspace*{1.3cm} $\mathcal{I}:\mathcal{P} \rightarrow \mathbb{B}$, \\[0.2cm]
  die jeder Aussage-Variablen $p\in \mathcal{P}$ einen Wahrheitswert $\mathcal{I}(p) \in \mathbb{B}$ zuordnet.
  \eox
\end{Definition}
Eine aussagenlogische Interpretation wird oft auch als \emph{Belegung} der
Aussage-Variablen mit Wahr\-heits-Werten bezeichnet.  

Eine aussagenlogische Interpretation $\mathcal{I}$ interpretiert die Aussage-Variablen.
Um nicht nur Variablen sondern auch aussagenlogische Formel interpretieren zu k\"{o}nnen, 
ben\"{o}tigen wir eine
Interpretation der Junktoren ``$\neg$'', ``$\wedge$'', ``$\vee$'', ``$\rightarrow$'' und
``$\leftrightarrow$''.  Zu diesem Zweck definieren wir auf der Menge $\mathbb{B}$
Funktionen
$\circneg$, $\circwedge$, $\circvee$, $\circright$ und $\circleftright$
mit deren Hilfe wir die aussagenlogischen Junktoren interpretieren k\"{o}nnen:
\begin{enumerate}
\item $\circneg: \mathbb{B} \rightarrow \mathbb{B}$
\item $\circwedge: \mathbb{B} \times \mathbb{B} \rightarrow \mathbb{B}$
\item $\circvee: \mathbb{B} \times \mathbb{B} \rightarrow \mathbb{B}$
\item $\circright: \mathbb{B} \times \mathbb{B} \rightarrow \mathbb{B}$
\item $\circleftright: \mathbb{B} \times \mathbb{B} \rightarrow \mathbb{B}$
\end{enumerate}
Wir haben in der Mengenlehre gesehen, dass Funktionen als spezielle Relationen
aufgefasst werden k\"{o}nnen.  Die Funktion $\circneg$ dreht die Wahrheits-Werte um und
kann daher als Relation wie folgt geschrieben werden:
\[ \circneg = \bigl\{ \pair(\texttt{true},\texttt{false}), \pair(\texttt{false},\texttt{true}) \bigr\}. \]
Wir k\"{o}nnten auch die Funktionen $\circwedge$, $\circvee$, $\circright$ und $\circleftright$ als
Relationen definieren, es ist aber anschaulicher, wenn wir die Werte dieser
Funktionen durch eine Tabelle festlegen.  Diese Tabelle ist oben auf Seite
\pageref{tab:aussagen-logik} abgebildet. 

\begin{table}[!ht]
  \centering
\framebox{
  \begin{tabular}{|l|l|l|l|l|l|l|}
\hline
   $p$            & $q$            & $\circneg\;(p)$ & $\circvee\;(p, q)$ & $\circwedge\;(p, q)$ & $\circright\;(p, q)$ & $\circleftright\;(p, q)$
   \\
\hline
\hline
   \texttt{true}  & \texttt{true}  & \texttt{false} & \texttt{true}  & \texttt{true}  & \texttt{true}     & \texttt{true}  \\
\hline
   \texttt{true}  & \texttt{false} & \texttt{false} & \texttt{true}  & \texttt{false} & \texttt{false}    & \texttt{false}  \\
\hline
   \texttt{false} & \texttt{true}  & \texttt{true}  & \texttt{true}  & \texttt{false} & \texttt{true}     & \texttt{false} \\
\hline
   \texttt{false} & \texttt{false} & \texttt{true}  & \texttt{false} & \texttt{false} & \texttt{true}     & \texttt{true}  \\
\hline
  \end{tabular}}
  \caption{Interpretation der Junktoren.}
  \label{tab:aussagen-logik}
\end{table}
Nun k\"{o}nnen wir den Wert, den eine aussagenlogische Formel $f$ unter einer gegebenen
aussagenlogischen Interpretation $\mathcal{I}$ annimmt, durch Induktion nach dem Aufbau
der Formel $f$ definieren.  Wir werden diesen Wert mit $\widehat{\mathcal{I}}(f)$
bezeichnen.  Wir setzen:
\begin{enumerate}
\item $\widehat{\mathcal{I}}(\falsum) := \mathtt{false}$.
\item $\widehat{\mathcal{I}}(\verum) := \mathtt{true}$.
\item $\widehat{\mathcal{I}}(p) := \mathcal{I}(p)$ f\"{u}r alle $p \in \mathcal{P}$.
\item $\widehat{\mathcal{I}}(\neg f) := \circneg\;\bigl(\widehat{\mathcal{I}}(f)\bigr)$ f\"{u}r alle $f \in \mathcal{F}$.
\item $\widehat{\mathcal{I}}(f \wedge g) := \circwedge\;\bigl(\widehat{\mathcal{I}}(f), \widehat{\mathcal{I}}(g)\bigr)$ 
      f\"{u}r alle $f, g \in \mathcal{F}$.
\item $\widehat{\mathcal{I}}(f \vee g) := \circvee\;\bigl(\widehat{\mathcal{I}}(f), \widehat{\mathcal{I}}(g)\bigr)$ 
      f\"{u}r alle $f, g \in \mathcal{F}$.
\item $\widehat{\mathcal{I}}(f \rightarrow g) := \circright\;\bigl(\widehat{\mathcal{I}}(f), \widehat{\mathcal{I}}(g)\bigr)$ 
      f\"{u}r alle $f, g \in \mathcal{F}$.
\item $\widehat{\mathcal{I}}(f \leftrightarrow g) := \circleftright\;\bigl(\widehat{\mathcal{I}}(f), \widehat{\mathcal{I}}(g)\bigr)$ 
      f\"{u}r alle $f, g \in \mathcal{F}$.
\end{enumerate}
Um die Schreibweise nicht \"{u}berm\"{a}\3ig kompliziert werden zu lassen, unterscheiden wir in
Zukunft nicht  mehr zwischen $\widehat{\mathcal{I}}$ und $\mathcal{I}$, wir werden das H\"{u}tchen \"{u}ber dem
$\mathcal{I}$ also weglassen.

\noindent
\textbf{Beispiel}: Wir zeigen, wie sich der Wahrheits-Wert der Formel
$$  (p \rightarrow q) \rightarrow (\neg p \rightarrow q) \rightarrow q $$
f\"{u}r die aussagenlogische Interpretation $\mathcal{I}$, die durch 
$\mathcal{I}(p) = \mathtt{true}$ und $\mathcal{I}(q) = \mathtt{false}$ definiert ist,
berechnen l\"{a}sst: 
\[
  \begin{array}{lcl}
   \mathcal{I}\Bigl( (p \rightarrow q) \rightarrow (\neg p \rightarrow q) \rightarrow q  \Bigr) 
   & = &  \circright\Bigl( \mathcal{I}\bigl( (p \rightarrow q) \bigr),\, \mathcal{I}\bigl((\neg p \rightarrow q) \rightarrow q\bigr) \Bigr) \\[0.2cm]
   & = & \circright\Bigl( \circright\bigl( \mathcal{I}(p), \mathcal{I}(q) \bigr),\, \mathcal{I}\bigl((\neg p \rightarrow q) \rightarrow q\bigr) \Bigr) \\[0.2cm]
   & = & \circright\Bigl( \circright\bigl( \mathtt{true}, \mathtt{false} \bigr),\, \mathcal{I}\bigl((\neg p \rightarrow q) \rightarrow q\bigr) \Bigr) \\[0.2cm]
   & = & \circright\Bigl( \mathtt{false}, \, \mathcal{I}\bigl((\neg p \rightarrow q) \rightarrow q\bigr) \Bigr) \\[0.2cm]
   & = & \mathtt{true} \\
 \end{array}
\]
Beachten Sie, dass wir bei der Berechnung gerade soviele Teile der Formel ausgewertet
haben, wie notwendig waren um den Wert der Formel zu bestimmen.  Trotzdem ist die
eben durchgef\"{u}hrte Rechnung f\"{u}r die Praxis zu umst\"{a}ndlich.  Stattdessen wird der Wert
einer Formel direkt mit Hilfe der Tabelle \ref{tab:aussagen-logik} auf Seite
\pageref{tab:aussagen-logik} berechnet.  Wir zeigen exemplarisch, wie wir den
Wahrheits-Wert der Formel
$$  (p \rightarrow q) \rightarrow (\neg p \rightarrow q) \rightarrow q $$
f\"{u}r beliebige Belegungen $\mathcal{I}$ \"{u}ber diese Tabelle berechnen k\"{o}nnen.
 Um nun die Wahrheitswerte 
dieser Formel unter einer gegebenen Belegung der Aussage-Variablen bestimmen zu k\"{o}nnen,
 bauen wir eine  Tabelle auf, die f\"{u}r jede in der Formel
auftretende Teilformel eine Spalte enth\"{a}lt.  Tabelle \ref{tab:tautologie} auf Seite
\pageref{tab:tautologie} zeigt die entstehende Tabelle.
\begin{table}[!ht]
  \centering
\framebox{
  \begin{tabular}{|l|l|l|l|l|l|l|}
\hline
   $p$ & $q$ & $\neg p$ & $p \rightarrow q$ & $\neg p \rightarrow q$ & $(\neg p \rightarrow q) \rightarrow q$ & $ (p \rightarrow q) \rightarrow (\neg p \rightarrow q) \rightarrow q$
   \\
\hline
\hline
   \texttt{true}  & \texttt{true}  & \texttt{false} & \texttt{true}  & \texttt{true}  & \texttt{true}     & \texttt{true}  \\
\hline
   \texttt{true}  & \texttt{false} & \texttt{false} & \texttt{false}  & \texttt{true} & \texttt{false}    & \texttt{true}  \\
\hline
   \texttt{false} & \texttt{true}  & \texttt{true}  & \texttt{true}  & \texttt{true} & \texttt{true}     & \texttt{true} \\
\hline
   \texttt{false} & \texttt{false} & \texttt{true}  & \texttt{true} & \texttt{false} & \texttt{true}     & \texttt{true}  \\
\hline
  \end{tabular}}
  \caption{Berechnung der Wahrheitswerte von $(p \rightarrow q) \rightarrow (\neg p \rightarrow q) \rightarrow q$.}
  \label{tab:tautologie}
\end{table}

Betrachten wir die letzte Spalte der Tabelle so sehen wir, dass dort immer der Wert
\texttt{true} auftritt.  Also liefert die Auswertung der Formel
$(p \rightarrow q) \rightarrow (\neg p \rightarrow q) \rightarrow q $
f\"{u}r jede aussagenlogische Belegung $\mathcal{I}$ den Wert \texttt{true}.  
Formeln, die immer wahr sind, haben in der Aussagenlogik eine besondere Bedeutung und
werden als \emph{Tautologien} bezeichnet.

Wir erl\"{a}utern die Aufstellung dieser Tabelle anhand der zweiten Zeile.  In dieser Zeile sind zun\"{a}chst die
aussagenlogischen Variablen $p$ auf \texttt{true} und $q$ auf \texttt{false} gesetzt.  Bezeichnen wir die
aussagenlogische Interpretation mit $\mathcal{I}$, so gilt also\\[0.2cm]
\hspace*{1.3cm} $\mathcal{I}(p) = \mathtt{true}$ und $\mathcal{I}(q) = \mathtt{false}$. \\[0.2cm]
Damit erhalten wir folgende Rechnung:
\begin{enumerate}
\item $\mathcal{I}(\neg p) = \circneg\,(\mathcal{I}(p)) = \circneg\,( \mathtt{true}) = \mathtt{false}$
\item $\mathcal{I}(p \rightarrow q) = \circright\,(\mathcal{I}(p), \mathcal{I}(q)) = \circright\,(\mathtt{true}, \mathtt{false}) = \mathtt{false}$
\item $\mathcal{I}(\neg p \rightarrow q) = \circright\bigl( \mathcal{I}(\neg p), \mathcal{I}(q)\bigr) = \circright(\mathtt{false}, \mathtt{false}) = \mathtt{true}$
\item $\mathcal{I}\bigl((\neg p \rightarrow q) \rightarrow q\bigr) = 
          \circright\bigl( \mathcal{I}(\neg p \rightarrow q), \mathcal{I}(q) \bigr) = 
          \circright( \mathtt{true}, \mathtt{false} ) = \mathtt{false}$
\item $\mathcal{I}\bigl((p \rightarrow q) \rightarrow  (\neg p \rightarrow q) \rightarrow q\bigr) = 
      \circright\bigl( \mathcal{I}(p \rightarrow q),  \mathcal{I}((\neg p \rightarrow q) \rightarrow q)\bigr) = 
       \circright\,( \mathtt{false},  \mathtt{false} ) = \mathtt{true}$
\end{enumerate}
F\"{u}r komplexe Formeln ist die Auswertung von Hand viel zu m\"{u}hsam und
fehleranf\"{a}llig um praktikabel zu sein.  Wir zeigen deshalb im \"{u}bern\"{a}chsten Abschnitt, wie
sich dieser Prozess automatisieren l\"{a}sst.

\subsection{Extensionale und intensionale Interpretationen der Aussagenlogik}
Die Interpretation des aussagenlogischen Junktoren ist rein \emph{extensional}:
Wenn wir den Wahrheitswert der Formel
\\[0.2cm]
\hspace*{1.3cm}
$\mathcal{I}(f \rightarrow g)$ 
\\[0.2cm]
berechnen wollen, so m\"{u}ssen wir die Details der Teilformeln $f$ und $g$ nicht kennen, es reicht,
wenn wir die Werte $\mathcal{I}(f)$ und $\mathcal{I}(g)$ kennen.   Das ist problematisch,
denn in der Umgangssprache hat der Junktor
``\textsl{wenn $\cdots$, dann}'' auch eine \emph{kausale} Bedeutung.  Mit der extensionalen
Implikation wird der Satz
\\[0.2cm]
\hspace*{1.3cm}
``\textsl{Wenn $3 \cdot 3 = 8$, dann schneit es.}''
\\[0.2cm]
als wahr interpretiert, denn die Formel $3 \cdot 3 = 8$ ist ja falsch.  Dass ist problematisch, weil wir diesen Satz in der Umgangssprache 
als sinnlos erkennen.  Insofern ist die extensionale Interpretation des sprachlichen Junktors
``\textsl{wenn $\cdots$, dann}'' nur eine Approximation der umgangssprachlichen Interpretation, die sich f\"{u}r die
Mathematik und die Informatik aber als ausreichend erwiesen hat.

Es gibt durchaus andere Logiken, in denen die Interpretation des Operators ``$\rightarrow$'' von der
hier gegebenen Definition abweicht.  Diese Logiken sind allerdings wesentlich komplizierter als die
Form der Logik, die wir hier betrachten.

\subsection{Implementierung in \textsc{SetlX}} 
Um die bisher eingef\"{u}hrten Begriffe nicht zu abstrakt werden zu lassen,
entwickeln wir in \textsc{SetlX} ein Programm, mit dessen Hilfe sich Formeln
auswerten lassen.  
Jedesmal, wenn wir ein Programm zur Berechnung irgendwelcher Wert entwickeln wollen,
m\"{u}ssen wir uns als erstes fragen, wie wir die Argumente der zu implementierenden Funktion und die
Ergebnisse dieser Funktion in der verwendeten Programmier-Sprache darstellen k\"{o}nnen.
In diesem Fall m\"{u}ssen wir uns also \"{u}berlegen, wie wir eine
aussagenlogische Formel in \textsc{SetlX} repr\"{a}sentieren k\"{o}nnen, denn Ergebnisswerte
\texttt{true} und \texttt{false} stehen ja als Wahrheitswerte unmittelbar zur Verf\"{u}gung.
Zusammengesetzte Daten-Strukturen k\"{o}nnen in \textsc{SetlX} am einfachsten als
Terme dargestellt werden und das ist auch der Weg, den wir f\"{u}r die aussagenlogischen
Formeln  beschreiten werden.  Wir definieren die Repr\"{a}sentation von
aussagenlogischen Formeln formal dadurch, dass wir eine Funktion
\\[0.2cm]
\hspace*{1.3cm}
$\textsl{rep}: \mathcal{F} \rightarrow \textsc{SetlX}$
\\[0.2cm]
definieren, die einer aussagenlogischen Formel $f$ einen Term $\textsl{rep}(f)$ zuordnet.  Wir
werden dabei die in \textsc{SetlX} bereits vorhandenen logischen Operatoren
``\texttt{!}'', ``\texttt{\&\&}'', ``\texttt{||}'', ``\texttt{=>}'' und
``\texttt{<==>}'' benutzen, denn damit k\"{o}nnen wir die aussagenlogischen Formeln in sehr nat\"{u}rlicher
Weise darstellen.
\begin{enumerate}
\item $\verum$ wird repr\"{a}sentiert durch den Wahrheitswert \texttt{true}.
      \\[0.2cm]
      \hspace*{1.3cm}
      $\textsl{rep}(\verum) := \mathtt{true}$
\item $\falsum$  wird repr\"{a}sentiert durch den Wahrheitswert \texttt{false}.
      \\[0.2cm]
      \hspace*{1.3cm}
      $\textsl{rep}(\falsum) := \mathtt{false}$
\item Eine aussagenlogische Variable $p \in \mathcal{P}$ repr\"{a}sentieren wir 
      durch einen Term der Form
      \\[0.2cm]
      \hspace*{1.3cm}
      \texttt{\symbol{94}variable(p)}.
      \\[0.2cm]
      Der Grund f\"{u}r diese zun\"{a}chst seltsam anmutende Darstellung der Variable liegt darin,
      dass \textsc{SetlX} intern Variablen in der obigen Form darstellt.  Wenn wir sp\"{a}ter
      einen \texttt{String} mit Hilfe der \textsc{SetlX}-Funktion \texttt{parse} in eine
      aussagenlogische Formel umwandeln wollen, dann werden Variablen automatisch in dieser Form
      dargestellt. Damit haben wir also
      \\[0.2cm]
      \hspace*{1.3cm}
      $\textsl{rep}(p) := \texttt{\symbol{94}variable}(p)$ \quad f\"{u}r alle $p \in \mathcal{P}$.
\item Ist $f$ eine aussagenlogische Formel, so repr\"{a}sentieren wir $\neg f$ mit Hilfe des Operators
      ``\texttt{!}'': \\[0.2cm]
      \hspace*{1.3cm} 
      $\textsl{rep}(\neg f) := \texttt{!} \textsl{rep}(f)$.
\item Sind $f_1$ und $f_2$ aussagenlogische Formel, so repr\"{a}sentieren wir $f_1 \vee f_2$ mit
      Hilfe des Operators  ``\texttt{||}'': \\[0.2cm]
      \hspace*{1.3cm} 
      $\textsl{rep}(f \vee g) := \textsl{rep}(f) \;\texttt{||}\; \textsl{rep}(g)$.
\item Sind $f_1$ und $f_2$ aussagenlogische Formel, so repr\"{a}sentieren wir $f_1 \wedge f_2$ mit
      Hilfe des Operators ``\texttt{\&\&}'': \\[0.2cm]
      \hspace*{1.3cm} 
      $\textsl{rep}(f \wedge g) := \textsl{rep}(f) \;\texttt{\&\&}\; \textsl{rep}(g)$.
\item Sind $f_1$ und $f_2$ aussagenlogische Formel, so repr\"{a}sentieren wir $f_1 \rightarrow f_2$ mit Hilfe
      des Operators  ``\texttt{=>}'': \\[0.2cm]
      \hspace*{1.3cm} 
      $\textsl{rep}(f \rightarrow g) := \textsl{rep}(f) \;\texttt{=>}\; \textsl{rep}(g)$.
\item Sind $f_1$ und $f_2$ aussagenlogische Formel, so repr\"{a}sentieren wir 
      $f_1 \leftrightarrow f_2$ mit Hilfe des Operators ``\texttt{<==>}'': \\[0.2cm] 
      \hspace*{1.3cm} 
      $\textsl{rep}(f \leftrightarrow g) := 
       \textsl{rep}(f) \;\texttt{<==>}\; \textsl{rep}(g)$.
\end{enumerate}
Bei der Wahl der Repr\"{a}sentation, mit der wir eine Formel in \setl\ rep\"{a}sentieren,
sind wir weitgehend frei.  Wir h\"{a}tten oben sicher auch eine andere Repr\"{a}sentation
verwenden k\"{o}nnen.  Beispielsweise wurden in einer fr\"{u}heren Version dieses Skriptes die
aussagenlogischen Formeln als Listen repr\"{a}sentiert.
Eine gute Repr\"{a}sentation sollte einerseits m\"{o}glichst intuitiv sein, andererseits ist
es auch wichtig, dass die Repr\"{a}sentation f\"{u}r die zu entwickelnden Algorithmen \underline{ad\"{a}}q\underline{uat}
ist.  Im wesentlichen hei\3t dies, dass es einerseits einfach sein sollte, auf
die Komponenten einer Formel zuzugreifen, andererseits sollte es auch leicht sein,
die entsprechende Repr\"{a}sentation zu erzeugen.  Da wir zur Darstellung der
aussagenlogischen Formeln dieselben Operatoren verwenden, die auch in \textsc{SetlX} selber
benutzt werden, k\"{o}nnen wir die in \textsc{SetlX} vordefinierte Funktion \texttt{parse}
benutzen um einen String in eine Formel umzuwandeln.  Beispielweise liefert der Aufruf
\\[0.2cm]
\hspace*{1.3cm}
\texttt{f := parse(\symbol{34}p => p || !q\symbol{34});}
\\[0.2cm]
f\"{u}r $f$ die Formel
\\[0.2cm]
\hspace*{1.3cm}
\texttt{p => p || !q}.
\\[0.2cm]
Mit Hilfe der \textsc{SetlX}-Funktion \texttt{canonical} k\"{o}nnen wir uns anschauen, wie die
Formel in \textsc{SetlX} intern als Term dargestellt wird.  Die Eingabe
\\[0.2cm]
\hspace*{1.3cm}
\texttt{canonical(f);}
\\[0.2cm]
in der Kommandozeile liefert uns das Ergebnis
\\[0.2cm]
\hspace*{1.3cm}
\texttt{\symbol{94}implication(\symbol{94}variable(\symbol{34}p\symbol{34}), \symbol{94}disjunction(\symbol{94}variable(\symbol{34}p\symbol{34}), \symbol{94}not(\symbol{94}variable(\symbol{34}q\symbol{34}))))}
\\[0.2cm]
Wir erkennen, dass in \textsc{SetlX} der Operator ``\texttt{=>}'' intern
durch das Funktions-Zeichen ``\texttt{\symbol{94}implication}'' dargestellt wird.
Dem Operator ``\texttt{||}'' entspricht das Funktions-Zeichen ````\texttt{\symbol{94}disjunction}'',
der Operator ``\texttt{\&\&}'' wird durch ``\texttt{\symbol{94}conjunction}'' repr\"{a}sentiert und
der Operator ``\texttt{!}'' wird intern als  ``\texttt{\symbol{94}not}'' geschrieben.

Als n\"{a}chstes geben wir an, wie wir eine aussagenlogische Interpretation in \textsc{SetlX}
darstellen.  Eine aussagenlogische Interpretation ist eine Funktion \\[0.2cm]
\hspace*{1.3cm} ${\cal I}: {\cal P} \rightarrow \mathbb{B}$ \\[0.2cm]
von der Menge der Aussage-Variablen ${\cal P}$ in die Menge der Wahrheitswerte 
$\mathbb{B}$.  Ist eine Formel $f$ gegeben, so ist klar, dass bei der
Interpretation ${\cal I}$ nur die Aussage-Variablen $p$ eine Rolle spielen,
die auch in der Formel $f$ auftreten.  Wir k\"{o}nnen daher die Interpretation
${\cal I}$ durch eine funktionale Relation darstellen, also durch eine Menge von
Paaren der Form \texttt{[ $p$, $b$ ]}, f\"{u}r die $p$ eine Aussage-Variable ist und f\"{u}r die zus\"{a}tzlich
$b \in \mathbb{B}$ gilt:
\[ \mathcal{I} \subseteq \mathcal{P} \times \mathbb{B}. \]
Damit k\"{o}nnen wir jetzt eine einfache Funktion schreiben, die den Wahrheitswert
einer aussagenlogischen Formel $f$ unter einer gegebenen aussagenlogischen
Interpretation ${\cal I}$ berechnet. Die Funktion
\href{https://github.com/karlstroetmann/Logik/blob/master/SetlX/evaluate.stlx}{\texttt{evaluate.stlx}}
ist in Abbildung \ref{fig:evaluate.stlx} auf Seite \pageref{fig:evaluate.stlx} gezeigt.
Die Funktion \texttt{evaluate} erwartet zwei Argumente:
\begin{enumerate}
\item Das erste Argument $f$ ist eine aussagenlogische Formel, die so durch einen Term dargestellt
      wird, wie wir das weiter oben beschrieben haben.
\item Das zweite Argument $i$ ist eine aussagenlogische Interpretation, die als funktionale Relation
      dargestellt wird.  F\"{u}r eine aussagenlogische Variable mit dem Namen $p$ k\"{o}nnen wir den Wert,
      der dieser Variablen durch $i$ zugeordnet wird, mittels des Ausdrucks $i[p]$ berechnen.
\end{enumerate}

\begin{figure}[!ht]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.3cm,
                  xrightmargin  = 0.3cm
                ]
    evaluate := procedure(f, i) {
        match (f) {
            case true:         return true;
            case false:        return false;
            case ^variable(p): return i[p];
            case !g:           return !evaluate(g, i);
            case g && h:       return  evaluate(g, i) && evaluate(h, i);
            case g || h:       return  evaluate(g, i) || evaluate(h, i);
            case g => h:       return  evaluate(g, i) => evaluate(h, i);
            case g <==> h:     return  evaluate(g, i) == evaluate(h, i);
            default:           abort("syntax error in evaluate($f$, $i$)");
        }
    };
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{Auswertung einer aussagenlogischen Formel.}
  \label{fig:evaluate.stlx}
\end{figure} 

\noindent
Wir diskutieren jetzt die Implementierung der Funktion \texttt{evaluate()} Zeile f\"{u}r
Zeile:
\begin{enumerate}
\item Falls die Formel $f$ den Wert \texttt{true} hat, so rep\"{a}sentiert $f$ die Formel $\verum$.
      Also ist das Ergebnis der Auswertung unabh\"{a}ngig von der aussagenlogischen
      Interpretation $i$ immer \texttt{true}. 
\item Falls die Formel $f$ den Wert \texttt{false} hat, so rep\"{a}sentiert $f$ die Formel
      $\falsum$.  Also ist das Ergebnis der
      Auswertung unabh\"{a}ngig von der aussagenlogischen Interpretation $i$ immer \texttt{false}.
\item In Zeile 5 betrachten wir den Fall, dass das Argument $f$ eine aussagenlogische
      Variable repr\"{a}sentiert.   

      In diesem Fall m\"{u}ssen wir die Belegung $i$, die ja eine Funktion
      von den aussagenlogischen Variablen in die Wahrheitswerte ist, auf die Variable $f$
      anwenden.  Da wir die Belegung als eine funktionale Relation dargestellt haben,
      k\"{o}nnen wir diese Relation durch den Ausdruck $i[p]$ sehr einfach f\"{u}r die Variable 
      $p$ auswerten.
\item In Zeile 6 betrachten wir den Fall, dass $f$ die Form $\texttt{!}g$
      hat und folglich die Formel $\neg g$ repr\"{a}sentiert.
      In diesem Fall werten wir erst $g$ unter der Belegung $i$ aus und negieren dann das Ergebnis.
\item In Zeile 7 betrachten wir den Fall, dass $f$ die Form 
      $g_1 \;\texttt{\&\&}\; g_2$ hat und folglich die 
      Formel $g_1 \wedge g_2$ repr\"{a}sentiert.
      In diesem Fall werten wir zun\"{a}chst $g_1$ und $g_2$ unter der Belegung $i$ 
      aus und verkn\"{u}pfen  das Ergebnis mit dem Operator ``\texttt{\&\&}''.
\item In Zeile 8 betrachten wir den Fall, dass $f$ die Form 
      $g_1 \;\texttt{||}\; g_2$ hat und folglich die Formel $g_1 \vee g_2$ repr\"{a}sentiert.
      In diesem Fall werten wir zun\"{a}chst $g_1$ und $g_2$ unter der Belegung $i$ 
      aus und verkn\"{u}pfen  das Ergebnis mit dem Operator ``\texttt{||}''.
\item In Zeile 9 betrachten wir den Fall, dass $f$ die Form 
       $g_1 \;\texttt{=>}\; g_2$ hat und folglich die 
      Formel $g_1 \rightarrow g_2$       repr\"{a}sentiert.
      In diesem Fall werten wir zun\"{a}chst $g_1$ und $g_2$ unter der Belegung $i$ 
      aus und benutzen dann den Operator ``\texttt{=>}'' der Sprache \textsc{SetlX}.
\item In Zeile 10 f\"{u}hren wir die Auswertung einer Formel $g_1 \;\texttt{<==>}\; g_2$
      auf die Gleichheit zur\"{u}ck: Die Formel $f \leftrightarrow g$ ist genau dann wahr,
      wenn $f$ und $g$ den selben Wahrheitswert haben.
\item Wenn keiner der vorhergehenden F\"{a}lle greift, liegt ein Syntax-Fehler vor, 
      auf den wir in Zeile 11 hinweisen.
\end{enumerate}


\subsection{Eine Anwendung}
Wir betrachten eine spielerische Anwendung der Aussagenlogik.  Inspektor Watson wird zu
einem Juweliergesch\"{a}ft gerufen, in das eingebrochen worden ist.
In der unmittelbaren Umgebung werden drei Verd\"{a}chtige Anton, Bruno und Claus festgenommen.
Die Auswertung der Akten ergibt folgendes:
\begin{enumerate}
\item Einer der drei Verd\"{a}chtigen muss die Tat begangen haben: \\[0.2cm]
      \hspace*{1.3cm} 
      $f_1 := a \vee b \vee c$.
\item Wenn Anton schuldig ist, so hat er genau einen Komplizen. 

      Diese Aussage zerlegen wir zun\"{a}chst in zwei Teilaussagen:
      \begin{enumerate}
      \item Wenn Anton schuldig ist, dann hat er mindestens einen Komplizen: \\[0.2cm]
            \hspace*{1.3cm} $f_2 := a \rightarrow b \vee c$ 
      \item Wenn Anton schuldig ist, dann hat er h\"{o}chstens einen Komplizen: \\[0.2cm]
           \hspace*{1.3cm} $f_3 := a \rightarrow \neg (b \wedge c)$
      \end{enumerate}
\item Wenn Bruno unschuldig ist, dann ist auch Claus unschuldig: \\[0.2cm]
      \hspace*{1.3cm} $f_4 :=  \neg b \rightarrow \neg c$ 
\item Wenn genau zwei schuldig sind, dann ist Claus einer von ihnen.

      Es ist nicht leicht zu sehen, wie diese Aussage sich aussagenlogisch
      formulieren l\"{a}sst.  Wir behelfen uns mit einem Trick und \"{u}berlegen uns, wann die
      obige Aussage falsch ist.  Wir sehen, die Aussage ist dann falsch,
      wenn Claus nicht schuldig ist und wenn gleichzeitig Anton und Bruno schuldig sind.
      Damit lautet die Formalisierung der obigen Aussage: \\[0.2cm]
      \hspace*{1.3cm} $f_5 := \neg ( \neg c  \wedge a \wedge b )$ 
\item Wenn Claus unschuldig ist, ist Anton schuldig. \\[0.2cm]
      \hspace*{1.3cm} $f_6 := \neg c \rightarrow a$
\end{enumerate}
Wir haben nun eine Menge $F = \{ f_1, f_2, f_3, f_4, f_5, f_6 \}$ von Formeln.
Wir fragen uns nun, f\"{u}r welche Belegungen $\mathcal{I}$ alle Formeln aus der Menge $F$ wahr werden.
Wenn es genau eine Belegungen gibt, f\"{u}r die dies der Fall ist, dann liefert uns die
Belegung den oder die T\"{a}ter.  Eine Belegung entspricht dabei 1-zu-1 der Menge der T\"{a}ter.
H\"{a}tten wir beispielsweise \\[0.2cm]
\hspace*{1.3cm} 
$\mathcal{I} = \bigl\{ \pair(a,\mathtt{false}), \pair(b,\mathtt{false}), \pair(c,\mathtt{true}) \bigr\}$,
\\[0.2cm]
so w\"{a}re Claus der alleinige T\"{a}ter.  Diese Belegung l\"{o}st unser Problem allerdings
nicht, denn Sie widerspricht der dritten Aussage: Da Bruno unschuldig w\"{a}re, w\"{a}re dann auch
Claus unschuldig.  Da es zu zeitraubend ist, alle Belegungen von Hand auszuprobieren,
schreiben wir besser ein Programm, das die notwendigen Berechnungen f\"{u}r uns durchf\"{u}hrt.
Abbildung \ref{fig:watson.stlx} zeigt das Programm
\href{https://github.com/karlstroetmann/Logik/blob/master/SetlX/watson.stlx}{\texttt{watson.stlx}}.
Wir diskutieren diese Programm nun Zeile f\"{u}r Zeile.

\begin{figure}[!ht]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm
                ]
    // This procedure turns a subset m of the set of all variables 
    // v into a propositional valuation i, such that i[x] is true 
    // iff x is an element of the set m.
    createValuation := procedure(m, v) {
        return { [ x, x in m ] : x in v };
    };
    // Austin, Brian, or Colin is guilty.
    f1 := parse("a || b || c");
    // If Austin is guilty, he has exactly one accomplice.
    f2 := parse("a => b || c");    // at least one accomplice
    f3 := parse("a => !(b && c)"); // at most  one accomplice
    // If Brian is innocent, then Colin is innocent, too.
    f4 := parse("!b => !c"); 
    // If exactly two are guilty, then Colin is one of them.
    f5 := parse("!(a && b && !c)"); 
    // If Colin is innocent, then Austin is guilty.
    f6 := parse("!c => a");
    fs := { f1, f2, f3, f4, f5, f6 };
    v  := { "a", "b", "c" };
    all := 2 ** v;
    print("all = ", all);
    // b is the set of all propositional valuations.
    b  := { createValuation(m, v) : m in all };
    s  := { i : i in b | forall (f in fs | evaluate(f, i)) };
    print("Set of all valuations satisfying all facts: ", s);
    if (#s == 1) {
        i := arb(s);
        offenders := { x : x in v | i[x] };
        print("Set of offenders: ", offenders);
    }
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{Programm zur Aufk\"{a}rung des Einbruchs.}
  \label{fig:watson.stlx}
\end{figure}

\begin{enumerate}
\item In den Zeilen 7 -- 17 definieren wir die Formeln $f_1$, $\cdots$, $f_6$      .
      Wir m\"{u}ssen hier die Formeln in die \textsc{SetlX}-Repr\"{a}sentation bringen.
      Diese Arbeit wird uns durch die Benutzung der Funktion \texttt{parse} leicht gemacht.
\item Als n\"{a}chstes m\"{u}ssen wir uns \"{u}berlegen, wie wir alle Belegungen aufz\"{a}hlen k\"{o}nnen. 
      Wir hatten oben schon beobachtet, dass die Belegungen 1-zu-1 zu den m\"{o}glichen Mengen der T\"{a}ter
      korrespondieren.  Die Mengen der m\"{o}glichen T\"{a}ter sind aber alle Teilmengen der Menge
      \\[0.2cm]
      \hspace*{1.3cm}
      $\{ \squote{a}, \squote{b}, \squote{c} \}$. 
      \\[0.2cm]
      Wir berechnen daher in Zeile 20 zun\"{a}chst die Menge aller dieser Teilmengen.
\item Wir brauchen jetzt eine M\"{o}glichkeit, eine Teilmenge in eine Belegung umzuformen.
      In den Zeilen 3 -- 5 haben wir eine Prozedur implementiert, die genau dies
      leistet.  Um zu verstehen, wie diese Funktion arbeitet, betrachten wir ein Beispiel
      und nehmen an, dass wir aus der Menge \\[0.2cm]
      \hspace*{1.3cm} $m = \{\squote{a}, \squote{c} \}$ \\[0.2cm]
      eine Belegung $\mathcal{I}$ erstellen sollen.  Wir erhalten dann \\[0.2cm]
      \hspace*{1.3cm} 
      $\mathcal{I} = \{ \pair(\squote{a},\mathtt{true}), 
                        \pair(\squote{b},\mathtt{false}),
                        \pair(\squote{c},\mathtt{true}) 
       \bigr\}
      $. 
      \\[0.2cm]
      Das allgemeine Prinzip ist offenbar, dass f\"{u}r eine aussagenlogische Variable
      $x$ das Paar $\pair(x,\mathtt{true})$ genau dann in der Belegung $\mathcal{I}$
      enthalten ist, wenn $x \el m$ ist, andernfalls ist das Paar $\pair(x,\mathtt{false})$
      in $\mathcal{I}$.  Damit k\"{o}nnten wir die Menge aller Belegungen, die genau die
      Elemente aus $m$ wahrmachen, wie folgt schreiben:
      \\[0.2cm]
      \hspace*{1.3cm}      
      \texttt{\{ [ x, true ] : x in m \} + \{ [ x, false ] : x in all | !(x in m) \}}
      \\[0.2cm]
      Es geht aber einfacher, denn wir k\"{o}nnen beide F\"{a}lle zusammenfassen, indem wir fordern,
      dass das Paar $\pair(x, x \el m)$ ein Element der Belegung $\mathcal{I}$ ist. Genau
      das steht in Zeile 5.
\item In Zeile 23 sammeln wir in der Menge $b$ alle m\"{o}glichen Belegungen auf.
\item In Zeile 24 berechnen wir die Menge $s$ aller der Belegungen $i$, f\"{u}r die alle 
      Formeln aus der Menge $\textsl{fs}$ wahr werden. 
\item Falls es genau eine Belegung gibt, die alle Formeln wahr macht, 
      dann haben wir das Problem l\"{o}sen k\"{o}nnen.  In diesem Fall
      extrahieren wir in Zeile 26 diese Belegungen aus der Menge $s$ und geben
      anschlie\3emd die Menge der T\"{a}ter aus.
\end{enumerate}
Lassen wir das Programm laufen, so erhalten wir als Ausgabe
\begin{verbatim}
    Set of offenders: {"b", "c"}
\end{verbatim}
Damit liefern unsere urspr\"{u}nglichen Formeln ausreichende Information um die T\"{a}ter zu \"{u}berf\"{u}hren:
Bruno und Claus sind schuldig.


\section{Tautologien}
Die Tabelle in Abbildung \ref{tab:tautologie} zeigt, dass die Formel
$$  (p \rightarrow q) \rightarrow (\neg p \rightarrow q) \rightarrow q $$
f\"{u}r jede aussagenlogische Interpretation wahr ist, denn in der letzten Spalte dieser Tabelle steht immer der
Wert \texttt{true}.  Formeln mit dieser Eigenschaft  bezeichnen wir als \emph{Tautologie}.
\begin{Definition}[Tautologie]
  Ist $f$ eine aussagenlogische Formel und gilt \\[0.2cm]
  \hspace*{1.3cm} $\mathcal{I}(f) = \mathtt{true}$ \quad f\"{u}r jede aussagenlogische Interpretation $\mathcal{I}$, \\[0.2cm]
  dann ist $f$ eine \colorbox{yellow}{\emph{Tautologie}}.  In diesem Fall schreiben wir \\[0.2cm]
  \hspace*{1.3cm} $\models f$.
  \eox
\end{Definition}

\noindent
Ist eine Formel $f$ eine Tautologie, so sagen wir auch, dass $f$
\colorbox{yellow}{\emph{allgemeing\"{u}ltig}} ist.

\noindent
\textbf{Beispiele}:
\begin{enumerate}
\item $\models p \vee \neg p$
\item $\models p \rightarrow p$
\item $\models p \wedge q \rightarrow p$
\item $\models p \rightarrow p \vee q$
\item $\models (p \rightarrow \falsum) \;\leftrightarrow\; \neg p$
\item $\models p \wedge q \;\leftrightarrow\; q \wedge p$
\end{enumerate}
Wir k\"{o}nnen die Tatsache, dass es sich bei diesen Formeln um Tautologien handelt, durch
eine Tabelle nachweisen, die analog zu der auf Seite \pageref{tab:tautologie} gezeigten
Tabelle \ref{tab:tautologie} aufgebaut ist.  Dieses Verfahren ist zwar konzeptuell sehr
einfach, allerdings zu ineffizient, wenn die Anzahl der aussagenlogischen Variablen gro\3
ist.  Ziel dieses Kapitels ist daher die Entwicklung eines effizienteren Verfahren.

Die letzten beiden Beispiele in der obigen Aufz\"{a}hlung geben Anlass zu einer neuen Definition.
\begin{Definition}[Ãquivalent]
  Zwei Formeln $f$ und $g$ hei\3en \colorbox{yellow}{\emph{\"{a}quivalent}} g.d.w.  \\[0.2cm]
  \hspace*{1.3cm} $\models f \leftrightarrow g$ 
  \\[0.1cm]
  gilt.
  \eox
\end{Definition}

\noindent
\textbf{Beispiele}:  Es gelten die folgenden \"{A}quivalenzen: \\[0.3cm]
\hspace*{0.3cm} 
$\begin{array}{lll}
\models \neg \falsum \leftrightarrow \verum & \models \neg \verum \leftrightarrow \falsum &  \\[0.2cm]
 \models p \vee   \neg p \leftrightarrow \verum & \models p \wedge \neg p \leftrightarrow \falsum & \mbox{Tertium-non-Datur} \\[0.2cm]
 \models p \vee   \falsum \leftrightarrow p & \models p \wedge \verum  \leftrightarrow p & \mbox{Neutrales Element}\\[0.2cm]
 \models p \vee   \verum  \leftrightarrow \verum & \models p \wedge \falsum \leftrightarrow \falsum &  \\[0.2cm]
 \models p \wedge p \leftrightarrow p  & \models p \vee p \leftrightarrow p &  \mbox{Idempotenz} \\[0.2cm]
 \models p \wedge q \leftrightarrow q \wedge p & \models p \vee   q \leftrightarrow q \vee p & \mbox{Kommutativit\"{a}t} \\[0.2cm]
 \models (p \wedge q) \wedge r \leftrightarrow p \wedge (q \wedge r) & \models (p \vee   q) \vee r \leftrightarrow p \vee   (q \vee r)  &
 \mbox{Assoziativit\"{a}t} \\[0.2cm]
 \models \neg \neg p \leftrightarrow p & & \mbox{Elimination von $\neg \neg$} \\[0.2cm]
 \models p \wedge (p \vee q)   \leftrightarrow p & \models p \vee   (p \wedge q) \leftrightarrow p &  \mbox{Absorption} \\[0.2cm]
 \models p \wedge (q \vee r)   \leftrightarrow (p \wedge q) \vee   (p \wedge r) & 
 \models p \vee   (q \wedge r) \leftrightarrow (p \vee q)   \wedge (p \vee   r) & \mbox{Distributivit\"{a}t} \\[0.2cm]
 \models \neg (p \wedge q) \leftrightarrow  \neg p \vee   \neg q &  \models \neg (p \vee   q) \leftrightarrow  \neg p \wedge \neg q &
 \mbox{\colorbox{yellow}{DeMorgan'sche Regeln}}  \\[0.2cm]
 \models (p \rightarrow q) \leftrightarrow \neg p \vee q & &  \mbox{Elimination von $\rightarrow$} \\[0.2cm]
 \models (p \leftrightarrow q) \leftrightarrow (\neg p \vee q) \wedge (\neg q \vee p) & & \mbox{Elimination von $\leftrightarrow$}
\end{array}$ \\[0.3cm]
Wir k\"{o}nnen diese \"{A}quivalenzen nachweisen, indem wir in einer Tabelle s\"{a}mtliche Belegungen
durchprobieren.  Eine solche Tabelle hei\3t auch \emph{Wahrheits-Tafel}.
Wir demonstrieren dieses Verfahren anhand der ersten DeMorgan'schen Regel.
\begin{table}[!ht]
  \centering
\framebox{
  \begin{tabular}{|l|l|l|l|l|l|l|}
\hline
   $p$            & $q$            &  $\neg p$      &  $\neg q$    & $p \wedge q$   & $\neg (p \wedge q)$ & $\neg p \vee \neg q$ \\
\hline
\hline
   \texttt{true}  & \texttt{true}  & \texttt{false} & \texttt{false}  & \texttt{true}  & \texttt{false}  & \texttt{false}  \\
\hline
   \texttt{true}  & \texttt{false} & \texttt{false} & \texttt{true}  & \texttt{false} & \texttt{true}    & \texttt{true}  \\
\hline
   \texttt{false} & \texttt{true}  & \texttt{true}  & \texttt{false}  & \texttt{false} & \texttt{true}     & \texttt{true} \\
\hline
   \texttt{false} & \texttt{false} & \texttt{true}  & \texttt{true} & \texttt{false} & \texttt{true}     & \texttt{true}  \\
\hline
  \end{tabular}}
  \caption{Nachweis der ersten DeMorgan'schen Regel.}
  \label{tab:deMorgan}
\end{table}
Wir erkennen, dass in Abbildung \ref{tab:deMorgan} in den letzten beiden Spalten in jeder Zeile dieselben Werte
stehen.  Daher sind die Formeln, die zu diesen Spalten geh\"{o}ren, \"{a}quivalent.

\subsection{Testen der Allgemeing\"{u}ltigkeit in \textsc{SetlX}}
\noindent
 Die manuelle \"{U}berpr\"{u}fung der Frage, ob eine gegebene Formel $f$ eine Tautologie ist, 
l\"{a}uft auf die Erstellung umfangreicher Wahrheitstafeln heraus.   Solche Wahrheitstafeln
von Hand zu erstellen ist viel zu zeitaufwendig. 
Wir wollen daher nun ein \textsc{SetlX}-Programm entwickeln, mit dessen Hilfe wir die
obige Frage automatisch beantworten k\"{o}nnen.   Die Grundidee ist, dass wir die zu untersuchende
Formel f\"{u}r alle m\"{o}glichen Belegungen auswerten und \"{u}berpr\"{u}fen, dass sich bei der Auswertung
jedesmal der Wert \texttt{true} ergibt.  Dazu m\"{u}ssen wir zun\"{a}chst einen Weg finden, alle
m\"{o}glichen Belegungen einer Formel zu berechnen.  Wir haben fr\"{u}her schon gesehen, dass
Belegungen $\mathcal{I}$ zu Teilmengen $M$ der Menge der aussagenlogischen Variablen
$\mathcal{P}$ korrespondieren, denn f\"{u}r jedes $M \subseteq \mathcal{P}$ k\"{o}nnen wir eine
aussagenlogische Belegung $\mathcal{I}(M)$ wie folgt definieren:
\\[0.2cm]
\hspace*{1.3cm}
$\mathcal{I}(M)(p) := \left\{
\begin{array}[c]{ll}
  \mathtt{true}  & \mbox{falls $p \in M$;} \\
  \mathtt{false} & \mbox{falls $p \notin M$.}
\end{array}
\right.
$
\\[0.2cm]
Um die aussagenlogische Belegung $\mathcal{I}$ in \textsc{SetlX} darstellen zu k\"{o}nnen,
fassen wir die Belegung $\mathcal{I}$ als links-totale und rechts-eindeutige Relation
$\mathcal{I} \subseteq \mathcal{P} \times \mathbb{B}$ auf.  Dann haben wir
\\[0.2cm]
\hspace*{1.3cm}
$\mathcal{I} = \bigl\{ \pair(p, \mathtt{true} ) \mid p \in    M \bigr\} \cup 
               \bigl\{ \pair(p, \mathtt{false}) \mid p \notin M \bigr\}
$.
\\[0.2cm]
Dies l\"{a}sst sich noch zu
\\[0.2cm]
\hspace*{1.3cm}
$\mathcal{I} = \bigl\{ \langle p, p \el M\rangle \mid  p \in \mathcal{P} \bigr\}$
\\[0.2cm]
vereinfachen.  Mit dieser Idee k\"{o}nnen wir nun eine Prozedur implementieren, die f\"{u}r eine
gegebene aussagenlogische Formel $f$ testet, of $f$ eine Tautologie ist.

\begin{figure}[!ht]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.0cm,
                  xrightmargin  = 0.0cm
                ]
    tautology := procedure(f) {
        p := collectVars(f);
        // a is the set of all propositional valuations.
        a := { { [x, x in m] : x in p } : m in 2 ** p };
        if (forall (i in a | evaluate(f, i))) {
            return {};
        } else {
            return arb({ i in a | !evaluate(f, i) });
        }
    };
    collectVars := procedure(f) {
        match (f) {
            case true:         return {};
            case false:        return {};
            case ^variable(p): return { p };
            case !g:           return collectVars(g);
            case g && h:       return collectVars(g) + collectVars(h);
            case g || h:       return collectVars(g) + collectVars(h);
            case g => h:       return collectVars(g) + collectVars(h);
            case g <==> h:     return collectVars(g) + collectVars(h);
            default:           abort("syntax error in collectVars($f$)");
        }
    };    
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{\"{U}berpr\"{u}fung der Allgemeing\"{u}ltigkeit einer aussagenlogischen Formel.}
  \label{fig:tautology.stlx}
\end{figure} 

\noindent
Die in Abbildung \ref{fig:tautology.stlx} auf Seite \pageref{fig:tautology.stlx}
gezeigte Funktion
\href{https://github.com/karlstroetmann/Logik/blob/master/SetlX/tautology.stlx}{\texttt{tautology}}
testet, ob die als Argument \"{u}bergebene
aussagenlogische Formel $f$ allgemeing\"{u}ltig ist.   
Die Prozedur verwendet die Funktion 
\href{https://github.com/karlstroetmann/Logik/blob/master/SetlX/evaluate.stlx}{\texttt{evaluate}}
aus dem in Abbildung
\ref{fig:evaluate.stlx} auf Seite \pageref{fig:evaluate.stlx} gezeigten Programm.
Wir diskutieren die Definition der Funktion $\textsl{tautology}$ nun Zeile f\"{u}r Zeile:
\begin{enumerate}
\item In Zeile 2 sammeln wir alle aussagenlogischen Variablen auf, die in der zu
      \"{u}berpr\"{u}fenden Formel auftreten.  Die dazu ben\"{o}tigte Prozedur \texttt{collectVars}
      ist in den Zeilen 11 -- 23 gezeigt.  Diese Prozedur ist durch Induktion \"{u}ber den
      Aufbau einer Formel definiert und liefert als Ergebnis die Menge aller Aussage-Variablen,
      die in der aussagenlogischen Formel $f$ auftreten.

      Es ist klar, das bei der Berechnung von ${\cal I}(f)$ f\"{u}r eine Formel $f$
      und eine aussagenlogische Interpretation ${\cal I}$ nur die Werte von
      ${\cal I}(p)$ eine Rolle spielen, f\"{u}r die die Variable $p$ in $f$
      auftritt.  Zur Analyse von $f$ k\"{o}nnen wir uns also auf aussagenlogische 
      Interpretationen  der Form \\[0.2cm]
      \hspace*{1.3cm} 
      ${\cal I}:\mathcal{P} \rightarrow \mathbb{B}$ \quad mit \quad $\mathcal{P} = \mathtt{collectVars}(f)$ 
      \\[0.2cm]
      beschr\"{a}nken.
\item In Zeile 4 berechnen wir die Menge aller aussagenlogischen
      Interpretationen \"{u}ber der Menge $\mathcal{P}$ der aussagenlogischen Variablen.  
      Wir berechnen f\"{u}r eine Menge $m$ von aussagenlogischen Variablen
      die Interpretation ${\cal I}(m)$ wie oben diskutiert mit Hilfe der Formel
      \\[0.2cm]
      \hspace*{1.3cm}
      ${\cal I}(m) := \{ \pair(x, x \!\in\! m) \mid x \in \mathcal{P} \}$.  
      \\[0.2cm]
      Betrachten wir zur Verdeutlichung als Beispiel die Formel \\[0.2cm]
      \hspace*{1.3cm} $\neg (p \wedge q) \leftrightarrow \neg p \vee \neg q$. \\[0.2cm]
      Die Menge $\mathcal{P}$ der aussagenlogischen Variablen, die in dieser Formel auftreten,
      ist \\[0.2cm]
      \hspace*{1.3cm} $\mathcal{P} = \{ p, q \}$. \\[0.2cm]
      Die Potenz-Menge der Menge $\mathcal{P}$ ist \\[0.2cm]
      \hspace*{1.3cm} $2^\mathcal{P} = \bigl\{ \{\}, \{p\}, \{q\}, \{p,q\} \bigr\}$. \\[0.2cm]
      Wir bezeichnen die vier Elemente dieser Menge mit $m_1$, $m_2$, $m_3$, $m_4$: \\[0.2cm]
      \hspace*{1.3cm} $m_1 := \{\},\; m_2 :=\{p\},\; m_3 :=\{q\},\; m_4 :=\{p,q\}$. \\[0.2cm]
      Aus jeder dieser Mengen $m_i$ gewinnen wir nun eine aussagenlogische Interpretation 
      $\mathcal{I}(m_i)$: 

      ${\cal I}(m_1) := \bigl\{ \bigl\langle x, x \!\in\! \{\} \bigl\rangle\, |\, x \!\in\! \{p,q\} = \bigl\{ \bigl\langle p, p \!\in\! \{\} \bigl\rangle,\, \bigl\langle q, q \!\in\! \{\} \bigl\rangle \bigr\} = \bigl\{ \bigl\langle p, \mathtt{false} \bigl\rangle,\, \bigl\langle q, \mathtt{false} \bigl\rangle \bigr\}$.

      $\mathcal{I}(m_2) := \bigl\{ \bigl\langle x, x \!\in\! \{p\} \bigl\rangle\, |\, x \!\in\! \{p,q\} \bigr\} = \bigl\{ \bigl\langle p, p \!\in\! \{p\} \bigl\rangle,\, \bigl\langle q, q \!\in\! \{p\} \bigl\rangle \bigr\} = \bigl\{ \bigl\langle p, \mathtt{true} \bigl\rangle,\, \bigl\langle q, \mathtt{false} \bigl\rangle \bigr\}$.

      ${\cal I}(m_3) := \bigl\{ \bigl\langle x, x \!\in\! \{q\} \bigl\rangle\, |\, x \!\in\! \{p,q\} \bigr\} = \bigl\{ \bigl\langle p, p \!\in\! \{q\} \bigl\rangle,\, \bigl\langle q, q \!\in\! \{q\} \bigl\rangle \bigr\} = \bigl\{ \bigl\langle p, \mathtt{false} \bigl\rangle,\, \bigl\langle q, \mathtt{true} \bigl\rangle \bigr\}$.

      ${\cal I}(m_4) := \bigl\{ \bigl\langle x, x \!\in\! \{p,q\} \bigl\rangle\, |\, x \!\in\! \{p,q\} \bigr\} = \bigl\{ \bigl\langle p, p \!\in\! \{p,q\} \bigl\rangle,\, \bigl\langle q, q \!\in\! \{p,q\} \bigl\rangle \bigr\} = \bigl\{ \bigl\langle p, \mathtt{true} \bigl\rangle,\, \bigl\langle q, \mathtt{true} \bigl\rangle \bigr\}$.

      damit haben wir alle m\"{o}glichen Interpretationen der Variablen $p$ und $q$. 
\item In Zeile 5 testen wir, ob die Formel $f$ f\"{u}r alle m\"{o}glichen Interpretationen $i$
      aus der Menge $a$ aller Interpretationen wahr ist.  Ist dies der Fall,
      so geben wir die leere Menge als Ergebnis zur\"{u}ck.

      Falls es allerdings eine Belegungen $i$ in der Menge $a$ gibt, f\"{u}r die die
      Auswertung von $f$ den Wert \textsl{false} liefert, so bilden wir in Zeile 8 die
      Menge aller solcher Belegungen und w\"{a}hlen mit Hilfe der Funktion
      $\textsl{arb}$ eine beliebige Belegungen aus dieser Menge aus, die wir dann
      als Gegenbeispiel zur\"{u}ck geben.
\end{enumerate}

\subsection{Nachweis der Allgemeing\"{u}ltigkeit durch \"{A}quivalenz-Umformungen}
Wollen wir nachweisen, dass eine Formel eine Tautologie ist, k\"{o}nnen wir uns prinzipiell
immer einer Wahrheits-Tafel bedienen. 
Aber diese Methode hat einen Haken: Kommen in der Formel $n$
verschiedene Aussage-Variablen vor, so hat die Tabelle $2^n$ Zeilen.  Beispielsweise hat
die Tabelle zum Nachweis eines der Distributiv-Gesetze bereits 
$8$ Zeilen, da hier 3 verschiedene Variablen auftreten.
Eine andere M\"{o}glichkeit nachzuweisen, dass eine Formel eine Tautologie ist, ergibt sich dadurch, dass wir
die Formel mit Hilfe der oben aufgef\"{u}hrten \"{A}quivalenzen \emph{vereinfachen}.  Wenn es gelingt, eine Formel $F$ unter Verwendung
dieser \"{A}quivalenzen zu $\verum$ zu vereinfachen, dann ist gezeigt, dass $F$ eine Tautologie ist.  
Wir demonstrieren das Verfahren zun\"{a}chst an einem Beispiel. 
Mit Hilfe einer Wahrheits-Tafel hatten wir schon gezeigt, dass die Formel \\[0.2cm]
\hspace*{1.3cm} $(p \rightarrow q) \rightarrow (\neg p \rightarrow q) \rightarrow q$ \\[0.2cm]
eine Tautologie ist.  Wir zeigen nun, wie wir diesen Tatbestand auch durch eine Kette von
\"{A}quivalenz-Umformungen einsehen k\"{o}nnen:\\[0.2cm]
\hspace*{1.3cm} 
$ 
\begin{array}[c]{lcr}
                 & (p \rightarrow q) \rightarrow (\neg p \rightarrow q) \rightarrow q  & \quad(\mbox{Elimination von $\rightarrow$}) \\    
 \leftrightarrow & (\neg p \vee q) \rightarrow (\neg p \rightarrow q) \rightarrow q    & \quad(\mbox{Elimination von $\rightarrow$})\\     
 \leftrightarrow & (\neg p \vee q) \rightarrow (\neg \neg p \vee q) \rightarrow q      & \quad(\mbox{Elimination der Doppelnegation})\\    
 \leftrightarrow & (\neg p \vee q) \rightarrow (p \vee q) \rightarrow q                & \quad(\mbox{Elimination von $\rightarrow$})\\     
 \leftrightarrow & \neg(\neg p \vee q) \vee ((p \vee q) \rightarrow q)                 & \quad(\mbox{DeMorgan})\\                          
 \leftrightarrow & (\neg\neg p \wedge \neg q) \vee ((p \vee q) \rightarrow q)          & \quad(\mbox{Elimination der Doppelnegation})\\    
 \leftrightarrow & (p \wedge \neg q) \vee ((p \vee q) \rightarrow q)                   & \quad(\mbox{Elimination von $\rightarrow$})\\     
 \leftrightarrow & (p \wedge \neg q) \vee (\neg(p \vee q) \vee q)                      & \quad(\mbox{DeMorgan})\\                          
 \leftrightarrow & (p \wedge \neg q) \vee ((\neg p \wedge \neg q) \vee q)              & \quad(\mbox{Distributivit\"{a}t}) \\
 \leftrightarrow & (p \wedge \neg q) \vee ((\neg p \vee q) \wedge (\neg q \vee q))     & \quad(\mbox{Tertium-non-Datur})\\               
 \leftrightarrow & (p \wedge \neg q) \vee ((\neg p \vee q) \wedge \verum)                & \quad(\mbox{Neutrales Element})\\                 
 \leftrightarrow & (p \wedge \neg q) \vee (\neg p \vee q)                              & \quad(\mbox{Distributivit\"{a}t})\\                   
 \leftrightarrow & (p \vee (\neg p \vee q)) \wedge (\neg q \vee (\neg p \vee q))       & \quad(\mbox{Assoziativit\"{a}t}) \\                   
 \leftrightarrow & ((p \vee \neg p) \vee q) \wedge (\neg q \vee (\neg p \vee q))       & \quad(\mbox{Tertium-non-Datur})\\               
 \leftrightarrow & (\verum \vee q) \wedge (\neg q \vee (\neg p \vee q))                  & \quad(\mbox{Neutrales Element}) \\                
 \leftrightarrow & \verum \wedge (\neg q \vee (\neg p \vee q))                           & \quad(\mbox{Neutrales Element}) \\                
 \leftrightarrow & \neg q \vee (\neg p \vee q)                                         & \quad(\mbox{Assoziativit\"{a}t})\\                    
 \leftrightarrow & (\neg q \vee \neg p) \vee q                                         & \quad(\mbox{Kommutativit\"{a}t})\\                    
 \leftrightarrow & (\neg p \vee \neg q) \vee q                                         & \quad(\mbox{Assoziativit\"{a}t})\\                    
 \leftrightarrow & \neg p \vee (\neg q  \vee q)                                        & \quad(\mbox{Tertium-non-Datur})\\               
 \leftrightarrow & \neg p \vee \verum                                                    & \quad(\mbox{Neutrales Element}) \\                
 \leftrightarrow & \verum \\
\end{array}
$

Die Umformungen in dem obigen Beweis sind nach einem bestimmten System durchgef\"{u}hrt worden.  Um dieses System
pr\"{a}zise formulieren zu k\"{o}nnen, ben\"{o}tigen wir noch einige Definitionen.

\begin{Definition}[Literal]
  Eine aussagenlogische Formel $f$ hei\3t \colorbox{yellow}{\emph{Literal}} g.d.w. einer der folgenden F\"{a}lle vorliegt:
  \begin{enumerate}
  \item $f = \verum$ oder $f = \falsum$.
  \item $f = p$, wobei $p$ eine aussagenlogische Variable ist.

        In diesem Fall sprechen wir von einem \colorbox{yellow}{\emph{positiven}} Literal.
  \item $f = \neg p$, wobei $p$ eine aussagenlogische Variable ist. 

        In diesem Fall sprechen wir von einem \colorbox{yellow}{\emph{negativen}} Literal.
  \end{enumerate}
  Die Menge aller Literale bezeichnen wir mit $\mathcal{L}$.
  \eox
\end{Definition}

Sp\"{a}ter werden wird noch den Begriff des \colorbox{yellow}{\emph{Komplements}} eines Literals ben\"{o}tigen.
Ist $l$ ein Literal, so wird das Komplement von $l$ mit $\komplement{\,l\,}$
bezeichnet.  Das Komplement wird durch Fall-Unterscheidung definiert:
\begin{enumerate}
\item $\komplement{\verum} = \falsum$ \quad und \quad $\komplement{\falsum} = \verum$. 
\item $\komplement{p} := \neg p$, \quad falls $p \in \mathcal{P}$.
\item $\komplement{\neg p} := p$, \quad falls $p \in \mathcal{P}$.
\end{enumerate}
Wir sehen, dass das Komplement $\komplement{\,l\,}$ eines Literals $l$ \"{a}quivalent zur
Negation von $l$ ist, wir haben also
\\[0.2cm]
\hspace*{1.3cm}
$\models \komplement{\,l\,} \leftrightarrow \neg l$.

\begin{Definition}[Klausel]
  Eine aussagenlogische Formel $k$ ist eine \colorbox{yellow}{\emph{Klausel}} wenn $k$ die Form \\[0.2cm]
  \hspace*{1.3cm} $k = l_1 \vee \cdots \vee l_r$ \\[0.2cm]
  hat, wobei $l_i$ f\"{u}r alle $i=1,\cdots,r$ ein Literal ist.  Eine Klausel ist also eine
  Disjunktion von Literalen. 
  Die Menge aller Klauseln bezeichnen wir mit $\mathcal{K}$.
  \eox
\end{Definition}

Oft werden Klauseln auch einfach als \emph{Mengen} von Literalen betrachtet.  
Durch diese Sichtweise abstrahieren wir von der Reihenfolge und der Anzahl des Auftretens
der Literale in der Disjunktion.  Dies ist m\"{o}glich aufgrund der Assoziativit\"{a}t, Kommutativit\"{a}t und
Idempotenz des Junktors ``$\vee$''.  F\"{u}r die Klausel $l_1 \vee \cdots \vee l_r$ schreiben
wir also in Zukunft auch 
\\[0.2cm]
\hspace*{1.3cm} $\{ l_1, \cdots, l_r \}$.
\\[0.2cm]
Das folgende Beispiel illustriert die N\"{u}tzlichkeit der Mengen-Schreibweise von Klauseln.
Wir betrachten die beiden Klauseln
\\[0.2cm]
\hspace*{1.3cm}
$p \vee q \vee \neg r \vee p$ \quad und \quad $\neg r \vee q \vee \neg r \vee p$. 
\\[0.2cm]
Die beiden Klauseln sind zwar \"{a}quivalent, aber die Formeln sind verschieden.
\"{U}berf\"{u}hren wir die beiden Klauseln in Mengen-Schreibweise, so erhalten wir
\\[0.2cm]
\hspace*{1.3cm}
$\{p, q, \neg r \}$ \quad und \quad $\{ \neg r, q, p \}$. 
\\[0.2cm]
In einer Menge kommt jedes Element h\"{o}chstens einmal vor und die Reihenfolge, in der die
Elemente auftreten, spielt auch keine Rolle.  Daher sind die beiden obigen Mengen gleich!
Durch die Tatsache, dass Mengen von der Reihenfolge und der Anzahl der Elemente
abstrahieren, implementiert die Mengen-Schreibweise die Assoziativit\"{a}t, Kommutativit\"{a}t und
Idempotenz der Disjunktion.  \"{U}ber\-tragen wir die  aussagenlogische \"{A}quivalenz
\\[0.2cm]
\hspace*{1.3cm}
$l_1 \vee \cdots \vee l_r \vee \falsum \leftrightarrow l_1 \vee \cdots \vee l_r$
\\[0.2cm]
in Mengen-Schreibweise, so erhalten wir
\\[0.2cm]
\hspace*{1.3cm}
$\{ l_1, \cdots, l_r, \falsum \} \leftrightarrow \{ l_1, \cdots, l_r \}$.
\\[0.2cm]
Dies zeigt, dass wir das Element $\falsum$ in einer Klausel getrost weglassen k\"{o}nnen.
Betrachten wir die letzten \"{A}quivalenz f\"{u}r den Fall, dass $r=0$ ist, so haben wir
\\[0.2cm]
\hspace*{1.3cm}
$\{\falsum \} \leftrightarrow \{\}$.
\\[0.2cm]
Damit sehen wir, dass die leere Menge von Literalen als $\falsum$ zu interpretieren ist.

\begin{Definition}
  Eine Klausel $k$ ist \colorbox{yellow}{\emph{trivial}}, wenn einer der beiden folgenden F\"{a}lle vorliegt:
  \begin{enumerate}
  \item $\verum \in k$.
  \item Es existiert $p \in \mathcal{P}$ mit $p \in k$ und $\neg p \in k$.

        In diesem Fall bezeichnen wir $p$ und $\neg p$ als \colorbox{yellow}{\emph{komplement\"{a}re Literale}}.
        \eox
\end{enumerate}
\end{Definition}

\begin{Satz} \label{satz:trivial}
  Eine Klausel ist genau dann eine Tautologie, wenn sie trivial ist.
\end{Satz}
\textbf{Beweis}:  Wir nehmen zun\"{a}chst an, dass die Klausel $k$ trivial ist.
Falls nun $\verum \el k$ ist, dann gilt wegen der G\"{u}ltigkeit der \"{A}quivalenz 
$f \vee \verum \leftrightarrow \verum$
offenbar $k \leftrightarrow \verum$.   Ist $p$ eine Aussage-Variable, so dass
sowohl $p \el k$ als auch $\neg p \el k$ gilt, dann folgt aufgrund der \"{A}quivalenz $p \vee
\neg p \leftrightarrow \verum$ sofort $k \leftrightarrow \verum$.

Wir nehmen nun an, dass die Klausel $k$ eine Tautologie ist.  Wir f\"{u}hren den Beweis
indirekt und nehmen an, dass $k$ nicht trivial ist.  Damit gilt  $\verum \notin k$ und
$k$ kann auch keine komplement\"{a}ren Literale enthalten.  Damit hat $k$ dann die Form
\\[0.2cm]
\hspace*{1.3cm} 
$k = \{ \neg p_1, \cdots, \neg p_m, q_1, \cdots, q_n \}$ \quad mit $p_i
\not= q_j$ f\"{u}r alle $i \in \{ 1,\cdots,m\}$ und $j \in \{1, \cdots, n\}$.
\\[0.2cm]
Dann k\"{o}nnten wir eine Interpretation $\mathcal{I}$ wie folgt definieren:
\begin{enumerate}
\item $\mathcal{I}(p_i) = \mathtt{true}$ f\"{u}r alle $i = 1, \cdots, m$ und
\item $\mathcal{I}(q_j) = \mathtt{false}$ f\"{u}r alle $j = 1, \cdots, n$,
\end{enumerate}
Mit dieser Interpretation w\"{u}rde offenbar $\mathcal{I}(k) = \mathtt{false}$ gelten und damit k\"{o}nnte $k$ keine
Tautologie sein.  Also ist die Annahme, dass $k$ nicht trivial ist, falsch.
\hspace*{\fill}  $\Box$

\begin{Definition}[Konjunktive Normalform]  
  Eine Formel $f$ ist in \colorbox{yellow}{\emph{konjunktiver Normalform}} (kurz KNF)
  genau dann, wenn $f$ eine Konjunktion von Klauseln ist, wenn also gilt \\[0.2cm]
  \hspace*{1.3cm} $f = k_1 \wedge \cdots \wedge k_n$, \\[0.2cm]
  wobei die $k_i$ f\"{u}r alle $i=1,\cdots,n$ Klauseln sind. \eox
\end{Definition}

\noindent
Aus der Definition der KNF folgt sofort:
\begin{Korollar} \label{korollar:knf}
  Ist $f = k_1 \wedge \cdots \wedge k_n$ in konjunktiver Normalform, so gilt\\[0.2cm]
  \hspace*{1.3cm} $\models f$ \quad genau dann, wenn \quad $\models k_i$ \quad f\"{u}r alle $i=1,\cdots,n$. \qed
\end{Korollar}

Damit k\"{o}nnen wir f\"{u}r eine Formel $f = k_1 \wedge \cdots \wedge k_n$ in konjunktiver
Normalform leicht entscheiden, ob $f$ eine Tautologie ist, denn $f$ ist genau dann eine
Tautologie, wenn alle Klauseln $k_i$ trivial sind.
\vspace*{0.2cm}

Da f\"{u}r die Konjunktion genau wie f\"{u}r die Disjunktion Assoziativit-Gesetz, Kommutativ-Gesetz und
Idempotenz-Gesetz gilt, ist es zweckm\"{a}\3ig, auch f\"{u}r Formeln in konjunktiver Normalform eine
Mengen-Schreibweise einzuf\"{u}hren.  Ist also die Formel
\\[0.2cm]
\hspace*{1.3cm} $f = k_1 \wedge \cdots \wedge k_n$
\\[0.2cm]
in konjunktiver Normalform, so repr\"{a}sentieren wir diese
Formel  durch die Menge ihrer Klauseln und schreiben \\[0.2cm]
\hspace*{1.3cm} $f = \{ k_1, \cdots, k_n \}$. 
\\[0.2cm]
Wir geben ein Beispiel:  Sind $p$, $q$ und $r$ Aussage-Variablen, so ist die Formel
\\[0.2cm]
\hspace*{1.3cm}
$(p \vee q \vee \neg r) \wedge (q \vee \neg r \vee p \vee q)\wedge (\neg r \vee p \vee \neg q)$
\\[0.2cm]
in konjunktiver Normalform.  In Mengen-Schreibweise wird daraus
\\[0.2cm]
\hspace*{1.3cm}
$\bigl\{ \{p, q, \neg r \},\, \{ p, \neg q, \neg r \} \bigr\}$.
\\[0.2cm]
Wir stellen nun ein Verfahren vor, mit dem sich jede Formel in KNF transformieren l\"{a}sst.  Nach
dem oben Gesagten k\"{o}nnen wir dann leicht entscheiden, ob $f$ eine Tautologie ist.
\begin{enumerate}
\item Eliminiere alle Vorkommen des Junktors ``$\leftrightarrow$'' mit Hilfe der \"{A}quivalenz \\[0.2cm]
      \hspace*{1.3cm} 
      $(f \leftrightarrow g) \leftrightarrow (f \rightarrow g) \wedge (g \rightarrow f)$
\item Eliminiere alle Vorkommen des Junktors ``$\rightarrow$'' mit Hilfe der \"{A}quivalenz \\[0.2cm]
      \hspace*{1.3cm} 
      $(f \rightarrow g) \leftrightarrow \neg f \vee g$
\item Schiebe die Negationszeichen soweit es geht nach innen.  Verwende dazu die folgenden \"{A}quivalenzen:
      \begin{enumerate}
      \item $\neg \falsum \leftrightarrow \verum$
      \item $\neg \verum \leftrightarrow \falsum$
      \item $\neg \neg f \leftrightarrow f$
      \item $\neg (f \wedge g) \leftrightarrow  \neg f \vee   \neg g$ 
      \item $\neg (f \vee   g) \leftrightarrow  \neg f \wedge \neg g$ 
      \end{enumerate}
      In dem Ergebnis, das wir nach diesem Schritt erhalten, stehen die Negationszeichen
      nur noch unmittelbar vor den aussagenlogischen Variablen.  Formeln mit dieser
      Eigenschaft bezeichnen wir auch als Formeln in \colorbox{yellow}{\emph{Negations-Normalform}}.
\item Stehen in der Formel jetzt ``$\vee$''-Junktoren \"{u}ber ``$\wedge$''-Junktoren, so k\"{o}nnen wir durch
      \emph{Ausmultiplizieren}, sprich Verwendung der Distributiv-Gesetze \\[0.2cm]
      \hspace*{1.3cm} 
      $f \vee (g \wedge h) \leftrightarrow (f \vee g) \wedge (f \vee h)$ \quad und \quad
      $(f \wedge g) \vee h \leftrightarrow (f \vee h) \wedge (g \vee h)$ 
      \\[0.2cm]
      diese Junktoren nach innen schieben.
\item In einem letzten Schritt \"{u}berf\"{u}hren wir die Formel nun in Mengen-Schreibweise, indem
      wir zun\"{a}chst die Disjunktionen aller Literale als Mengen zusammenfassen und anschlie\3end
      alle so entstandenen Klauseln wieder in einer Menge zusammen fassen.
\end{enumerate}
Hier sollten wir noch bemerken, dass die Formel beim Ausmultiplizieren stark anwachsen kann.
Das liegt daran, dass die Formel $f$ auf der rechten Seite der \"{A}quivalenz 
$f \vee (g \wedge h) \leftrightarrow (f \vee g) \wedge (f \vee h)$ zweimal auftritt, w\"{a}hrend sie
links nur einmal      vorkommt. 

Wir demonstrieren das Verfahren am Beispiel der Formel\\[0.2cm]
\hspace*{1.3cm} $(p \rightarrow q) \rightarrow (\neg p \rightarrow \neg q)$.
\begin{enumerate}
\item Da die Formel den Junktor ``$\leftrightarrow$'' nicht enth\"{a}lt,
      ist im ersten Schritt nichts zu tun.
\item Die Elimination von ``$\rightarrow$'' liefert \\[0.2cm]
      \hspace*{1.3cm} $\neg (\neg p \vee q) \vee (\neg \neg p \vee \neg q)$.
\item Die Umrechnung auf Negations-Normalform liefert \\[0.2cm]
      \hspace*{1.3cm} $(p \wedge \neg q) \vee (p \vee \neg q)$.
\item Durch ``Ausmultiplizieren'' erhalten wir \\[0.2cm]
      \hspace*{1.3cm} $(p \vee (p \vee \neg q)) \wedge (\neg q \vee (p \vee \neg q))$.
\item Die \"{U}berf\"{u}hrung in die Mengen-Schreibweise ergibt zun\"{a}chst als Klauseln die beiden Mengen \\[0.2cm]
      \hspace*{1.3cm} $\{p, p, \neg q\}$ \quad und \quad $\{\neg q,  p,  \neg q\}$. \\[0.2cm]
      Da die Reihenfolge der Elemente einer Menge aber unwichtig ist und au\3erdem eine Menge
      jedes Element nur einmal enth\"{a}lt, stellen wir fest, dass diese beiden Klauseln gleich sind.
      Fassen wir jetzt die Klauseln noch in einer Menge zusammen, so erhalten wir \\[0.2cm]
      \hspace*{1.3cm} $\bigl\{ \{p, \neg q\} \bigr\}$. \\[0.2cm]
      Beachten Sie, dass sich die Formel durch die \"{U}berf\"{u}hrung in 
      Mengen-Schreibweise noch einmal deutlich vereinfacht hat.
\end{enumerate}
Damit ist die Formel in KNF \"{u}berf\"{u}hrt.

\subsection{Berechnung der konjunktiven Normalform in \textsc{SetlX}}
Wir geben nun eine Reihe von Prozeduren an, mit deren Hilfe sich eine gegebene
Formel $f$ in konjunktive Normalform \"{u}berf\"{u}hren l\"{a}sst.  Wir beginnen mit einer
Prozedur 
\\[0.2cm]
\hspace*{1.3cm}
$\texttt{elimGdw}: \mathcal{F} \rightarrow \mathcal{F}$
\\[0.2cm]
die die Aufgabe hat, eine vorgegebene aussagenlogische Formel $f$ in eine \"{a}quivalente Formel
umzuformen, die den Junktor ``$\leftrightarrow$'' nicht mehr enth\"{a}lt.  Die Funktion
$\texttt{elimGdw}(f)$ wird durch Induktion \"{u}ber den Aufbau der aussagenlogischen Formel $f$ definiert.
Dazu stellen wir zun\"{a}chst rekursive Gleichungen auf,
die das Verhalten der Funktion $\texttt{elimGdw}()$ beschreiben:
\begin{enumerate}
\item Wenn $f$ eine
      Aussage-Variable $p$ ist, so ist nichts zu tun:
      \\[0.2cm]
      \hspace*{1.3cm}
      $\mathtt{elimGdw}(p) = p$ \quad f\"{u}r alle $p \in \mathcal{P}$.
\item Hat $f$ die Form $f = \neg g$, so eliminieren wir den Junktor
      ``$\leftrightarrow$'' aus der Formel $g$: \\[0.2cm]
      \hspace*{1.3cm} 
      $\mathtt{elimGdw}(\neg g) = \neg \mathtt{elimGdw}(g)$.
\item Im Falle $f = g_1 \wedge g_2$ eliminieren wir den Junktor
      ``$\leftrightarrow$'' aus den Formeln $g_1$ und $g_2$: \\[0.2cm]
      \hspace*{1.3cm} 
      $\mathtt{elimGdw}(g_1 \wedge g_2) = \mathtt{elimGdw}(g_1) \wedge \mathtt{elimGdw}(g_2)$.
\item Im Falle $f = g_1 \vee g_2$ eliminieren wir den Junktor
      ``$\leftrightarrow$'' aus den Formeln $g_1$ und $g_2$: \\[0.2cm]
      \hspace*{1.3cm} 
      $\mathtt{elimGdw}(g_1 \vee g_2) = \mathtt{elimGdw}(g_1) \vee \mathtt{elimGdw}(g_2)$.
\item Im Falle $f = g_1 \rightarrow g_2$ eliminieren wir den Junktor
      ``$\leftrightarrow$'' aus den Formeln $g_1$ und $g_2$: \\[0.2cm]
      \hspace*{1.3cm} 
      $\mathtt{elimGdw}(g_1 \rightarrow g_2) = \mathtt{elimGdw}(g_1) \rightarrow \mathtt{elimGdw}(g_2)$.
\item Hat $f$ die Form $f = g_1 \leftrightarrow g_2$, so benutzen wir die
      \"{A}quivalenz \\[0.2cm]
      \hspace*{1.3cm} 
      $(g_1 \leftrightarrow g_2) \leftrightarrow \bigl( (g_1 \rightarrow g_2) \wedge (g_2 \rightarrow g_1)\bigr)$.
      \\[0.2cm]
      Das f\"{u}hrt auf die Gleichung:
      \\[0.2cm]
      \hspace*{1.3cm} 
      $\mathtt{elimGdw}(g_1 \leftrightarrow g_2) = \mathtt{elimGdw}\bigl( (g_1 \rightarrow g_2) \wedge (g_2 \rightarrow g_1)\bigr)$. 
      \\[0.2cm]
      Der Aufruf von \texttt{elimGdw} auf der rechten Seite der Gleichung ist notwendig,
      denn der Junktor ``$\leftrightarrow$'' kann ja noch in $g_1$ und $g_2$ auftreten.
\end{enumerate}
Abbildung
\ref{fig:eliminate-gdw} auf Seite \pageref{fig:eliminate-gdw} zeigt die Implementierung der
Prozedur 
\href{https://github.com/karlstroetmann/Logik/blob/master/SetlX/knf.stlx}{\texttt{elimGdw}}.

\begin{figure}[!ht]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.0cm,
                  xrightmargin  = 0.0cm
                ]
    elimGdw := procedure(f) {
        match (f) {
            case !g       : return !elimGdw(g);
            case g && h   : return elimGdw(g) && elimGdw(h);
            case g || h   : return elimGdw(g) || elimGdw(h);
            case g => h   : return elimGdw(g) => elimGdw(h);
            case g <==> h : return elimGdw((g => h) && (h => g));
            default       : return f; 
        }
    };
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{Elimination von $\leftrightarrow$.}
  \label{fig:eliminate-gdw}
\end{figure} 

Als n\"{a}chstes betrachten wir die Prozedur zur Elimination des Junktors ``$\rightarrow$''. 
Abbildung
\ref{fig:eliminate-folgt} auf Seite \pageref{fig:eliminate-folgt} zeigt die
Implementierung der Funktion
\href{https://github.com/karlstroetmann/Logik/blob/master/SetlX/knf.stlx}{\texttt{elimFolgt}}.
Die der Implementierung zu Grunde liegende Idee ist dieselbe wie bei der Elimination des
Junktors ``$\leftrightarrow$''.  Der einzige Unterschied besteht darin, dass wir jetzt die
\"{A}quivalenz \\[0.2cm]
\hspace*{1.3cm} $(g_1 \rightarrow g_2) \leftrightarrow (\neg g_1 \vee g_2)$ \\[0.2cm]
benutzen.  Au\3erdem k\"{o}nnen wir schon voraussetzen, dass der Junktor ``$\leftrightarrow$''
bereits vorher eliminiert wurde.  Dadurch entf\"{a}llt ein Fall.

\begin{figure}[!ht]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.0cm,
                  xrightmargin  = 0.0cm
                ]
    elimFolgt := procedure(f) {
        match (f) {
            case !g     : return !elimFolgt(g);
            case g && h : return  elimFolgt(g) && elimFolgt(h);
            case g || h : return  elimFolgt(g) || elimFolgt(h);
            case g => h : return !elimFolgt(g) || elimFolgt(h);
            default     : return f; 
        }
    };
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{Elimination von $\rightarrow$.}
  \label{fig:eliminate-folgt}
\end{figure}
 
Als n\"{a}chstes zeigen wir die Routinen zur Berechnung der Negations-Normalform.
Abbildung
\ref{fig:nnf} auf Seite \pageref{fig:nnf} zeigt die Implementierung der Funktionen
\href{https://github.com/karlstroetmann/Logik/blob/master/SetlX/knf.stlx}{\texttt{nnf}} und
\href{https://github.com/karlstroetmann/Logik/blob/master/SetlX/knf.stlx}{\texttt{neg}},
die sich wechselseitig aufrufen.  Dabei berechnet \texttt{neg($f$)}
die Negations-Normalform von $\neg f$, w\"{a}hrend \texttt{nnf($f$)} die
Negations-Normalform von $f$ berechnet, es gilt also
\\[0.2cm]
\hspace*{1.3cm}
$\mathtt{neg}(f) = \mathtt{nnf}(\neg f)$.
\\[0.2cm]
  Die eigentliche Arbeit wird dabei in der
Funktion \texttt{neg} erledigt, denn dort kommen die beiden DeMorgan'schen Gesetze \\[0.2cm]
\hspace*{1.3cm} $\neg (f \wedge g) \leftrightarrow (\neg f \vee \neg g)$ \quad und \quad $\neg (f \vee g) \leftrightarrow (\neg f \wedge \neg g)$ \\[0.2cm]
zur Anwendung.  Wir beschreiben die Umformung in Negations-Normalform durch 
die folgenden Gleichungen:
\begin{enumerate}
\item $\texttt{nnf}(\neg f) = \mathtt{neg}(f)$,
\item $\texttt{nnf}(f_1 \wedge f_2) = \mathtt{nnf}(f_1) \wedge \mathtt{nnf}(f_2)$,
\item $\texttt{nnf}(f_1 \vee f_2) = \mathtt{nnf}(f_1) \vee \mathtt{nnf}(f_2)$.
\end{enumerate}
Die Hilfsprozedur \texttt{neg}, die die Negations-Normalform von $\neg f$ berechnet,
spezifizieren wir ebenfalls durch rekursive Gleichungen:
\begin{enumerate}
\item $\texttt{neg}(p) = \mathtt{nnf}(\neg p) = \neg p$ f\"{u}r alle Aussage-Variablen $p$,
\item $\texttt{neg}(\neg f) = \mathtt{nnf}(\neg \neg f) = \mathtt{nnf}(f)$,
\item $\begin{array}[t]{cl}
         & \texttt{neg}\bigl(f_1 \wedge f_2 \bigr) \\[0.1cm]
       = & \mathtt{nnf}\bigl(\neg(f_1 \wedge f_2)\bigr) \\[0.1cm]
       = & \mathtt{nnf}\bigl(\neg f_1 \vee \neg f_2\bigr) \\[0.1cm]
       = & \mathtt{nnf}\bigl(\neg f_1\bigr) \vee \mathtt{nnf}\bigl(\neg f_2\bigr) \\[0.1cm]
       = & \mathtt{neg}(f_1) \vee \mathtt{neg}(f_2),
       \end{array}
      $
\item $\begin{array}[t]{cl}
         & \texttt{neg}\bigl(f_1 \vee f_2 \bigr)        \\[0.1cm]
       = & \texttt{nnf}\bigl(\neg(f_1 \vee f_2) \bigr)  \\[0.1cm]
       = & \texttt{nnf}\bigl(\neg f_1 \wedge \neg f_2 \bigr)  \\[0.1cm]
       = & \texttt{nnf}\bigl(\neg f_1\bigr) \wedge \mathtt{nnf}\bigl(\neg f_2 \bigr)  \\[0.1cm]
       = & \mathtt{neg}(f_1) \wedge \mathtt{neg}(f_2). 
       \end{array}
      $
\end{enumerate}

\begin{figure}[!ht]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  xleftmargin   = 0.0cm,
                  xrightmargin  = 0.0cm,
                  numbers       = left,
                  numbersep     = -0.2cm,
                ]
    nnf := procedure(f) {
        match (f) {
            case !g     : return neg(g);
            case g && h : return nnf(g) && nnf(h);
            case g || h : return nnf(g) || nnf(h);
            default     : return f; 
        }
    };
    neg := procedure(f) {
        match (f) {
            case !g     : return nnf(g);
            case g && h : return neg(g) || neg(h);
            case g || h : return neg(g) && neg(h);
            default     : return !f; 
        }
    };
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{Berechnung der Negations-Normalform.}
  \label{fig:nnf}
\end{figure}


Als letztes stellen wir die Prozeduren vor, mit denen die Formeln, die bereits in
Negations-Normalform sind, ausmultipliziert und dadurch in konjunktive
Normalform gebracht werden.  Gleichzeitig werden  die zu normalisierende Formel dabei
in die Mengen-Schreibweise transformiert, d.h.~die Formeln werden als Mengen von Mengen 
von Literalen dargestellt.  Dabei interpretieren wir eine Menge von Literalen als
Disjunktion der Literale und eine Menge von Klauseln interpretieren wir als Konjunktion
der Klauseln.
Abbildung \ref{fig:knf} auf Seite \pageref{fig:knf} zeigt die Implementierung der Funktion
\href{https://github.com/karlstroetmann/Logik/blob/master/SetlX/knf.stlx}{\texttt{knf}}.
\begin{enumerate}
\item Falls die Formel $f$, die wir in KNF transformieren wollen, die Form \\[0.2cm]
      \hspace*{1.3cm} $f = \neg g$ \\[0.2cm]
      hat, so muss $g$ eine Aussage-Variable sein, denn $f$ ist ja bereits in
      Negations-Normalform.  Damit k\"{o}nnen wir $f$ in eine Klausel transformieren, 
      indem wir $\{\neg g\}$, also $\{f\}$ schreiben.  
      Da eine KNF eine Menge von Klauseln ist, ist dann 
      $\bigl\{\{f\}\bigr\}$ das Ergebnis, das wir in Zeile 3 zur\"{u}ck geben.
\item Falls $f= f_1 \wedge f_2$ ist, transformieren wir zun\"{a}chst $f_1$ und $f_2$ in KNF.
      Dabei erhalten wir \\[0.2cm]
      \hspace*{1.3cm} 
      $\mathtt{knf}(f_1) = \{ h_1, \cdots, h_m \}$ \quad und \quad
      $\mathtt{knf}(f_2) = \{ k_1, \cdots, k_n \}$. \\[0.2cm]
      Dabei sind die $h_i$ und die $k_j$ Klauseln.  Um nun die KNF von $f_1 \wedge f_2$ 
      zu bilden, reicht es aus, die Vereinigung dieser beiden Mengen zu bilden,
      wir haben also \\[0.2cm]
      \hspace*{1.3cm} $\mathtt{knf}(f_1 \wedge f_2) = \mathtt{knf}(f_1) \cup  \mathtt{knf}(f_2)$.
      \\[0.2cm]
      Das liefert Zeile 4 der Implementierung.
\item Falls $f= f_1 \vee f_2$ ist, transformieren wir zun\"{a}chst $f_1$ und $f_2$ in KNF.
      Dabei erhalten wir \\[0.2cm]
      \hspace*{1.3cm} 
      $\mathtt{knf}(f_1) = \{ h_1, \cdots, h_m \}$ \quad und \quad
      $\mathtt{knf}(f_2) = \{ k_1, \cdots, k_n \}$. \\[0.2cm]
      Dabei sind die $h_i$ und die $k_j$ Klauseln.  Um nun die KNF von $f_1 \vee f_2$ zu
      bilden, rechnen wir wie folgt: 
      $$
      \begin{array}[c]{ll}
        & f_1 \vee f_2  \\[0.2cm]
      \leftrightarrow & (h_1 \wedge \cdots \wedge h_m) \vee (k_1 \wedge \cdots \wedge k_n) \\[0.2cm]
      \leftrightarrow & (h_1 \vee k_1) \quad \wedge \quad \cdots \quad \wedge \quad (h_m \vee k_1) \quad \wedge \\ 
                      & \qquad \vdots     \hspace*{4cm} \vdots                \\
                      & (h_1 \vee k_n) \quad \wedge \quad \cdots \quad \wedge \quad (h_m \vee k_n) \\[0.2cm] 
      \leftrightarrow & \bigl\{ h_i \vee k_j : i \in \{ 1, \cdots, m\}, j \in \{ 1, \cdots, n \} \bigr\} \\ 
      \end{array}
      $$
      Ber\"{u}cksichtigen wir noch, dass Klauseln in der Mengen-Schreibweise als Mengen von
      Literalen aufgefasst werden, die implizit disjunktiv verkn\"{u}pft werden, so k\"{o}nnen wir
      f\"{u}r $h_i \vee k_j$ auch $h_i \cup k_j$ schreiben.  
      Insgesamt erhalten wir damit \\[0.2cm]
      \hspace*{1.3cm} 
      $\mathtt{knf}(f_1 \vee f_2) = \bigl\{ h \cup k \mid h \in \mathtt{knf}(f_1) \;\wedge\; k \in \mathtt{knf}(f_2) \bigr\}$.
      \\[0.2cm]
      Das liefert die Zeile 5 der Implementierung der Prozedur \texttt{knf}.
\item Falls die Formel $f$, die wir in KNF transformieren wollen, eine Aussage-Variable
      ist, so transformieren wir $f$ zun\"{a}chst in eine Klausel. Das liefert $\{f\}$.  
      Da eine KNF eine Menge von Klauseln ist, ist die KNF dann $\bigl\{\{f\}\bigr\}$.
      Dieses Ergebnis geben wir in Zeile 6 zur\"{u}ck.
\end{enumerate}

\begin{figure}[!ht]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.0cm,
                  xrightmargin  = 0.0cm
                ]
    knf := procedure(f) {
        match (f) {
            case !g     : return { { !g } };
            case g && h : return knf(g) + knf(h);
            case g || h : return { k1 + k2 : k1 in knf(g), k2 in knf(h) };
            default     : return { { f } }; // f is a variable
        }
    };
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{Berechnung der konjunktiven Normalform.}
  \label{fig:knf}
\end{figure}

Zum Abschluss zeigen wir in Abbildung \ref{fig:normalize} auf Seite \pageref{fig:normalize}
wie die einzelnen Funktionen zusammenspielen.  Die Funktion \texttt{normalize} eliminiert
zun\"{a}chst die Junktoren ``$\leftrightarrow$'' und ``$\rightarrow$'' und bringt die Formel
in Negations-Normalform.  Die Negations-Normalform wird nun mit Hilfe der Funktion
\texttt{knf} in konjunktive Normalform gebracht, wobei gleichzeitig die Formel in
Mengen-Schreibweise \"{u}berf\"{u}hrt wird.  Im letzten Schritt entfernt die Funktion
\texttt{simplify} alle Klauseln, die trivial sind.   Eine Klausel $k$ ist dann trivial,
wenn es eine aussagenlogische Variablen $p$ gibt, so dass sowohl $p$ als auch $\neg p$
in $k$ der Menge $k$ auftritt.  Daher berechnet die Funktion \texttt{isTrivial} f\"{u}r eine
Klausel $c$ zun\"{a}chst die Menge
\\[0.2cm]
\hspace*{1.3cm}
\verb'{ p in c | fct(p) == "^variable" }'
\\[0.2cm]
aller Variablen, die in der Klausel $c$ auftreten.  Anschlie\3end wird die Menge
\\[0.2cm]
\hspace*{1.3cm}
\verb'{ args(l)[1] : l in c | fct(l) == "^not" }'
\\[0.2cm]
berechnet.  Diese Menge enth\"{a}lt alle die aussagenlogischen Variablen $p$, f\"{u}r die $\neg p$
ein Element der Klausel $c$ ist, denn die Formel $\neg p$ wird intern in \textsc{SetlX}
durch den Term
\\[0.2cm]
\hspace*{1.3cm}
\texttt{\symbol{94}not(p)}
\\[0.2cm]
dargestellt.  Falls also das Literal $l$ die Form $l = \neg p$ hat, so hat der Term $l$
das Funktions-Zeichen \texttt{\symbol{94}not}.  Die Anwendung der Funktion
\texttt{fct} auf $l$ liefert uns genau dieses Funktions-Zeichen.  Der Ausdruck
$\texttt{args}(l)$ berechnet die Liste der Argumente des Funktions-Zeichens 
\texttt{\symbol{94}not} und diese Liste enth\"{a}lt als einziges Element gerade die
aussagenlogische Variable $p$, die wir daher durch den Ausdruck
\\[0.2cm]
\hspace*{1.3cm}
\texttt{args(l)[1]}
\\[0.2cm]
aus dem Literal $l$ extrahieren k\"{o}nnen.  Falls nun die beiden oben berechneten Mengen ein
gemeinsames Element haben, so ist die Klausel $c$ trivial.  Dies wird dadurch gepr\"{u}ft,
dass der Schnitt der beiden Mengen berechnet wird.
Das vollst\"{a}ndige Programm zur Berechnung der konjunktiven Normalform finden Sie als die Datei
\href{https://github.com/karlstroetmann/Logik/blob/master/SetlX/knf.stlx}{\texttt{knf.stlx}}
unter GitHub..

\begin{figure}[!ht]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.0cm,
                  xrightmargin  = 0.0cm
                ]
    normalize := procedure(f) {
        n1 := elimGdw(f);
        n2 := elimFolgt(n1);
        n3 := nnf(n2);
        n4 := knf(n3);
        return simplify(n4);
    };
    simplify := procedure(k) {
        return { c : c in k | !isTrivial(c) };
    };
    isTrivial := procedure(c) {
        return { p : p in c | fct(p) == "^variable" } * 
               { args(l)[1] : l in c | fct(l) == "^not" } != {};
    };
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{Normalisierung einer Formel}
  \label{fig:normalize}
\end{figure}
\vspace*{\fill}



\section{Der Herleitungs-Begriff}
Ist $\{f_1,\cdots,f_n\}$ eine Menge von Formeln, und $g$ eine weitere Formel, so
k\"{o}nnen wir uns fragen, ob  die  Formel $g$ aus $f_1$, $\cdots$, $f_n$ \emph{folgt}, ob
also 
\[ \models f_1 \wedge \cdots \wedge f_n \rightarrow g \]
gilt.
Es gibt verschiedene M\"{o}glichkeiten, diese Frage zu beantworten.  Ein Verfahren kennen wir
schon: Zun\"{a}chst \"{u}berf\"{u}hren wir die Formel  $f_1 \wedge \cdots \wedge f_n \rightarrow g$ in
konjunktive Normalform.  Wir erhalten dann eine Menge
$\{k_1,\cdots,k_n\}$ von Klauseln, deren Konjunktion zu der  Formel
\\[0.2cm]
\hspace*{1.3cm} $f_1 \wedge \cdots \wedge f_n \rightarrow g$
\\[0.2cm] 
\"{a}quivalent ist.  Diese Formel ist nun genau dann eine Tautologie, wenn
jede der Klauseln $k_1$, $\cdots$, $k_n$ trivial ist.  

Das oben dargestellte Verfahren ist aber sehr aufwendig.  Wir zeigen dies anhand eines
Beispiels und wenden das Verfahren
an, um zu entscheiden, ob $p \rightarrow r$ aus den beiden Formeln $p \rightarrow q$ und
$q \rightarrow r$ folgt.   Wir bilden also die konjunktive Normalform der Formel 
\[ h := (p \rightarrow q) \wedge (q \rightarrow r) \rightarrow p \rightarrow r
\]
und erhalten nach m\"{u}hsamer Rechnung
\[
   (p \vee \neg p \vee r \vee \neg r) \wedge (\neg q \vee \neg p \vee r \vee \neg r) \wedge
   (\neg q \vee \neg p \vee q \vee r) \wedge (p \vee \neg p \vee q \vee r). 
\]
Zwar k\"{o}nnen wir jetzt sehen, dass die Formel $h$ eine Tautologie ist, aber angesichts der
Tatsache, dass wir mit blo\3em Auge sehen, dass  $p \rightarrow r$ aus den Formeln $p \rightarrow q$ und
$q \rightarrow r$ folgt, ist die Rechnung  doch  sehr m\"{u}hsam.

Wir stellen daher nun eine weiteres Verfahren vor, mit dessen Hilfe wir entscheiden
k\"{o}nnen, ob eine Formel aus einer gegebenen Menge von Formeln folgt.  Die Idee bei diesem Verfahren
ist es, die Formel $f$ mit Hilfe von \emph{Schluss-Regeln} aus den gegebenen Formeln 
$f_1, \cdots, f_n$ herzuleiten.
  Das Konzept einer Schluss-Regel wird in der nun folgenden Definition festgelegt.
\begin{Definition}[Schluss-Regel]
    Eine \colorbox{yellow}{\emph{Schluss-Regel}} ist eine Paar  $\langle \{f_1, \cdots, f_n\}, k \rangle$.
    Dabei ist 
    $\{f_1, \cdots, f_n\}$ eine Menge von Formeln und $k$ ist eine einzelne Formel.  
    Die Formeln $f_1$, $\cdots$, $f_n$ bezeichnen wir als
    \colorbox{yellow}{\emph{Pr\"{a}missen}}, die Formel $k$ hei\3t die \colorbox{yellow}{\emph{Konklusion}} der Schluss-Regel.
    Ist das Paar 
    $\langle \{f_1, \cdots, f_n\}, k \rangle$ eine Schluss-Regel, so schreiben wir
    dies als: 
    \\[0.3cm]
    \hspace*{1.3cm}      
    $\schluss{f_1 \quad \cdots \quad f_n}{k}$.
    \\[0.3cm]
    Wir lesen diese Schluss-Regel wie folgt: 
    ``\textsl{Aus $f_1$, $\cdots$, $f_n$ kann auf $k$ geschlossen werden.}''
    \eox
\end{Definition}
\vspace*{0.3cm}

\noindent
\textbf{Beispiele} f\"{u}r Schluss-Regeln: 
\\[0.2cm]
\hspace*{1.3cm}            
\begin{tabular}[t]{|l|l|l|}
\hline
\rule{0pt}{15pt} \emph{Modus Ponens} & \emph{Modus Ponendo Tollens} & \emph{Modus Tollendo Tollens} \\[0.3cm]
\hline
$
\rule[-15pt]{0pt}{40pt}\schluss{p \quad\quad p \rightarrow q}{q}$ &
$\schluss{\neg q \quad\quad p \rightarrow q}{\neg p}$ &
$\schluss{\neg p \quad\quad p \rightarrow q}{\neg q}$ \\[0.3cm]
\hline
\end{tabular}
\\[0.3cm]

\noindent
Die Definition der Schluss-Regel schr\"{a}nkt zun\"{a}chst die Formeln, die als Pr\"{a}missen
bzw.~Konklusion verwendet werden k\"{o}nnen, nicht weiter ein.  Es ist aber sicher nicht
sinnvoll, beliebige Schluss-Regeln zuzulassen.  Wollen wir Schluss-Regeln in Beweisen
verwenden, so sollten die Schluss-Regeln in dem in der folgenden Definition erkl\"{a}rten
Sinne \emph{korrekt} sein.

\begin{Definition}[Korrekte Schluss-Regel]
  Eine Schluss-Regel der Form \\[0.2cm]
  \hspace*{1.3cm} $\schluss{f_1 \quad \cdots \quad f_n}{k}$ \\[0.2cm]
  ist genau dann \colorbox{yellow}{\emph{korrekt}}, wenn 
  $\models f_1 \wedge \cdots \wedge f_n \rightarrow k$ gilt. \eox
\end{Definition}
Mit dieser Definition sehen wir, dass 
die oben als ``\emph{Modus Ponens}'' und ``\emph{Modus Ponendo Tollens}'' bezeichneten
Schluss-Regeln korrekt sind, w\"{a}hrend die als  ``\emph{Modus Tollendo Tollens}'' bezeichnete
Schluss-Regel nicht korrekt ist.

Im Folgenden gehen wir davon aus, dass alle Formeln Klauseln sind.  Einerseits ist dies
keine echte Einschr\"{a}nkung, denn wir k\"{o}nnen ja jede Formel in eine \"{a}quivalente Menge von
Klauseln umrechnen.  Andererseits haben viele in der Praxis auftretende aussagenlogische
Probleme die Gestalt von Klauseln.  Daher stellen wir jetzt eine Schluss-Regel vor, in der
sowohl die Pr\"{a}missen als auch die Konklusion Klauseln sind.
     
\begin{Definition}[Schnitt-Regel]
    Ist $p$ eine aussagenlogische Variable und sind $k_1$ und $k_2$ Mengen von Literalen,
    die wir als Klauseln interpretieren, so bezeichnen wir die folgende Schluss-Regel
    als die \colorbox{yellow}{\emph{Schnitt-Regel}}: 
    \\[0.2cm]
    \hspace*{1.3cm}
    $\displaystyle \schluss{ k_1 \cup \{p\} \quad \{\neg p\} \cup k_2 }{k_1 \cup k_2}$. 
    \eox
\end{Definition}

\noindent
Die Schnitt-Regel ist sehr allgemein.  Setzen wir in der obigen Definition f\"{u}r $k_1 =
\{\}$ und  $k_2 = \{q\}$ 
ein, so erhalten wir die folgende Regel als Spezialfall: \\[0.2cm]
\hspace*{1.3cm} $\schluss{\{\} \cup \{p\} \quad\quad \{\neg p\} \cup \{ q \} }{ \{\} \cup \{q\} }$ \\[0.2cm]
Interpretieren wir nun die Mengen als Disjunktionen, so haben wir: \\[0.2cm]
\hspace*{1.3cm}  $\schluss{p \quad\quad \neg p \vee q }{ q }$ \\[0.2cm]
Wenn wir jetzt noch ber\"{u}cksichtigen, dass die Formel $\neg p \vee q$ \"{a}quivalent ist zu der
Formel $p \rightarrow q$, dann ist das nichts anderes als der \emph{Modus Ponens}.  
Die Regel \emph{Modus Tollens} ist ebenfalls ein Spezialfall der Schnitt-Regel.  Wir
erhalten diese Regel, wenn wir in der Schnitt-Regel $k_1 = \{ \neg q \}$ und $k_2 = \{\}$ setzen.

\begin{Satz}
  Die Schnitt-Regel ist korrekt.
\end{Satz}
\textbf{Beweis}:  Wir m\"{u}ssen zeigen, dass \\[0.2cm]
\hspace*{1.3cm} $\models (k_1 \vee p) \wedge (\neg p \vee k_2) \rightarrow k_1 \vee k_2$ \\[0.2cm]
gilt.  Dazu \"{u}berf\"{u}hren wir die obige Formel in konjunktive Normalform:
$$
\begin{array}{ll}
  & (k_1 \vee p) \wedge (\neg p \vee k_2) \rightarrow k_1 \vee k_2  \\[0.2cm]
\leftrightarrow  & 
    \neg \bigl( (k_1 \vee p) \wedge (\neg p \vee k_2) \bigr) \vee k_1 \vee k_2 \\[0.2cm]
\leftrightarrow  & 
    \neg (k_1 \vee p) \vee \neg (\neg p \vee k_2) \vee k_1 \vee k_2 \\[0.2cm]
\leftrightarrow  & 
     (\neg k_1 \wedge \neg p) \vee  (p \wedge \neg k_2) \vee k_1 \vee k_2 \\[0.2cm]
\leftrightarrow  & 
     (\neg k_1 \vee p \vee k_1 \vee k_2)  \wedge 
     (\neg k_1 \vee \neg k_2 \vee k_1 \vee k_2)  \wedge 
     (\neg p \vee p \vee k_1 \vee k_2)  \wedge 
     (\neg p \vee \neg k_2 \vee k_1 \vee k_2) 
      \\[0.2cm]
\leftrightarrow  & 
     \verum  \wedge 
     \verum  \wedge 
     \verum  \wedge 
     \verum 
      \\[0.2cm]
\leftrightarrow  & 
     \verum    \hspace*{13.5cm} _\Box
      \\
\end{array}
$$



\begin{Definition}[$\vdash$]
    Es sei $M$ eine Menge von Klauseln  und $f$ sei eine einzelne Klausel.  
    Die Formeln aus $M$ bezeichnen wir als unsere Annahmen.  Unser Ziel ist es, mit diesen
    Annahmen die Formel $f$ zu beweisen.  Dazu definieren wir induktiv die Relation \\[0.2cm]
    \hspace*{1.3cm} $M \vdash f$. \\[0.2cm]
    Wir lesen ``$M \vdash f$'' als ``$M$ leitet $f$ her''.  Die induktive Definition ist
    wie folgt:
    \begin{enumerate}
    \item Aus einer Menge $M$ von Annahmen kann jede der Annahmen hergeleitet werden: \\[0.2cm]
          \hspace*{1.3cm} 
          Falls $f \el M$ ist, dann gilt  $M \vdash f$.
    \item Sind $k_1 \cup \{p\}$ und $\{ \neg p \} \cup k_2$ Klauseln, die aus $M$
          hergeleitet werden k\"{o}nnen, so kann mit der Schnitt-Regel auch die Klausel $k_1 \cup k_2$ aus $M$
          hergeleitet werden: \\[0.2cm]
          \hspace*{1.3cm} 
          Falls sowohl $M \vdash k_1 \cup \{p\}$ als auch $M \vdash \{ \neg p \} \cup k_2$
          gilt, dann gilt auch $M \vdash k_1 \cup k_2$.
    \eox
    \end{enumerate}
\end{Definition}



\noindent
\textbf{Beispiel}:  Um den Beweis-Begriff zu veranschaulichen geben wir ein Beispiel und
zeigen 
\[ \bigl\{\; \{\neg p, q\},\; \{ \neg q, \neg p \},\; \{ \neg q, p \},\; \{ q, p \}\; \bigr\} \vdash \falsum.
\]
Gleichzeitig zeigen wir anhand des Beispiels, wie wir Beweise zu Papier bringen:
\begin{enumerate}
\item Aus $\{\neg p, q \}$ und $\{ \neg q, \neg p \}$ folgt mit der Schnitt-Regel   
      $\{ \neg p, \neg p \}$.   Wegen $\{ \neg p, \neg p \} = \{ \neg p \}$
      schreiben wir dies als 
      \[ \{\neg p, q \}, \{ \neg q, \neg p \} \;\vdash\; \{ \neg p \}. \]
      Dieses Beispiel zeigt, dass die Klausel $k_1 \cup k_2$ durchaus auch weniger
      Elemente enthalten kann als die Summe $\symbol{35}k_1 + \symbol{35}k_2$.  Dieser
      Fall tritt genau dann ein, wenn es Literale gibt, die sowohl in $k_1$ als auch in
      $k_2$ vorkommen.
\item $\{\neg q, \neg p \},\; \{ p, \neg q \} \;\vdash\; \{ \neg q \}$. 
\item $\{ p, q \},\; \{ \neg q \} \;\vdash\; \{ p \}$. 
\item $\{ \neg p \},\; \{ p \} \;\vdash\; \{\}$. 
\end{enumerate}
Als weiteres Beipiel zeigen wir nun, dass $p \rightarrow r$ aus $p \rightarrow q$ und $q \rightarrow r$ 
folgt.  Dazu \"{u}berf\"{u}hren wir zun\"{a}chst alle Formeln in Klauseln: 
\[ \mathtt{knf}(p \rightarrow q) = \bigl\{ \{ \neg p, q \} \bigr\}, \quad
   \mathtt{knf}(q \rightarrow r) = \bigl\{ \{ \neg q, r \} \bigr\}, \quad 
   \mathtt{knf}(p \rightarrow r) = \bigl\{ \{ \neg p, r \} \bigr\}.
\]
Wir haben also $M = \bigl\{\, \{ \neg p, q \},\; \{ \neg q, r \}\,\bigr\}$ und m\"{u}ssen zeigen, dass
\[ M \vdash  \{ \neg p, r \} \]
folgt.  Der Beweis besteht aus einer einzigen Anwendung der Schnitt-Regel: 
\[ \{ \neg p, q \},\; \{ \neg q, r \} \;\vdash\; \{ \neg p, r \}. \]

\subsection{Eigenschaften des Herleitungs-Begriffs}
Die Relation $\vdash$ hat zwei wichtige Eigenschaften:

\begin{Satz}[Korrektheit]
  Ist $\{k_1, \cdots, k_n \}$ eine Menge von Klauseln und $k$ eine einzelne Klausel,
  so haben wir: \\[0.2cm]
  \hspace*{3.3cm} Wenn $\{k_1, \cdots, k_n \} \vdash k$ gilt, \quad dann gilt auch $\models k_1 \wedge \cdots \wedge k_n \rightarrow k$.  
\end{Satz}

\noindent
\textbf{Beweis}:  Der Beweis verl\"{a}uft durch eine Induktion nach der Definition der Relation $\vdash$. 
\begin{enumerate}
\item Fall: Es gilt $\{ k_1, \cdots, k_n \} \vdash k$ weil $k \in \{ k_1, \cdots, k_n \}$ ist.  
      Dann gibt es also ein $i \in \{1,\cdots,n\}$, so dass $k = k_i$ ist.  In diesem Fall
      m\"{u}ssen wir
      \\[0.2cm]
      \hspace*{1.3cm}
      $\models k_1 \wedge \cdots \wedge k_n \rightarrow k_i$
      \\[0.2cm]
      zeigen, was offensichtlich ist.
\item Fall: Es gilt $\{ k_1, \cdots, k_n \} \vdash k$ weil es eine aussagenlogische
      Variable $p$ und Klauseln $g$ und $h$ gibt, so dass 
      \[ \{ k_1, \cdots, k_n \} \vdash g \cup \{ p \} \quad \mathrm{und} \quad
         \{ k_1, \cdots, k_n \} \vdash h \cup \{ \neg p \}
      \]
      gilt und daraus haben wir mit der Schnitt-Regel auf
      \[ \{ k_1, \cdots, k_n \} \vdash g \cup h \]
      geschlossen, wobei $k = g \cup h$ gilt. 

      Nach Induktions-Voraussetzung haben wir dann
      \[ \models k_1 \wedge \cdots \wedge k_n \rightarrow g \vee p \quad \mathrm{und} \quad 
         \models k_1 \wedge \cdots \wedge k_n \rightarrow h \vee \neg p. \]
      Wegen 
      \[ \models (g \vee p) \wedge (h \vee \neg p) \rightarrow g \vee h \quad \mathrm{und} \quad
         k = g \cup h \]
      folgt daraus die Behauptung.
      \qed
\end{enumerate}

\noindent
Die Umkehrung dieses Satzes gilt leider nur in abgeschw\"{a}chter Form und zwar dann, wenn $k$
die leere Klausel ist, also im Fall $k = \falsum$.
\begin{Satz}[Widerlegungs-Vollst\"{a}ndigkeit] \label{widerlegungs-vollstaendig}
  Ist  $M = \{k_1, \cdots, k_n \}$ eine Menge von Klauseln,
  so haben wir: \\[0.1cm]
  \hspace*{1.3cm} 
  Wenn $\models \{ k_1, \cdots, k_n \} \rightarrow \falsum$ gilt, dann gilt auch  $M \vdash \{\}$.
\end{Satz}
\vspace*{0.2cm}



\subsection{Beweis der Widerlegungs-Vollst\"{a}ndigkeit}
Der Beweis der Widerlegungs-Vollst\"{a}ndigkeit der Aussagenlogik ben\"{o}tigt den  Begriff der
\emph{Erf\"{u}llbarkeit}, den wir jetzt formal einf\"{u}hren. 

\begin{Definition}[Erf\"{u}llbarkeit]
  Es sei $M$ eine Menge von aussagenlogischen Formeln.
  Falls es eine aussagenlogische Interpretation $\I$ gibt, die alle Formeln aus $M$ erf\"{u}llt, nennen
  wir $M$ \colorbox{yellow}{\emph{erf\"{u}llbar}}. 

  Wir sagen, dass $M$ \colorbox{yellow}{\emph{unerf\"{u}llbar}} ist und schreiben 
  \\[0.2cm]
  \hspace*{1.3cm}
  $M \models \falsum$
  \\[0.2cm]
  wenn es keine aussagenlogische Interpretation $\I$ gibt, die alle Formel aus $M$ erf\"{u}llt.
  Bezeichnen wir die Menge der aussagenlogischen Interpretationen mit
  \textsc{Ali}, so schreibt sich das formal als
  \\[0.2cm]
  \hspace*{1.3cm}
  $M \models \falsum \quad \mbox{g.d.w.} \quad \forall \I \in \textsc{Ali}: \exists g \in M: \I(g) = \mathtt{false}$.   
  \eox
\end{Definition}

\remark 
Ist $M = \{ k_1, \cdots, k_n \}$ eine Menge von Klauseln, so k\"{o}nnen Sie sich leicht \"{u}berlegen, dass
$M$ genau dann nicht erf\"{u}llbar ist, wenn
\\[0.2cm]
\hspace*{1.3cm}
$\models k_1 \wedge \cdots \wedge k_n \rightarrow \falsum$
\\[0.2cm]
gilt. \eox

Wir f\"{u}hren den Bewies der Widerlegungs-Vollst\"{a}ndigkeit mit Hilfe eines Programms, das in den
Abbildungen \ref{fig:completeness.stlx-1}, \ref{fig:completeness.stlx-2} und
\ref{fig:completeness.stlx-3} auf den folgenden Seiten gezeigt ist.  Die Grundidee
bei diesem Programm besteht darin, dass wir versuchen, aus einer gegebenen Menge $M$ von Klauseln
alle Klauseln herzuleiten, die mit der Schnittregel aus $M$ herleitbar sind.  Wenn wir dabei auch
die leere Klausel herleiten, dann ist $M$ aufgrund der Korrektheit der Schnitt-Regel offenbar
unerf\"{u}llbar.  Falls es uns aber nicht gelingt, die leere Klausel aus $M$ abzuleiten, dann konstruieren wir
aus der Menge aller Klauseln, die wir aus $M$ hergeleitet haben, eine aussagenlogische Interpretation
$\I$, die alle Klauseln aus $M$ erf\"{u}llt.

Wir diskutieren zun\"{a}chst die Hilfsprozeduren, die in Abbildung \ref{fig:completeness.stlx-1} gezeigt
sind. 
\begin{enumerate}
\item Die Funktion \texttt{complement} erh\"{a}lt als Argument ein Literal $l$ und berechnet das
      \colorbox{yellow}{\emph{Komplement}} $\komplement{\,l\,}$ dieses Literals.  Falls $l$ die Form $\neg p$ mit einer
      aussagenlogischen Variablen $p$ hat, so gilt $\komplement{\neg p} = p$.   Falls das Literal
      $l$ eine aussagenlogische Variable $p$ ist, haben wir $\komplement{p} = \neg p$.
\item Die Funktion \texttt{extractVar} extrahiert die aussagenlogische Variable aus einem Literal $l$.
      Die Implementierung verl\"{a}uft analog zur Implementierung der Funktion \texttt{complement} \"{u}ber eine
      Fallunterscheidung, bei der wir ber\"{u}cksichtigen, dass $l$ entweder die Form $\neg p$ oder die
      Form $p$ hat, wobei $p$ eine aussagenlogische Variable ist.
\item Die Funktion \texttt{collectVars} erh\"{a}lt als Argument eine Menge $m$ von Klauseln, wobei die
      einzelnen Klauseln $c \in m$ als Mengen von Literalen dargestellt werden.  Aufgabe der
      Funktion \texttt{collectVars} ist es, die Menge aller aussagenlogischen Variablen zu
      berechnen, die in einer der Klauseln $c$ aus $m$ vorkommen.  Bei der Implementierung iterieren
      wir zun\"{a}chst \"{u}ber die Klauseln $c$ der Menge $m$ und dann f\"{u}r jede Klausel $c$ \"{u}ber die in $c$
      vorkommenden Literale $l$, wobei die Literale mit Hilfe der Funktion \texttt{extractVar} in
      aussagenlogische Variablen umgewandelt werden.
\item Die Funktion \texttt{cutRule} erh\"{a}lt als Argumente zwei Klauseln $c_1$ und $c_2$ und berechnet
      alle die Klauseln, die mit Hilfe der Schnittregel aus $c_1$ und $c_2$ gefolgert werden
      k\"{o}nnen.  Beispielsweise k\"{o}nnen wir aus den beiden Klauseln
      \\[0.2cm]
      \hspace*{1.3cm}
      $\{ p, q \}$ \quad und \quad $\{ \neg p, \neg q \}$ 
      \\[0.2cm]
      mit der Schnitt-Regel sowohl die Klausel
      \\[0.2cm]
      \hspace*{1.3cm}
      $\{q, \neg q\}$ \quad als auch die Klausel \quad $\{p, \neg p \}$
      \\[0.2cm]
      herleiten.
\end{enumerate}

\begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  firstnumber   = 1,
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm,
                ]
    complement := procedure(l) {
        match (l) {
            case !p : return  p;
            case  p : return !p;
        }
    };
    extractVar := procedure(l) {
        match (l) {
            case !p : return p;
            case  p : return p;
        }
    };
    collectVars := procedure(m) {
        return { extractVar(l) : c in m, l in c };
    };
    cutRule := procedure(c1, c2) {
        return { (c1 - {l}) + (c2 - {complement(l)}) 
               : l in c1
               | complement(l) in c2
               };
    };
\end{Verbatim}
\vspace*{-0.3cm}
\caption{Verschiedene Hilfsprozeduren, die in Abbildung \ref{fig:completeness.stlx-2} genutzt werden.}
\label{fig:completeness.stlx-1}
\end{figure}

\begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  firstnumber   = last,
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm,
                ]
    saturate := procedure(clauses) {
        while (true) {
            derived := {} +/ { cutRule(c1, c2) : c1 in clauses, c2 in clauses };
            if ({} in derived) {
                return { {} };  // clauses are inconsistent
            }
            derived -= clauses;
            if (derived == {}) {
                return clauses;
            }
            clauses += derived;
        }
    };
\end{Verbatim}
\vspace*{-0.3cm}
\caption{Die Funktion \texttt{saturate}.}
\label{fig:completeness.stlx-2}
\end{figure}

Abbildung \ref{fig:completeness.stlx-2} zeigt die Funktion \texttt{saturate}.  Die Funktion erh\"{a}lt
als Eingabe eine Menge \texttt{clauses} von aussagenlogischen Klauseln, die als Mengen von Literalen
dargestellt werden.  Aufgabe der Funktion ist es, alle Klauseln herzuleiten, die mit Hilfe der
Schnittregel auf direktem oder indirekten Wege aus der Menge \texttt{clauses} hergeleitet werden
k\"{o}nnen.  Genauer sagen wir, dass die Menge $S$ der Klauseln, die von der Funktion \texttt{saturate}
zur\"{u}ck gegeben wird, unter Anwendung der Schnitt-Regel \colorbox{yellow}{\emph{saturiert}} ist, was formal wie folgt
definiert ist:
\begin{enumerate}
\item Falls $S$ die leere Klausel $\{\}$ enth\"{a}lt, dann ist $S$ saturiert.
\item Andernfalls muss \texttt{clauses} eine Teilmenge von $S$ sein und es muss zus\"{a}tzlich Folgendes
      gelten: Falls $c_1 \cup \{ l \}$ und  $c_2 \cup \bigl\{ \komplement{\,l\,} \bigr\}$ Klauseln aus $S$
      sind, dann ist auch die Klausel $c_1 \cup c_2$ ein Element der Klauselmenge $S$.
\end{enumerate}
Wir erl\"{a}utern nun die Implementierung der Funktion \texttt{saturate}.
\begin{enumerate}
\item Die \texttt{while}-Schleife, die in Zeile 23 beginnt, hat die Aufgabe, die Schnitt-Regel
      solange wie m\"{o}glich anzuwenden um mit Hilfe der Schnitt-Regel neue Klauseln aus den gegebenen
      Klauseln herzuleiten.  Da die Bedingung dieser Schleife den Wert \texttt{true} hat, kann diese
      Schleife nur durch die Ausf\"{u}hrung eines \texttt{return}-Befehls abgebrochen werden.
\item In Zeile 24 wird die Menge \texttt{derived} dadurch berechnet, dass alle Klauseln berechnet
      werden, die mit Hilfe der Schnitt-Regel aus zwei der Klauseln in der Menge \texttt{clauses} 
      gefolgert werden k\"{o}nnen.
\item Falls die Menge \texttt{derived} die leere Klausel enth\"{a}lt, dann ist die Menge
      \texttt{clauses} widerspr\"{u}chlich und die Funktion \texttt{saturate} gibt als Ergebnis die
      Menge $\bigl\{ \{\} \bigr\}$ zur\"{u}ck.
\item Andernfalls ziehen wir in Zeile 28 von der Menge \texttt{derived} zun\"{a}chst die Klauseln ab, die wir schon
      vorher hatten, denn es geht uns darum festzustellen, ob wir im letzten Schritt tats\"{a}chlich
      neue Klauseln gefunden haben, oder ob alle Klauseln, die wir im letzten Schritt in Zeile 23
      hergeleitet haben, eigentlich schon vorher  bekannt  waren.
\item Falls wir nun in Zeile 29 feststellen, dass wir keine neuen Klauseln hergeleitet haben,
      dann ist die Menge \texttt{clauses} saturiert und wir geben diese Menge in Zeile 30 zur\"{u}ck.
\item Andernfalls f\"{u}gen wir in Zeile 32 die Klauseln, die wir neu gefunden haben, zu der Menge
      \texttt{clauses} hinzu und setzen die \texttt{while}-Schleife fort.
\end{enumerate}
An dieser Stelle m\"{u}ssen wir uns \"{u}berlegen, dass die \texttt{while}-Schleife tats\"{a}chlich irgendwann
abbricht.  Das hat zwei Gr\"{u}nde:  
\begin{enumerate}
\item In jeder Iteration der Schleife wird die Anzahl der Elemente der Menge \texttt{clauses}
      mindestens um Eins erh\"{o}ht, denn wir wissen ja, dass die Menge \texttt{derived}, die wir zu
      \texttt{clauses} hinzuf\"{u}gen, einerseits nicht leer ist und andererseits auch nur solche
      Klauseln enth\"{a}lt, die nicht bereits in \texttt{clauses} auftreten.
\item Die Menge \texttt{clauses}, mit der wir urspr\"{u}nglich starten, enth\"{a}lt eine bestimmte Anzahl $n$
      von aussagenlogischen Variablen.  Bei der Anwendung der Schnitt-Regel werden aber keine neue
      Variablen erzeugt.  Daher bleibt die Anzahl der aussagenlogischen Variablen, die in
      \texttt{clauses} auftreten, immer gleich.  Damit ist nat\"{u}rlich auch die Anzahl der Literale,
      die in \texttt{clauses} auftreten, beschr\"{a}nkt: Wenn es nur $n$ aussagenlogische Variablen gibt,
      dann kann es auch h\"{o}chstens $2 \cdot n$ Literale geben.  Jede Klausel aus \texttt{clauses} ist
      aber eine Teilmenge der Menge aller Literale.  Da eine Menge mit $k$ Elementen insgesamt $2^k$
      Teilmengen hat, gibt es h\"{o}chstens $2^{2 \cdot n}$ verschiedene Klauseln, die in
      \texttt{clauses} auftreten k\"{o}nnen.  
\end{enumerate}
Aus den beiden oben angegebenen Gr\"{u}nden k\"{o}nnen wir schlie\3en, dass die \texttt{while}-Schleife in
Zeile 23 nach sp\"{a}testens $2^{2 \cdot n}$ Iterationen abgebrochen wird. 

\begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  firstnumber   = last,
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm,
                ]
    findValuation := procedure(clauses) {
        vars    := collectVars(clauses);
        clauses := saturate(clauses);
        if ({} in clauses) {
            return false;
        }
        literals := {};  // refuted literal
        for (p in vars) {
            if (exists(c in clauses | p in c && c <= literals + {p})) {
                literals += { !p };
            } else {
                literals += { p };
            }
        }
        result := { complement(p) : p in literals };
        return result;
    };
\end{Verbatim}
\vspace*{-0.3cm}
\caption{Die Funktion \texttt{findValuation}.}
\label{fig:completeness.stlx-3}
\end{figure}

Als n\"{a}chstes diskutieren wir die Implementierung der Funktion \texttt{findValuation}, die in
Abbildung \ref{fig:completeness.stlx-3} gezeigt ist.  Diese Funktion erh\"{a}lt als Eingabe eine Menge
\texttt{clauses} von Klauseln.  Falls diese Menge widerspr\"{u}chlich ist, soll die Funktion
das Ergebnis \texttt{false} zur\"{u}ck geben.  Andernfalls soll eine aussagenlogische Belegung $\I$ berechnet werden,
unter der alle Klauseln aus der Menge \texttt{clauses} erf\"{u}llt sind.  Im Detail arbeitet die
Funktion \texttt{findValuation} wie folgt.
\begin{enumerate}
\item Zun\"{a}chst berechnen wir in Zeile 36 die Menge aller aussagenlogischen Variablen, die in
      der Menge \texttt{clauses} auftreten.  Wir ben\"{o}tigen diese Menge, denn wir m\"{u}ssen diese
      Variablen ja auf die Menge $\{ \mathtt{true}, \mathtt{false} \}$ abbilden.
\item In Zeile 37 saturieren wir die Menge \texttt{clauses} und berechnen alle Klauseln, die aus der
      urspr\"{u}nglich gegebenen Menge von Klauseln mit Hilfe der Schnitt-Regel hergeleitet werden
      k\"{o}nnen.  Hier k\"{o}nnen zwei F\"{a}lle auftreten:
      \begin{enumerate}
      \item Falls die leere Klausel hergeleitet werden kann, dann ist die urspr\"{u}nglich gegebene Menge
            von Klauseln widerspr\"{u}chlich und wir geben als Ergebnis an Stelle einer Belegung den
            Wert \texttt{false} zur\"{u}ck, denn eine widerspr\"{u}chliche Menge von Klauseln ist sicher
            nicht erf\"{u}llbar.
      \item Andernfalls berechnen wir nun eine aussagenlogische Belegung, unter der alle Klauseln aus
            \texttt{clauses} wahr werden.  Zu diesem Zweck berechnen wir zun\"{a}chst eine Menge von
            Literalen \texttt{literals}.  Die Idee ist dabei, dass wir die Variable $p$ genau
            dann in die Menge \texttt{literals} aufnehmen, wenn die gesuchte Belegung $\I$ die
            Variable $p$ zu \texttt{false} auswertet.  Andernfalls nehmen wir an Stelle von $p$ das
            Literal $\neg p$ in der Menge \texttt{literals} auf.  Als Ergebnis geben wir daher in
            Zeile 50 die Menge \texttt{result} zur\"{u}ck, bei der wir jedes Literal $l$ aus der 
            Menge \texttt{literals} durch sein Komplement $\komplement{\,l\,}$ ersetzen.  

            Im engeren Sinne ist die Menge \texttt{result} keine aussagenlogische Belegung, aber wir
            k\"{o}nnen aus dieser Menge leicht eine aussagenlogische Belegung $\I$ erzeugen, indem
            wir $\I$ wie folgt definieren: 
            \\[0.2cm]
            \hspace*{1.3cm}
            $\I(p) := \left\{
            \begin{array}{ll}
              \mathtt{true} & \mbox{falls $p \in \mathtt{result}$;}  \\
              \mathtt{false} & \mbox{sonst.}
            \end{array}
            \right.
            $
      \end{enumerate}
\item Die Berechnung der Menge \texttt{literals} erfolgt nun \"{u}ber eine \texttt{for}-Schleife.
      Dabei ist die Idee, dass wir f\"{u}r eine aussagenlogische Variable $p$ genau dann das Literal
      $\neg p$ zu der Menge \texttt{literals} hinzuf\"{u}gen, wenn die Belegung $\I$ die Variable $p$
      auf \texttt{true} abbilden muss um die Klauseln zu erf\"{u}llen.  

      Die Bedingung daf\"{u}r ist wie folgt: Angenommen, wir haben bereits Werte f\"{u}r die Variablen
      $p_1$, $\cdots$, $p_n$ in der Menge \texttt{literals}  gefunden.
      Die Werte dieser Variablen seien durch die Literale $l_1$, $\cdots$, $l_n$ in der Menge \texttt{literals}
      wie folgt festgelegt: Wenn $l_i = \neg p_i$ ist, dann gilt $\I(p_i) = \mathtt{true}$ 
      und falls $l_i = p_i$ gilt, so haben wir $\I(p_i) = \mathtt{false}$.
      Nehmen wir nun weiter an, dass eine Klausel $c$ in der Menge \texttt{clauses} existiert, so dass
      \\[0.2cm]
      \hspace*{1.3cm}
      $c \subseteq \{ l_1, \cdots, l_n, p \}$ \quad und \quad $p \in c$
      \\[0.2cm]
      gilt.  Wenn $\I(c) = \mathtt{true}$ gelten soll, dann muss $\I(p) = \mathtt{true}$ gelten, denn
      nach Konstruktion von $\I$ gilt 
      \\[0.2cm]
      \hspace*{1.3cm}
      $\I(l_i) = \mathtt{false}$ \quad f\"{u}r alle $i \in \{1,\cdots,n\}$
      \\[0.2cm]
      und damit ist $p$ das einzige Literal in der Klausel $c$, das wir mit Hilfe der Belegung $\I$
      \"{u}berhaupt noch wahr machen k\"{o}nnen.  In diesem Fall f\"{u}gen wir also das Literal
      $\neg p$ in die Menge \texttt{literals} ein. 

      Falls wir keine solche Klausel $c$ finden, dann setzen wir $\mathtt{I}(p) := \mathtt{false}$
      und f\"{u}gen das Literal $p$ in die Menge \texttt{literals} ein.
\end{enumerate}
Der entscheidende Punkt ist nun der Nachweis, dass die Funktion \texttt{findValuation} in dem Falle,
dass in Zeile 39 nicht der Wert \texttt{false} zur\"{u}ck gegeben wird, eine aussagenlogische Belegung $\I$ berechnet, bei der
alle Klauseln aus der Menge \texttt{clauses} den Wert \texttt{true} erhalten.  Um diesen Nachweis zu
erbringen, nummerieren wie die aussagenlogischen Variablen, die in der Menge \texttt{clauses}
auftreten, in der selben Reihenfolge durch, in der diese Variablen in der \texttt{for}-Schleife in Zeile
42 betrachtet werden.  Wir bezeichnen diese Variablen als
\\[0.2cm]
\hspace*{1.3cm}
 $p_1, p_2, p_3, \cdots, p_k$
\\[0.2cm]
und zeigen durch Induktion nach $n$, dass nach $n$ Durchl\"{a}ufen der Schleife f\"{u}r jede Klausel $d \in \mathtt{clauses}$, in der nur
die Variablen $p_1$, $\cdots$, $p_n$ vorkommen, 
\\[0.2cm]
\hspace*{1.3cm}
$\I(d) = \mathtt{true}$
\\[0.2cm]
gilt.
\begin{enumerate}
\item[I.A.:] $n = 0$.

             Die einzige Klausel, in der \"{u}berhaupt keine Variablen vorkommen, ist die leere Klausel.
             Da wir aber vorausgesetzt haben, dass \texttt{clauses} die leere Klausel nicht enth\"{a}lt,
             ist die zu zeigende Behauptung trivialerweise wahr.
\item[I.S.:] $n \mapsto n+1$.

             Wir setzen nun voraus, dass die Behauptung vor dem $(n\!+\!1)$-ten Durchlauf der
             \texttt{for}-Schleife gilt und haben zu zeigen, dass die Behauptung dann auch nach
             diesem Durchlauf erf\"{u}llt ist.  Sei dazu $d$ eine Klausel, in der nur die Variablen
             $p_1$, $\cdots$, $p_n$, $p_{n+1}$ vorkommen.  Die Klausel ist dann eine Teilmenge einer
             Menge der Form
             \\[0.2cm]
             \hspace*{1.3cm}
             $\{ l_1, \cdots, l_n, l_{n+1} \}$, \quad wobei $l_i \in \{ p_i, \neg p_i \}$ f\"{u}r alle
             $i \in \{1,\cdots, n+1\}$ gilt.
             \\[0.2cm]
             Nun gibt es mehrere M\"{o}glichkeiten, die wir getrennt untersuchen.
             \begin{enumerate}
             \item Es gibt ein $i \in \{1,\cdots,n\}$, so dass $l_i \in d$ und  $\I(l_i) =
               \mathtt{true}$ ist.  

                   Da eine Klausel als Disjunktion ihrer Literale aufgefasst wird, gilt dann auch
                   $\I(d) = \mathtt{true}$ unabh\"{a}ngig davon, ob $\I(p_{n+1})$ den Wert \texttt{true} oder
                   \texttt{false} hat.
             \item F\"{u}r alle $i \in \{1,\cdots,n\}$ mit $l_i \in d$ gilt $\I(l_i) = \mathtt{false}$ und es gilt $l_{n+1} = p_{n+1}$.
                   
                   Dann gilt f\"{u}r die Klausel $d$ gerade die Bedingung
                   \\[0.2cm]
                   \hspace*{1.3cm}
                   $d \subseteq \mathtt{literals} \cup \{ p_{n+1} \}$
                   \\[0.2cm]
                   und daher wird in Zeile 44 der Funktion \texttt{findValuation} das Literal $\neg p_{n+1}$ 
                   zu der Menge \texttt{literals} hinzugef\"{u}gt.  Nach Definition der Belegung $\I$, 
                   die von der Funktion \texttt{findValuation} zur\"{u}ck gegeben wird, hei\3t dies
                   gerade, dass 
                   \\[0.2cm]
                   \hspace*{1.3cm}
                   $\I(p_{n+1}) = \mathtt{true}$
                   \\[0.2cm]
                   ist und dann gilt nat\"{u}rlich auch $\I(d) = \mathtt{true}$.
             \item F\"{u}r alle $i \in \{1,\cdots,n\}$ mit $l_i \in d$ gilt $\I(l_i) = \mathtt{false}$ und es gilt $l_{n+1} = \neg p_{n+1}$.

                   An dieser Stelle ist eine weitere Fall-Unterscheidung notwendig.
                   \begin{enumerate}
                   \item Es gibt eine Klausel $c$ in der Menge \texttt{clauses}, so dass
                         \\[0.2cm]
                         \hspace*{1.3cm}
                         $c \subseteq \mathtt{literals} \cup \{p_{n+1}\}$
                         \\[0.2cm]
                         gilt.  Hier sieht es zun\"{a}chst so aus, als ob wir ein Problem h\"{a}tten, denn
                         in diesem Fall w\"{u}rde um die Klausel $c$ wahr zu machen das Literal $\neg p_{n+1}$ zur Menge
                         \texttt{literals} hinzugef\"{u}gt und damit w\"{a}re zun\"{a}chst $\I(p_{n+1}) = \mathtt{true}$ 
                         und damit $\I(\neg p_{n+1}) = \mathtt{false}$, woraus insgesamt 
                         $\I(d) = \mathtt{false}$ folgern w\"{u}rde.  In diesem Fall w\"{u}rden sich
                         die Klauseln $c$ und $d$  in der Form
                         \\[0.2cm]
                         \hspace*{1.3cm}
                         $c = c' \cup \{p_{n+1}\}$, \quad $d = d' \cup \{ \neg p_{n+1} \}$
                         \\[0.2cm]
                         schreiben lassen, wobei 
                         \\[0.2cm]
                         \hspace*{1.3cm}
                         $c' \subseteq \mathtt{literals}$  \quad und \quad $d' \subseteq \mathtt{literals}$
                         \\[0.2cm]
                         gelten würde.  Daraus w\"{u}rde sowohl
                         \\[0.2cm]
                         \hspace*{1.3cm}
                         $\I(c') = \mathtt{false}$ \quad als auch \quad $\I(d') = \mathtt{false}$
                         \\[0.2cm]
                         folgen und das würde auch
                         \\[0.2cm]
                         \hspace*{1.3cm}
                         $\I(c' \cup d') = \mathtt{false}$ \hspace*{\fill} $(*)$
                         \\[0.2cm]
                         implizieren.
                         Die entscheidende Beobachtung ist nun, dass die Klausel $c' \cup d'$ mit
                         Hilfe der Schnitt-Regel aus den beiden Klauseln
                         \\[0.2cm]
                         \hspace*{1.3cm}
                         $c = c' \cup \{p_{n+1}\}$, \quad $d = d' \cup \{ \neg p_{n+1} \}$, 
                         \\[0.2cm]
                         gefolgert werden kann.  Das hei\3t dann aber, dass die Klausel $c' \cup d'$ ein
                         Element der Menge \texttt{clauses} sein muss, denn die Menge
                         \texttt{clauses} ist ja saturiert!  Da die Klausel $c' \cup d'$ au\3erdem
                         nur die aussagenlogischen Variablen $p_1, \cdots, p_n$ enth\"{a}lt, gilt nach
                         Induktions-Voraussetzung 
                         \\[0.2cm]
                         \hspace*{1.3cm}
                         $\I(c' \cup d') = \mathtt{true}$.
                         \\[0.2cm]
                         Dies steht aber im Widerspruch zu $(*)$.  Dieser Widerspruch zeigt, dass 
                         es keine Klausel $c \in \mathtt{clauses}$ mit 
                         \\[0.2cm]
                         \hspace*{1.3cm}
                         $c \subseteq \mathtt{literals} \cup \{p_{n+1}\}$ \quad und \quad $p_{n+1} \in c$
                         \\[0.2cm]
                         geben kann und damit tritt der hier untersuchte Fall gar nicht auf. 
                   \item Es gibt \underline{keine} Klausel $c$ in der Menge \texttt{clauses}, so dass
                         \\[0.2cm]
                         \hspace*{1.3cm}
                         $c \subseteq \mathtt{literals} \cup \{p_{n+1}\}$ \quad und \quad $p_{n+1} \in c$
                         \\[0.2cm]
                         gilt.  In diesem Fall wird das Literal $p_{n+1}$ zur Menge \texttt{literals}
                         hinzugef\"{u}gt und damit gilt zun\"{a}chst $\I(p_{n+1}) = \mathtt{false}$ und folglich
                         $\I(\neg p_{n+1}) = \mathtt{true}$, woraus schlie\3lich $\I(d) = \mathtt{true}$ folgt.
                   \end{enumerate}
                   Wir sehen, dass der erste Fall der vorherigen Fall-Unterscheidung nicht
                   auftritt und dass im zweiten Fall $\I(d) = \mathtt{true}$ gilt, womit wir insgesamt 
                   $\I(d) = \mathtt{true}$ gezeigt haben.  Damit ist der Induktions-Schritt
                   abgeschlossen.
             \end{enumerate}
             Da jede Klausel $c \in \mathtt{clauses}$ nur eine endliche Anzahl von Variablen
             enth\"{a}lt, haben wir insgesamt gezeigt, dass f\"{u}r alle diese Klauseln 
             $\I(c) = \mathtt{true}$ gilt. \qed
\end{enumerate}

\noindent
\textbf{Beweis der Widerlegungs-Vollst\"{a}ndigkeit der Schnitt-Regel:}
Wir haben nun alles Material zusammen um zeigen zu k\"{o}nnen, dass die Schnitt-Regel
widerlegungs-vollst\"{a}ndig ist.  Wir nehmen also an, dass $M$ eine endliche Menge von Klauseln ist,  die nicht
erf\"{u}llbar ist, was wir als
\\[0.2cm]
\hspace*{1.3cm}
$M \models \falsum$ 
\\[0.2cm]
schreiben.  Wir rufen die Funktion \texttt{findValuation} mit dieser Menge $M$ als Argument auf.
Jetzt gibt es zwei M\"{o}glichkeiten:
\begin{enumerate}
\item Fall: Die Funktion \texttt{findValuation} liefert als Ergebnis \texttt{false}.  Nach
      Konstruktion der Funktionen \texttt{findValuation} \texttt{saturate} tritt dieser Fall nur
      ein, wenn sich die leere Klausel $\{\}$ aus den Klauseln der Menge $M$ mit Hilfe der
      Schnitt-Regel herleiten l\"{a}sst.  Dann haben wir also
      \\[0.2cm]
      \hspace*{1.3cm}
      $M \vdash \{\}$,
      \\[0.2cm]
      was zu zeigen war.
\item Fall: Die Funktion \texttt{findValuation} liefert als Ergebnis eine aussagenlogische Belegung
      $\I$.  Bei der Diskussion der Funktion \texttt{findValuation} haben wir gezeigt, dass f\"{u}r
      alle Klauseln $d \in \mathtt{clauses}$
      \\[0.2cm]
      \hspace*{1.3cm}
      $\I(d) = \mathtt{true}$
      \\[0.2cm]
      gilt.  Die Menge $M$ ist aber eine Teilmenge der Menge \texttt{clauses} und damit sehen wir, dass die
      Menge $M$ erf\"{u}llbar ist.  Dies steht im Widerspruch zu $M \models \falsum$ und folglich kann der
      zweite Fall gar nicht auftreten. 
\end{enumerate}
Folglich liefert die Funktion \texttt{findValuation} f\"{u}r eine unerf\"{u}llbare Menge von Klauseln immer
das Ergebnis \texttt{false}, was impliziert, dass $M \vdash \{\}$ gilt.  \qed

\section{Das Verfahren von Davis und Putnam}
In der Praxis stellt sich oft die Aufgabe, f\"{u}r eine gegebene Menge von Klauseln $K$ eine
Belegung $\I$ der Variablen zu berechnen, so dass 
\\[0.2cm]
\hspace*{1.3cm} $\mathtt{eval}(k,\I) = \mathtt{true}$ \quad f\"{u}r alle $k\in K$ \\[0.2cm]
gilt.  In diesem Fall sagen wir auch, dass die Belegung $\I$ eine \colorbox{yellow}{\emph{L\"{o}sung}} der
 Klausel-Menge $K$ ist.  Im letzten Abschnitt haben wir bereits die Prozedur \texttt{findValuation}
 kennengelernt, mit der wir eine solche Belegung berechnen k\"{o}nnten.
Bedauerlicherweise ist diese Prozedur f\"{u}r eine praktische Anwendung nicht effizient genug.
Wir werden daher in diesem Abschnitt ein Verfahren vorstellen, mit dem die Berechnung einer L\"{o}sung
einer aussagenlogischen Klausel-Menge auch in der Praxis m\"{o}glich ist.
Dieses Verfahren geht auf Davis und Putnam
\cite{davis62} zur\"{u}ck.  Verfeinerungen dieses Verfahrens werden beispielsweise
eingesetzt, um die Korrektheit digitaler elektronischer Schaltungen nachzuweisen.  

Um das Verfahren zu motivieren \"{u}berlegen wir zun\"{a}chst, bei welcher Form der Klausel-Menge $K$
unmittelbar klar ist, ob es eine Belegung gibt, die $K$ l\"{o}st und wie diese Belegung
aussieht.  Betrachten wir dazu ein Beispiel: \\[0.2cm]
\hspace*{1.3cm} 
$K_1 = \bigl\{\; \{p\},\; \{\neg q\},\; \{r\},\; \{\neg s\}, \; \{\neg t\} \;\bigr\}$ 
\\[0.2cm]
Die Klausel-Menge $K_1$ entspricht der aussagenlogischen Formel
\\[0.2cm]
\hspace*{1.3cm}
$p \wedge \neg q \wedge r \wedge \neg s \wedge \neg t$.
\\[0.2cm]
Daher ist $K_1$ l\"{o}sbar und die Belegung  \\[0.2cm]
\hspace*{1.3cm} 
$\I = \bigl\{\; \pair(p, \mathtt{true}),\; \pair(q, \mathtt{false}),\;\pair(r, \mathtt{true}),\; \pair(s, \mathtt{false}),\; \pair(t, \mathtt{false})\;\}$
\\[0.2cm]
ist eine L\"{o}sung.  Betrachten wir eine weiteres Beispiel: \\[0.2cm]
\hspace*{1.3cm} 
$K_2 = \bigl\{\; \{\}, \{p\},\; \{\neg q\},\; \{r\}\; \bigr\}$ 
\\[0.2cm]
Diese Klausel-Menge entspricht der Formel
\\[0.2cm]
\hspace*{1.3cm}
$\falsum \wedge p \wedge \neg q \wedge r$.
\\[0.2cm]
Offensichtlich ist $K_2$ unl\"{o}sbar.  Als letztes Beispiel betrachten wir 
\\[0.2cm]
\hspace*{1.3cm} $K_3 = \bigl\{ \{p\}, \{\neg q\}, \{\neg p\} \bigr\}$.
\\[0.2cm]
Diese Klausel-Menge kodiert die Formel
\\[0.2cm]
\hspace*{1.3cm}
$p \wedge \neg q \wedge \neg p $
\\[0.2cm]
Offenbar ist $K_3$ ebenfalls unl\"{o}sbar, denn eine L\"{o}sung $\I$ m\"{u}sste $p$ gleichzeitig
wahr und falsch machen.
Wir nehmen die an den letzten drei Beispielen gemachten Beobachtungen zum Anlass f\"{u}r zwei Definitionen.

\begin{Definition}[Unit-Klausel]
  Eine Klausel $k$ hei\3t \colorbox{yellow}{\emph{Unit-Klausel}}, wenn $k$ nur aus einem Literal besteht.
  Es gilt dann \\[0.2cm]
  \hspace*{1.3cm} $k = \{p\}$ \quad oder \quad $k = \{\neg p\}$ \\[0.2cm]
  f\"{u}r eine Aussage-Variable $p$. \eox
\end{Definition}

\begin{Definition}[Triviale Klausel-Mengen]
  Eine Klausel-Menge $K$ hei\3t \colorbox{yellow}{\emph{trivial}} wenn einer der beiden folgenden F\"{a}lle
  vorliegt.
  \begin{enumerate}
  \item $K$ enth\"{a}lt die leere Klausel: $\{\} \el K$.

        In diesem Fall ist $K$ offensichtlich unl\"{o}sbar.
  \item $K$ enth\"{a}lt nur Unit-Klausel mit verschiedenen Aussage-Variablen.
        Bezeichnen wir die Menge der aussagenlogischen Variablen mit $\mathcal{P}$,
        so schreibt sich diese Bedingung als 
        \\[0.3cm]
        \hspace*{1.3cm}
        $\forall k \el K: \textsl{card}(k) = 1$ \quad und \quad
        $\forall p \el \mathcal{P}: \neg\bigl( \{p\} \in K \wedge \{\neg p\} \in K\bigr)$.
        \\[0.3cm]
        Dann ist die aussagenlogische Belegung
        \\[0.2cm]
        \hspace*{1.3cm}
        $ \I = \bigl\{ \pair(p, \mathtt{true}) \mid \{p\} \in K \bigr\} \,\cup\, \bigl\{
             \pair(p, \mathtt{false}) \mid \{\neg p\} \in K \bigr\} 
        $
        \\[0.2cm]
        eine L\"{o}sung von $K$. \eox
  \end{enumerate}
\end{Definition}


Wie k\"{o}nnen wir nun eine Menge von Klauseln so vereinfachen, dass die Menge schlie\3lich nur
noch aus Unit-Klauseln besteht?  Es gibt drei
M\"{o}glichkeiten, Klauselmengen zu vereinfachen:
\begin{enumerate}
\item Schnitt-Regel,
\item Subsumption und
\item Fallunterscheidung.
\end{enumerate}
Wir betrachten diese M\"{o}glickeiten jetzt der Reihe nach.

\subsection{Vereinfachung mit der Schnitt-Regel}
Eine typische Anwendung der Schnitt-Regel hat die Form: \\[0.2cm]
\hspace*{1.3cm} $\schluss{ k_1 \cup \{p\} \quad \{\neg p\} \cup k_2}{k_1 \cup k_2}$
\\[0.2cm]
Die hierbei erzeugte Klausel $k_1 \cup k_2$ wird in der Regel mehr Literale enthalten
als die Pr\"{a}missen $k_1 \cup \{p\}$ und $\bigl\{\neg p\} \cup k_2$.  Enth\"{a}lt die
Klausel $k_1 \cup \{p\}$ insgesamt $m+1$ Literale und enth\"{a}lt die Klausel
$\bigl\{\neg p\} \cup k_2$ insgesamt $n+1$ Literale, so kann die Konklusion $k_1 \cup k_2$ 
insgesamt $m + n$ Literale enthalten.  Nat\"{u}rlich k\"{o}nnen es auch weniger Literale 
sein, und zwar dann, wenn es Literale gibt, die sowohl in $k_1$ als auch in $k_2$
auftreten.  Im allgemeinen ist $m + n$ gr\"{o}\3er als $m + 1$ und als $n + 1$.  Die
Klauseln wachsen nur dann sicher nicht, wenn entweder $n = 0$ oder $m = 0$ ist.
Dieser Fall liegt vor, wenn einer der beiden Klauseln nur aus einem Literal besteht
und folglich eine \emph{Unit-Klausel} ist.  Da es unser Ziel ist, die Klausel-Mengen
zu vereinfachen, lassen wir nur solche Anwendungen der Schnitt-Regel zu, bei denen
eine der Klausel eine Unit-Klausel ist.  Solche Schnitte bezeichnen wir als
\colorbox{yellow}{\emph{Unit-Schnitte}}.  Um alle mit einer gegebenen Unit-Klausel $\{l\}$ m\"{o}glichen Schnitte
durchf\"{u}hren zu k\"{o}nnen, definieren wir eine Funktion
\\[0.2cm]
\hspace*{1.3cm}
$\textsl{unitCut}: 2^\mathcal{K} \times \mathcal{L} \rightarrow 2^\mathcal{K}$
\\[0.2cm]
so, dass f\"{u}r eine Klausel-Menge $K$ und ein Literal $l$ die Funktion
$\textsl{unitCut}(K,l)$ die Klausel-Menge $K$ soweit wie m\"{o}glich mit Unit-Schnitten mit der Klausel
$\{l\}$ vereinfacht:
\\[0.2cm]
\hspace*{1.3cm}
$\textsl{unitCut}(K,l) = \Bigl\{ k \backslash \bigl\{ \komplement{\,l\,} \bigr\} \;\Big|\; k \in K \Bigr\}$.
\\[0.2cm]
Beachten Sie, dass die Menge $\textsl{unitCut}(K,l)$ genauso viele Klauseln enth\"{a}lt wie die Menge
$K$.  Allerdings sind die Klauseln aus der Menge $K$, die das Literal $\komplement{\,l\,}$
enthalten, verk\"{u}rzt worden. 

\subsection{Vereinfachung durch Subsumption}
Das Prinzip der Subsumption demonstrieren wir zun\"{a}chst an einem Beispiel.
Wir betrachten \\[0.2cm]
\hspace*{1.3cm} $K = \bigl\{ \{p, q, \neg r\}, \{p\} \bigr\} \cup M$. \\[0.2cm]
Offenbar impliziert die Klausel $\{p\}$ die Klausel $\{p, q, \neg r\}$, denn immer wenn
$\{p\}$ erf\"{u}llt ist, ist automatisch auch $\{q, p, \neg r\}$ erf\"{u}llt.  Das liegt daran, dass 
\\[0.2cm]
\hspace*{1.3cm} $\models p \rightarrow q \vee p \vee \neg r$
\\[0.2cm]
gilt.  Allgemein sagen wir, dass eine Klausel $k$
 von einer Unit-Klausel $u$ \colorbox{yellow}{\emph{subsumiert}} wird, wenn
\\[0.2cm]
\hspace*{1.3cm} $u \subseteq k$ \\[0.2cm]
gilt.  Ist $K$ eine Klausel-Menge mit $k \in K$ und $u \in K$ und wird
$k$ durch $u$ subsumiert, so k\"{o}nnen wir $K$ durch Unit-Subsumption zu $K - \{k\}$
vereinfachen, indem wir die Klausel $k$ aus $K$ l\"{o}schen.  Allgemein definieren wir eine Funktion
\\[0.2cm]
\hspace*{1.3cm}
$\textsl{subsume}: 2^\mathcal{K} \times \mathcal{L} \rightarrow 2^\mathcal{K}$
\\[0.2cm]
die eine gegebene Klauselmenge $K$, welche die Unit-Klausel $\{l\}$ enth\"{a}lt, mittels Subsumption 
dadurch vereinfacht, dass alle durch $\{l\}$ subsumierten Klauseln aus $K$ gel\"{o}scht werden.
Die Unit-Klausel $\{l\}$ behalten wir nat\"{u}rlich.  Daher definieren wir:
\\[0.2cm]
\hspace*{1.3cm}
$\textsl{subsume}(K, l) := 
\bigl(K \backslash \bigl\{ k \in K \mid l \in k \bigr\}\bigr) \cup \bigl\{\{l\}\bigr\} = 
\bigl\{ k \in K \mid l \not\in k \bigr\} \cup \bigl\{\{l\}\bigr\}$.
\\[0.2cm]
In der obigen Definition muss $\{l\}$ in das Ergebnis eingef\"{u}gt werden, weil die Menge
$\bigl\{ k \in K \mid l \not\in k \bigr\}$ die Unit-Klausel $\{l\}$ nicht enth\"{a}lt.


\subsection{Vereinfachung durch Fallunterscheidung}
Ein Kalk\"{u}l, der nur mit Unit-Schnitten und Subsumption arbeitet, ist nicht 
widerlegungs-vollst\"{a}ndig.  Wir brauchen 
daher eine weitere M\"{o}glichkeit, Klausel-Mengen zu vereinfachen.
Eine solche M\"{o}glichkeit bietet das Prinzip der
\colorbox{yellow}{\emph{Fallunterscheidung}}.  Dieses Prinzip basiert auf dem folgenden
Satz.

\begin{Satz}
  Ist $K$ eine Menge von Klauseln und ist $p$ eine aussagenlogische Variable, 
  so ist $K$ genau dann erf\"{u}llbar, wenn $K \cup \bigl\{\{p\}\bigr\}$ oder 
  $K \cup \bigl\{\{\neg p\}\bigr\}$ erf\"{u}llbar ist.  
\end{Satz}
Beweis: 
Ist $K$ erf\"{u}llbar durch eine
Belegung $\I$, so gibt es f\"{u}r  $\I(p)$ zwei M\"{o}glichkeiten:  Falls $\I(p) = \mathtt{true}$ ist, ist
damit auch die Menge $K \cup \bigl\{\{p\}\bigr\}$ erf\"{u}llbar, andernfalls ist
$K \cup \bigl\{\{\neg p\}\bigr\}$ erf\"{u}llbar. 

Da $K$ sowohl eine Teilmenge von $K \cup \bigl\{\{p\}\bigr\}$ als auch von 
$K \cup \bigl\{\{\neg p\}\bigr\}$ ist, ist klar, dass $K$ erf\"{u}llbar
ist, wenn eine dieser Mengen erf\"{u}llbar sind.  
\qed

Wir k\"{o}nnen nun eine Menge $K$ von Klauseln dadurch vereinfachen, dass wir eine
aussagenlogische Variable $p$ w\"{a}hlen, die in $K$ vorkommt.
Anschlie\3end bilden wir die Mengen \\[0.2cm]
\hspace*{1.3cm} $K_1 := K \cup \bigl\{\{p\}\bigr\}$ \quad und \quad $K_2 := K \cup
\bigl\{\{\neg p\}\bigr\}$
\\[0.2cm]
und untersuchen rekursiv ob $K_1$ erf\"{u}llbar ist.  Falls wir eine L\"{o}sung f\"{u}r $K_1$ finden,
ist dies auch eine L\"{o}sung f\"{u}r die urspr\"{u}ngliche Klausel-Menge $K$ und wir haben unser Ziel
erreicht.
Andernfalls untersuchen wir rekursiv ob $K_2$ erf\"{u}llbar ist.
Falls wir nun eine L\"{o}sung finden, ist dies auch eine L\"{o}sung von $K$ und wenn wir f\"{u}r $K_2$
keine L\"{o}sung finden, dann hat auch $K$ keine L\"{o}sung.
Die rekursive Untersuchung von $K_1$ bzw.~$K_2$ ist leichter,
weil ja wir dort mit den Unit-Klausel $\{p\}$ bzw.~$\{\neg p\}$
zun\"{a}chst Unit-Subsumption und anschlie\3end Unit-Schnitte durchf\"{u}hren k\"{o}nnen.


\subsection{Der Algorithmus}
Wir k\"{o}nnen jetzt den Algorithmus von Davis und Putnam skizzieren.
Gegeben sei eine Menge $K$ von Klauseln.  Gesucht ist dann eine L\"{o}sung von $K$.  Wir
suchen  also eine Belegung $\I$, so dass gilt: \\[0.2cm]
\hspace*{1.3cm} $\I(k) = \mathtt{true}$ \quad f\"{u}r alle $k \in K$.\\[0.2cm]
Das Verfahren von Davis und Putnam besteht nun aus den folgenden Schritten.
\begin{enumerate}
\item F\"{u}hre alle Unit-Schnitte aus, die mit Klauseln aus $K$ m\"{o}glich sind und f\"{u}hre
      zus\"{a}tzlich alle Unit-Subsumptionen aus.
\item Falls $K$ nun trivial ist, sind wir fertig.
\item Andernfalls w\"{a}hlen wir eine aussagenlogische Variable $p$, die in $K$ auftritt.
      \begin{enumerate}
      \item Jetzt versuchen  wir rekursiv  die Klausel-Menge \\[0.2cm]
            \hspace*{1.3cm}  $K \cup \bigl\{\{p\}\bigr\}$ \\[0.2cm]
            zu l\"{o}sen. Falls diese gelingt, haben wir eine L\"{o}sung von $K$.
      \item Andernfalls versuchen wir  die Klausel-Menge \\[0.2cm]
            \hspace*{1.3cm} $K \cup \bigl\{\{\neg p\}\bigr\}$ \\[0.2cm]
            zu l\"{o}sen.  Wenn auch dies fehlschl\"{a}gt, ist $K$ unl\"{o}sbar, andernfalls
            haben wir eine L\"{o}sung von $K$.
      \end{enumerate}
\end{enumerate}
F\"{u}r die Implementierung ist es zweckm\"{a}\3ig, die beiden oben definierten Funktionen $\textsl{unitCut}()$ und
$\textsl{subsume}()$ zusammen zu fassen.  Wir definieren eine Funktion
\\[0.2cm]
\hspace*{1.3cm}
$\textsl{reduce}: 2^\mathcal{K} \times \mathcal{L} \rightarrow 2^\mathcal{K}$
\\[0.2cm]
wie folgt: 
\\[0.2cm]
\hspace*{1.3cm}
$\textsl{reduce}(K,l)  = 
 \bigl\{\, k \backslash \{\komplement{l}\} \;|\; k \in K \wedge \komplement{l} \in k \,\bigr\} 
       \,\cup\, \bigl\{\, k \in K \mid \komplement{l} \not\in k \wedge l \not\in k \} \cup \bigl\{\{l\}\bigr\}.
$
\\[0.2cm]
Die Menge enth\"{a}lt also einerseits die Ergebnisse von Schnitten mit
der Unit-Klausel $\{l\}$ und andererseits nur noch die Klauseln $k$,
die mit $l$ nichts zu tun haben weil weder $l \in k$ noch $\komplement{l} \in k$
gilt.  Au\3erdem f\"{u}gen wir auch noch die Unit-Klausel $\{l\}$ hinzu.
Dadurch erreichen wir, dass die beiden Mengen $K$ und $\textsl{reduce}(K,l)$
logisch \"{a}quivalent sind, wenn wir dieses Mengen als Formeln in konjunktiver Normalform
interpretieren.  



\subsection{Ein Beispiel}
Zur Veranschaulichung demonstrieren wir das Verfahren von Davis und Putnam an einem Beispiel.
Die Menge $K$ sei wie folgt definiert: \\[0.2cm]
\hspace*{1.3cm} $K := \Big\{ \{p, q, s\},\; \{\neg p, r, \neg t\},\;  \{r, s\},\; \{\neg r, q, \neg p\},$ \\
\hspace*{2.5cm} $\{\neg s, p\},\; \{\neg p, \neg q, s, \neg r\},\; \{p, \neg q, s\},\; \{\neg r, \neg s\},\; \{\neg p, \neg s\} \Big\}  $. \\[0.2cm]
Wir zeigen nun mit dem Verfahren von Davis und Putnam, dass $K$ nicht l\"{o}sbar ist.  Da die
Menge $K$ keine Unit-Klauseln enth\"{a}lt, ist im ersten Schritt nichts zu tun.  Da $K$ nicht
trivial ist, sind wir noch nicht fertig.  Also gehen wir jetzt zu Schritt 3 und w\"{a}hlen
eine aussagenlogische Variable, die in $K$ auftritt.  An dieser Stelle ist es sinnvoll
eine Variable zu w\"{a}hlen, die in m\"{o}glichst vielen Klauseln von $K$ auftritt.  Wir w\"{a}hlen
daher die aussagenlogische Variable $p$.
\begin{enumerate}
\item Zun\"{a}chst bilden wir die Menge \\[0.2cm]
      \hspace*{1.3cm} $K_0 := K \cup \bigl\{ \{p\} \bigr\}$       \\[0.2cm]
      und versuchen, diese Menge zu l\"{o}sen.  Dazu bilden wir \\[0.2cm]
      \hspace*{0.3cm} 
      $K_1 := \textsl{reduce}\bigl(K_0,p\bigr) = 
          \Big\{ \{r, \neg t\},\; \{r, s\},\; \{\neg r, q\},\; \{\neg q, s, \neg r\},\; \{\neg r, \neg s\},\; \{ \neg s\},\;\{p\}\, \Big\}$.
      \\[0.2cm]
      Die Klausel-Menge $K_1$ enth\"{a}lt die Unit-Klausel $\{\neg s\}$,
      so dass wir als n\"{a}chstes mit dieser Klausel reduzieren k\"{o}nnen: \\[0.2cm]
      \hspace*{1.3cm} 
      $K_2 := \textsl{reduce}\bigl(K_1,\;\neg s\bigr) = 
              \Big\{ \{r, \neg t\},\; \{r\},\; \{\neg r, q\},\; \{\neg q, \neg r\},\; \{ \neg s\},\; \{p\} \Big\}$.
      \\[0.2cm]
      Hier haben wir nun die neue Unit-Klausel $\{r\}$, mit der wir als n\"{a}chstes reduzieren:
      \\[0.2cm]
      \hspace*{1.3cm} 
      $K_3 := \textsl{reduce}\bigl(K_2,\; r\bigr) = 
              \Big\{ \{r\},\; \{q\},\; \{\neg q\},\; \{ \neg s\},\; \{p\} \Big\}$
      \\[0.2cm]
      Da $K_3$ die Unit-Klausel $\{q\}$ enth\"{a}lt, reduzieren wir jetzt mit $q$: \\[0.2cm]
      \hspace*{1.3cm} 
      $K_4 := \textsl{reduce}\bigl(K_2,\;q\bigr) = 
              \Big\{ \{r\},\; \{q\},\; \{\},\; \{ \neg s\},\; \{p\} \Big\}$.
      \\[0.2cm]
      Die Klausel-Menge $K_4$ enth\"{a}lt die leere Klausel und ist damit unl\"{o}sbar.
     
\item Also bilden wir jetzt die Menge \\[0.2cm]
      \hspace*{1.3cm} $K_5 := K \cup \bigl\{ \{\neg p\} \bigr\}$ \\[0.2cm]
      und versuchen, diese Menge zu l\"{o}sen.  Dazu bilden wir
      \\[0.2cm]
      \hspace*{1.3cm} 
      $K_6 = \textsl{reduce}\bigl(K_5,\; \neg p\bigr) =\Big\{ \{q, s\},\; \{r, s\},\;\{\neg s\},\; \{\neg q, s\},\; \{\neg r, \neg s\},\;\{\neg p\}\, \Big\}$.
      \\[0.2cm]
      Die Menge $K_6$ enth\"{a}lt die  Unit-Klausel $\{\neg s\}$.  Wir bilden daher \\[0.2cm]
      \hspace*{1.3cm} 
      $K_7 = \textsl{reduce}\bigl(K_6,\; \neg s\bigr) =\Big\{ \{q\},\; \{r\},\;\{\neg s\},\; \{\neg q\},\;\{\neg p\}\, \Big\}$.
      \\[0.2cm]
      Die Menge $K_7$ enth\"{a}lt die neue Unit-Klausel $\{q\}$, mit der wir als n\"{a}chstes reduzieren:\\[0.2cm]
      \hspace*{1.3cm} 
      $K_8 = \textsl{reduce}\bigl(K_7,\; q \bigr) =\Big\{ \{q\},\; \{r\},\;\{\neg s\},\; \{\},\;\{\neg p\}\, \Big\}$.
      \\[0.2cm]
      Da $K_8$ die leere Klausel enth\"{a}lt, ist $K_8$ und damit auch die urspr\"{u}nglich
      gegebene Menge $K$ unl\"{o}sbar.
\end{enumerate}
Bei diesem Beispiel hatten wir Gl\"{u}ck, denn wir mussten nur eine einzige Fallunterscheidung
durchf\"{u}hren. Bei komplexeren Beispielen ist es h\"{a}ufig so, dass wir mehrere Fallunterscheidungen
durchf\"{u}hren m\"{u}ssen.

\subsection{Implementierung des Algorithmus von Davis und Putnam}
Wir zeigen jetzt die Implementierung der Prozedur \texttt{davisPutnam}, 
mit der die Frage, ob eine Menge von Klauseln erf\"{u}llbar ist, beantwortet werden kann. Die
Implementierung ist in Abbildung \ref{fig:davisPutnam} auf Seite \pageref{fig:davisPutnam}
gezeigt.  Die Prozedur erh\"{a}lt zwei Argumente: \texttt{clauses} und \texttt{literals}.
\texttt{clauses} ist eine Menge von Klauseln und \texttt{literals} ist eine Menge von
Literalen.  Falls  die Vereinigung dieser beiden Mengen erf\"{u}llbar ist, so liefert
der Aufruf 
\\[0.2cm]
\hspace*{1.3cm}
\texttt{davisPutnam(clauses, literals)} 
\\[0.2cm]
eine Menge von Unit-Klauseln \texttt{r}, so
dass jede Belegung $\I$, die alle Unit-Klauseln aus \texttt{r} erf\"{u}llt, auch die
Menge $\mathtt{clauses} \cup \mathtt{literals}$ erf\"{u}llt.  Falls die Menge
$\mathtt{clauses} \cup \mathtt{literals}$ nicht erf\"{u}llbar ist, liefert der Aufruf
\\[0.2cm]
\hspace*{1.3cm}
\texttt{davisPutnam(clauses, literals)} 
\\[0.2cm]
als Ergebnis die Menge $\bigl\{ \{\} \bigr\}$ zur\"{u}ck,
denn die leere Klausel repr\"{a}sentiert die unerf\"{u}llbare Formel $\falsum$.

Sie fragen sich vielleicht, wozu wir in der Prozedur \texttt{davisPutnam} die Menge
\texttt{literals} brauchen.  Der Grund ist, dass wir uns bei den rekursiven Aufrufen
merken m\"{u}ssen, welche Literale wir schon benutzt haben.  Diese Literale sammeln wir in der
Menge \texttt{literals}.

Die in Abbildung \ref{fig:davisPutnam} gezeigte Implementierung funktioniert wie folgt:
\begin{enumerate}
\item In Zeile 2 reduzieren wir mit Hilfe der Methode \texttt{saturate} 
      solange wie m\"{o}glich die gegebene Klausel-Menge \texttt{clauses} mit Hilfe
      von Unit-Schnitten und entfernen alle Klauseln die durch Unit-Klauseln
      subsumiert werden.
\item Anschlie\3end testen wir in Zeile 3, ob die so vereinfachte Klausel-Menge
      die leere Klausel enth\"{a}lt und geben in diesem Fall als Ergebnis die Menge 
      $\bigl\{\{\}\bigr\}$ zur\"{u}ck.
\item Dann testen wir in Zeile 6, ob bereits alle Klauseln $c$ aus der Menge
      \texttt{clauses} Unit-Klauseln sind.  Wenn dies so ist,
      dann ist die Menge \texttt{clauses} trivial und wir geben diese Menge als Ergebnis zur\"{u}ck.
\item Andernfalls w\"{a}hlen wir in Zeile 9 ein Literal $l$ aus der Menge \texttt{clauses}, 
      dass wir noch nicht benutzt haben.
      Wir untersuchen dann in Zeile 10 rekursiv, ob die Menge \\[0.2cm]
      \hspace*{1.3cm} 
      $\mathtt{clauses} \cup \bigl\{\{\mathtt{l}\}\bigr\}$ 
      \\[0.2cm]
      l\"{o}sbar ist.  Dabei gibt es zwei F\"{a}lle:
      \begin{enumerate}
      \item Falls diese Menge l\"{o}sbar ist, geben wir die L\"{o}sung dieser Menge als Ergebnis zur\"{u}ck.

      \item Sonst  pr\"{u}fen wir rekursiv, ob die Menge \\[0.2cm]
            \hspace*{1.3cm} $\mathtt{clauses} \cup \bigl\{ \{ \neg \mathtt{l}\} \bigr\}$ \\[0.2cm]
            l\"{o}sbar ist.  
      \end{enumerate}
\end{enumerate}
\begin{figure}[!ht]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.2cm,
                  xrightmargin  = 0.2cm
                ]
    davisPutnam := procedure(clauses, literals) {
        clauses := saturate(clauses);
        if ({} in clauses) {
            return { {} };
        }
        if (forall (c in clauses | #c == 1)) {
            return clauses;
        }
        l := selectLiteral(clauses, literals);
        notL := negateLiteral(l);    
        r := davisPutnam(clauses + { {l} }, literals + { l, notL });
        if (r != { {} }) {
            return r;
        }     
        return davisPutnam(clauses + { {notL} }, literals + { l, notL });
    };
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{Die Prozedur \texttt{davisPutnam}.}
  \label{fig:davisPutnam}
\end{figure} 

Wir diskutieren nun die Hilfsprozeduren, die bei der Implementierung der Prozedur
\texttt{davisPutnam} verwendet wurden.
Als erstes besprechen wir die Funktion \texttt{saturate}.  Diese Prozedur erh\"{a}lt eine
Menge $s$ von Klauseln als Eingabe und f\"{u}hrt alle m\"{o}glichen Unit-Schnitte und
Unit-Subsumptionen durch.  
Die Prozedur \texttt{saturate} ist in Abbildung \ref{fig:saturate} auf Seite \pageref{fig:saturate}
gezeigt.

\begin{figure}[!ht]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm
                ]
    saturate := procedure(s) {
        units := { k in s | #k == 1 };
        used := {};
        while (units != {}) {
            unit  := arb(units);
            used  := used + { unit };
            l     := arb(unit);
            s     := reduce(s, l);
            units := { k in s | #k == 1 } - used;        
        }
        return s;
    };
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{Die Prozedur \texttt{saturate}.}
  \label{fig:saturate}
\end{figure} 
Die Implementierung von \texttt{saturate} funktioniert wie folgt: 
\begin{enumerate}
\item Zun\"{a}chst berechnen wir in Zeile 2 die Menge \texttt{units} aller Unit-Klauseln.  
\item Dann initialisieren wir in Zeile 3 die Menge \texttt{used} als die leere Menge.
      In dieser Menge merken wir uns, welche Unit-Klauseln wir schon f\"{u}r Unit-Schnitte und
      Subsumptionen benutzt haben.
\item Solange die Menge \texttt{units} der Unit-Klauseln nicht leer ist, w\"{a}hlen wir in Zeile 5
      eine beliebige Unit-Klausel \texttt{unit} aus der Menge \texttt{units} aus.
\item In Zeile 6 f\"{u}gen wir die Klausel \texttt{unit} zu der Menge
      \texttt{used} der benutzten Klausel hinzu.  
\item In Zeile 7 extrahieren mit \texttt{arb} das Literal \texttt{l} der Klausel \texttt{unit}.  
\item In Zeile 8 wird  die eigentliche Arbeit durch einen Aufruf der Prozedur
      \texttt{reduce} geleistet.  Diese Funktion berechnet alle Unit-Schnitte, die mit der
      Unit-Klausel $\{\texttt{l}\}$ m\"{o}glich sind und entfernt dar\"{u}ber hinaus alle Klauseln, die
      durch die Unit-Klausel $\{\texttt{l}\}$ subsumiert werden.
\item Wenn die Unit-Schnitte mit der Unit-Klausel $\{\texttt{l}\}$ berechnet werden, k\"{o}nnen neue
      Unit-Klauseln entstehen, die wir in Zeile 9 aufsammeln.  Wir sammeln dort aber nur die Unit-Klauseln auf,
       die wir noch nicht benutzt haben. 
\item Die Schleife in den Zeilen 4 -- 10 wird nun solange durchlaufen, wie wir 
      Unit-Klauseln finden, die wir noch nicht benutzt haben.
\item Am Ende geben wir die verbliebende Klauselmenge als Ergebnis zur\"{u}ck.
\end{enumerate}
Die dabei verwendete Prozedur $\texttt{reduce}()$ ist in Abbildung \ref{fig:reduce} gezeigt.
Im vorigen Abschnitt hatten wir die Funktion $\textsl{reduce}(K,l)$, die eine
Klausel-Menge $K$ mit Hilfe des Literals $l$ reduziert, als
\\[0.2cm]
\hspace*{1.3cm}
$\textsl{reduce}(K,l)  = 
 \bigl\{\, k \backslash \{\komplement{l}\} \;|\; k \in K \wedge \komplement{l} \in k \,\bigr\} 
       \,\cup\, \bigl\{\, k \in K \mid \komplement{l} \not\in k \wedge l \not\in k \} \cup \bigl\{\{l\}\bigr\}
$
\\[0.2cm]
definiert.
Die Implementierung setzt diese Definition unmittelbar um.  


\begin{figure}[!ht]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm
                ]
    reduce := procedure(s, l) {
        notL := negateLiteral(l);
        return   { k - { notL } : k in s | notL in k } 
               + { k in s | !(notL in k) && !(l in k) } 
               + { {l} };
    };
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{Die Prozedur \texttt{reduce}.}
  \label{fig:reduce}
\end{figure} 

Die Implementierung des Algorithmus von Davis und Putnam benutzt au\3er den bisher diskutierten Prozeduren
noch zwei weitere Hilfsprozeduren, deren Implementierung in 
Abbildung \ref{fig:solve-aux} auf Seite \pageref{fig:solve-aux} gezeigt wird.
\begin{enumerate}
\item Die Prozedur \texttt{selectLiteral} w\"{a}hlt ein beliebiges Literal aus 
      einer gegeben Menge $s$ von Klauseln aus, das au\3erdem nicht in der Menge
      \texttt{forbidden} von Literalen vorkommen darf, die bereits benutzt worden sind.
      Dazu werden alle Klauseln, die ja Mengen von Literalen sind, vereinigt.  Von dieser
      Menge wird dann die Menge der bereits benutzten Literalen abgezogen und aus der
      resultierenden Menge wird mit Hilfe der Funktion $\texttt{arb}()$ ein Literal ausgew\"{a}hlt.
\item Die Prozedur \texttt{negateLiteral} bildet die Negation $\komplement{l}$ 
      eines gegebenen Literals $l$.  
\end{enumerate}
\begin{figure}[!ht]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm
                ]
    selectLiteral := procedure(s, forbidden) {
        return arb(+/ s - forbidden);
    };
    negateLiteral := procedure(l) {
        match (l) {
            case !p : return p;
            case  p : return !p;
        }
    };
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{Die Prozeduren \texttt{select} und \texttt{negateLiteral}.}
  \label{fig:solve-aux}
\end{figure}

Die oben dargestellte Version des Verfahrens von Davis und Putnam l\"{a}sst sich in vielerlei
Hinsicht verbessern.  Aus Zeitgr\"{u}nden k\"{o}nnen wir auf solche Verbesserungen leider nicht
weiter eingehen. Der interessierte Leser sei hier auf die Arbeit \cite{moskewicz01}  verwiesen:
\\[0.2cm]
\hspace*{1.3cm} \textsl{Chaff: Engineering an Efficient SAT Solver} \\
\hspace*{1.3cm} von \emph{M. Moskewicz, C. Madigan, Y. Zhao, L. Zhang, S. Malik} 


\section{Das 8-Damen-Problem}
In diesem Abschnitt zeigen wir, wie bestimmte kombinatorische Problem in aussagenlogische
Probleme umformuliert werden k\"{o}nnen.  Diese
k\"{o}nnen dann anschlie\3end mit dem Algorithmus von Davis und Putnam bzw.~mit 
Verbesserungen dieses Algorithmus gel\"{o}st werden.  Als konkretes
Beispiel betrachten wir das 8-Damen-Problem.  Dabei geht es darum, 8 Damen so auf einem
Schach-Brett aufzustellen, dass keine Dame eine andere Dame schlagen kann.
Beim Schach-Spiel kann eine Dame dann eine andere Figur schlagen, wenn diese Figur
entweder 
\begin{itemize}
\item in derselben Zeile,
\item in derselben Spalte, oder
\item in derselben Diagonale
\end{itemize}
wie die Dame steht.  Abbildung \ref{fig:queens-problem} auf Seite \pageref{fig:queens-problem}
zeigt ein Schachbrett, in dem sich in der dritten Zeile in der vierten Spalte
eine Dame befindet.  Diese Dame kann auf alle die Felder ziehen, die mit Pfeilen markierte
sind, und kann damit Figuren, die sich auf diesen Feldern befinden, schlagen.

\begin{figure}[!ht]
  \centering
\setlength{\unitlength}{1.0cm}
\begin{picture}(10,9)
\thicklines
\put(1,1){\line(1,0){8}}
\put(1,1){\line(0,1){8}}
\put(1,9){\line(1,0){8}}
\put(9,1){\line(0,1){8}}
\put(0.9,0.9){\line(1,0){8.2}}
\put(0.9,9.1){\line(1,0){8.2}}
\put(0.9,0.9){\line(0,1){8.2}}
\put(9.1,0.9){\line(0,1){8.2}}
\thinlines
\multiput(1,2)(0,1){7}{\line(1,0){8}}
\multiput(2,1)(1,0){7}{\line(0,1){8}}
\put(4.15,6.15){{\chess Q}}
\multiput(5.25,6.5)(1,0){4}{\vector(1,0){0.5}}
\multiput(3.75,6.5)(-1,0){3}{\vector(-1,0){0.5}}
\multiput(5.25,7.25)(1,1){2}{\vector(1,1){0.5}}
\multiput(5.25,5.75)(1,-1){4}{\vector(1,-1){0.5}}
\multiput(3.75,5.75)(-1,-1){3}{\vector(-1,-1){0.5}}
\multiput(3.75,7.25)(-1,1){2}{\vector(-1,1){0.5}}
\multiput(4.5,7.25)(0,1){2}{\vector(0,1){0.5}}
\multiput(4.5,5.75)(0,-1){5}{\vector(0,-1){0.5}}
\end{picture}
\vspace*{-1.0cm}
  \caption{Das 8-Damen-Problem.}
  \label{fig:queens-problem}
\end{figure}

Als erstes \"{u}berlegen wir uns, wie wir ein Schach-Brett mit den darauf
positionierten Damen aussagenlogisch repr\"{a}sentieren k\"{o}nnen.  Eine M\"{o}glichkeit besteht darin, 
f\"{u}r jedes Feld eine aussagenlogische Variable einzuf\"{u}hren.  Diese Variable dr\"{u}ckt
aus, dass auf dem entsprechenden Feld eine Dame steht.  Wir ordnen diesen Variablen wie
folgt Namen zu:  Die Variable, die das $j$-te Feld in der $i$-ten
Zeile bezeichnet, stellen wir durch den Term \\[0.2cm]
\hspace*{1.3cm} $\mathtt{Var}(i,j)$ \quad mit $i,j \in \{1, \cdots, 8\}$ \\[0.2cm]
dar. Wir nummerieren die Zeilen dabei von oben beginnend von 1 bis 8 durch, w\"{a}hrend die
Spalten von links nach rechts numeriert werden.  Abbildung \ref{fig:queens-assign} auf
Seite \pageref{fig:queens-assign} zeigt die Zuordnung der Variablen zu den Feldern.

\begin{figure}[!ht]
  \centering
\setlength{\unitlength}{1.8cm}
\begin{picture}(10,9)
\thicklines
\put(0.9,0.9){\line(1,0){8.2}}
\put(0.9,9.1){\line(1,0){8.2}}
\put(0.9,0.9){\line(0,1){8.2}}
\put(9.1,0.9){\line(0,1){8.2}}
\put(1,1){\line(1,0){8}}
\put(1,1){\line(0,1){8}}
\put(1,9){\line(1,0){8}}
\put(9,1){\line(0,1){8}}
\thinlines
\multiput(1,2)(0,1){7}{\line(1,0){8}}
\multiput(2,1)(1,0){7}{\line(0,1){8}}

%%  for (i = 1; i <= 8; i = i + 1) {
%%for (j = 1; j <= 8; j = j + 1) \{
%%   \put(\$j.15,<9-$i>.35){{\Large p<$i>\$j}}
%%\}
%%  }

\put(1.15,8.40){{ Var(1,1) }}
\put(2.15,8.40){{ Var(1,2) }}
\put(3.15,8.40){{ Var(1,3) }}
\put(4.15,8.40){{ Var(1,4) }}
\put(5.15,8.40){{ Var(1,5) }}
\put(6.15,8.40){{ Var(1,6) }}
\put(7.15,8.40){{ Var(1,7) }}
\put(8.15,8.40){{ Var(1,8) }}
\put(1.15,7.40){{ Var(2,1) }}
\put(2.15,7.40){{ Var(2,2) }}
\put(3.15,7.40){{ Var(2,3) }}
\put(4.15,7.40){{ Var(2,4) }}
\put(5.15,7.40){{ Var(2,5) }}
\put(6.15,7.40){{ Var(2,6) }}
\put(7.15,7.40){{ Var(2,7) }}
\put(8.15,7.40){{ Var(2,8) }}
\put(1.15,6.40){{ Var(3,1) }}
\put(2.15,6.40){{ Var(3,2) }}
\put(3.15,6.40){{ Var(3,3) }}
\put(4.15,6.40){{ Var(3,4) }}
\put(5.15,6.40){{ Var(3,5) }}
\put(6.15,6.40){{ Var(3,6) }}
\put(7.15,6.40){{ Var(3,7) }}
\put(8.15,6.40){{ Var(3,8) }}
\put(1.15,5.40){{ Var(4,1) }}
\put(2.15,5.40){{ Var(4,2) }}
\put(3.15,5.40){{ Var(4,3) }}
\put(4.15,5.40){{ Var(4,4) }}
\put(5.15,5.40){{ Var(4,5) }}
\put(6.15,5.40){{ Var(4,6) }}
\put(7.15,5.40){{ Var(4,7) }}
\put(8.15,5.40){{ Var(4,8) }}
\put(1.15,4.40){{ Var(5,1) }}
\put(2.15,4.40){{ Var(5,2) }}
\put(3.15,4.40){{ Var(5,3) }}
\put(4.15,4.40){{ Var(5,4) }}
\put(5.15,4.40){{ Var(5,5) }}
\put(6.15,4.40){{ Var(5,6) }}
\put(7.15,4.40){{ Var(5,7) }}
\put(8.15,4.40){{ Var(5,8) }}
\put(1.15,3.40){{ Var(6,1) }}
\put(2.15,3.40){{ Var(6,2) }}
\put(3.15,3.40){{ Var(6,3) }}
\put(4.15,3.40){{ Var(6,4) }}
\put(5.15,3.40){{ Var(6,5) }}
\put(6.15,3.40){{ Var(6,6) }}
\put(7.15,3.40){{ Var(6,7) }}
\put(8.15,3.40){{ Var(6,8) }}
\put(1.15,2.40){{ Var(7,1) }}
\put(2.15,2.40){{ Var(7,2) }}
\put(3.15,2.40){{ Var(7,3) }}
\put(4.15,2.40){{ Var(7,4) }}
\put(5.15,2.40){{ Var(7,5) }}
\put(6.15,2.40){{ Var(7,6) }}
\put(7.15,2.40){{ Var(7,7) }}
\put(8.15,2.40){{ Var(7,8) }}
\put(1.15,1.40){{ Var(8,1) }}
\put(2.15,1.40){{ Var(8,2) }}
\put(3.15,1.40){{ Var(8,3) }}
\put(4.15,1.40){{ Var(8,4) }}
\put(5.15,1.40){{ Var(8,5) }}
\put(6.15,1.40){{ Var(8,6) }}
\put(7.15,1.40){{ Var(8,7) }}
\put(8.15,1.40){{ Var(8,8) }}

\end{picture}
\vspace*{-1.0cm}
  \caption{Zuordnung der Variablen.}
  \label{fig:queens-assign}
\end{figure}

Als n\"{a}chstes \"{u}berlegen wir uns, wie wir die einzelnen Bedingungen des 8-Damen-Problems 
als aussagenlogische
Formeln kodieren k\"{o}nnen.  Letztlich lassen sich alle Aussagen der Form
\begin{itemize}
\item ``in einer Zeile steht h\"{o}chstens eine Dame'', 
\item ``in einer Spalte steht h\"{o}chstens eine Dame'', oder 
\item ``in einer Diagonale steht h\"{o}chstens eine Dame'' 
\end{itemize}
auf dasselbe Grundmuster zur\"{u}ckf\"{u}hren:
Ist eine Menge von aussagenlogischen Variablen \\[0.2cm]
\hspace*{1.3cm} $V = \{ x_1, \cdots, x_n \}$ \\[0.2cm]
gegeben, so brauchen wir eine Formel die aussagt, dass \textbf{\emph{h\"{o}chstens}} eine der Variablen aus
$V$ den Wert \texttt{true} hat.  Das ist aber gleichbedeutend damit, dass f\"{u}r jedes Paar
$x_i, x_j \in V$ mit $x_i \not= x_j$ die folgende Formel gilt: \\[0.2cm]
\hspace*{1.3cm} $\neg (x_i \wedge x_j)$. \\[0.2cm]
Diese Formel dr\"{u}ckt aus, dass die Variablen $x_i$ und $x_j$ nicht gleichzeitig den Wert
\texttt{true} annehmen.  Nach den De\-Morgan'schen Gesetzen gilt
\\[0.2cm]
\hspace*{1.3cm}
$\neg (x_i \wedge x_j) \leftrightarrow \neg x_i \vee \neg x_j$
\\[0.2cm]
und die Klausel auf der rechten Seite dieser \"{A}quivalenz schreibt sich in Mengen-Schreibweise als
\\[0.2cm]
\hspace*{1.3cm}  $\{\neg x_i, \neg x_j \}$. \\[0.2cm]
Die Formel, die f\"{u}r eine Variablen-Menge $V$ ausdr\"{u}ckt, dass keine zwei verschiedenen
Variablen gleichzeitig gesetzt sind, kann daher als Klausel-Menge in der Form
\\[0.2cm]
\hspace*{1.3cm} $\bigl\{\, \{ \neg p, \neg q \} \;|\; p \in V \,\wedge\, q \in V
\,\wedge\, p \not= q \bigr\}$
\\[0.2cm]
geschrieben werden.
Wir setzen diese \"{U}berlegungen in eine \textsc{SetlX}-Prozedur um.  Die in Abbildung \ref{fig:atMostOne}
gezeigte Prozedur \texttt{atMostOne}() bekommt als Eingabe eine Menge $V$ von
aussagenlogischen Variablen.  Der Aufruf $\texttt{atMostOne}(V)$ berechnet eine Menge von
Klauseln.  Diese Klauseln sind genau dann wahr, wenn h\"{o}chstens eine der Variablen aus $V$
den Wert \texttt{true} hat.

\begin{figure}[!ht]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm
                ]
    atMostOne := procedure(v) {
        return { { !p, !q } : p in v, q in v | p != q };
    };
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{Die Prozedur \texttt{atMostOne}.}
  \label{fig:atMostOne}
\end{figure}

Mit Hilfe der Prozedur \texttt{atMostOne} k\"{o}nnen wir nun die Prozedur
\texttt{atMostOneInRow} implementieren.  Der Aufruf \\[0.2cm]
\hspace*{1.3cm} \texttt{atMostOneInRow}(\textsl{row}, n) \\[0.2cm]
berechnet f\"{u}r eine gegebene Zeile \textsl{row} bei einer Brettgr\"{o}\3e von $n$ eine Formel,
die ausdr\"{u}ckt, dass in der Zeile \textsl{row} h\"{o}chstens eine Dame steht.
Abbildung \ref{fig:atMostOneInRow} zeigt die
Prozedur $\texttt{atMostOneInRow}()$: Wir sammeln alle Variablen der durch \texttt{row}
spezifizierten Zeile
in der Menge 
\\[0.2cm]
\hspace*{1.3cm}
$\bigl\{ \mathtt{Var}(\mathtt{row},j) \mid j \in \{1, \cdots, n \} \bigr\}$
\\[0.2cm]
 auf und rufen mit dieser Menge die Hilfs-Prozedur $\texttt{atMostOne}()$ auf, die das Ergebnis
als Menge von Klauseln liefert.

\begin{figure}[!ht]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm
                ]
    atMostOneInRow := procedure(row, n) {
        return atMostOne({ Var(row, j) : j in [1 .. n] });
    };
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{Die Prozedur \texttt{atMostOneInRow}.}
  \label{fig:atMostOneInRow}
\end{figure}

Als n\"{a}chstes berechnen wir eine Formel die aussagt, dass mindestens eine Dame in einer gegebenen
Spalte steht.  F\"{u}r die erste Spalte h\"{a}tte diese Formel im Falle eine $8 \times 8$-Bretts die Form 
\\[0.2cm]
\hspace*{1.3cm}
$\texttt{Var}(1,1) \vee \texttt{Var}(2,1) \vee \texttt{Var}(3,1) \vee \texttt{Var}(4,1) \vee \texttt{Var}(5,1) \vee
\texttt{Var}(6,1) \vee \texttt{Var}(7,1) \vee \texttt{Var}(8,1)$
\\[0.2cm]
und wenn allgemein eine Spalte $c$ mit $c \in \{1,\cdots,8\}$ gegeben ist, lautet die Formel
\\[0.2cm]
\hspace*{1.3cm}
$\texttt{Var}(1,c) \vee \texttt{Var}(2,c) \vee \texttt{Var}(3,c) \vee \texttt{Var}(4,c) \vee \texttt{Var}(5,c) \vee
\texttt{Var}(6,c) \vee \texttt{Var}(7,c) \vee \texttt{Var}(8,c)$.
\\[0.2cm]
Schreiben wir diese Formel in der Mengenschreibweise als Menge von Klauseln, so erhalten wir
\\[0.2cm]
\hspace*{1.3cm}
$\bigl\{ \{\texttt{Var}(1,c) , \texttt{Var}(2,c) , \texttt{Var}(3,c) , \texttt{Var}(4,c) , \texttt{Var}(5,c) ,
\texttt{Var}(6,c) , \texttt{Var}(7,c) , \texttt{Var}(8,c) \}\bigr\}$.
\\[0.2cm]
Abbildung \ref{fig:oneInColumn} zeigt eine \textsc{SetlX}-Prozedur, die f\"{u}r eine gegebene Spalte
\texttt{column} und eine gegebene Brettgr\"{o}\3e \texttt{n }die entsprechende Klausel-Menge berechnet.
Der Schritt, von einer einzelnen Klausel 
zu einer Menge von Klauseln \"{u}berzugehen ist notwendig, da unsere Implementierung des Algorithmus von
Davis und Putnam ja mit einer Menge von Klauseln arbeitet.

\begin{figure}[!ht]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm
                ]
    oneInColumn := procedure(column, n) {
        return { { Var(row, column) : row in { 1 .. n } } };
    };
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{Die Prozedur \texttt{oneInColumn}.}
  \label{fig:oneInColumn}
\end{figure}

An dieser Stelle erwarten Sie vielleicht, dass wir noch Formeln angeben die
ausdr\"{u}cken, dass in einer gegebenen Spalte h\"{o}chstens eine Dame steht und dass in jeder
Reihe mindestens eine Dame steht.
Solche Formeln sind aber unn\"{o}tig, denn wenn wir wissen, dass in jeder Spalte mindestens
eine Dame steht, so wissen wir bereits, dass auf dem Brett mindestens 8 Damen stehen.
Wenn wir nun zus\"{a}tzlich wissen, dass in jeder Zeile h\"{o}chstens eine Dame steht, so ist
automatisch klar, dass in jeder Zeile genau eine Dame stehen muss, denn sonst kommen wir insgesamt
nicht auf 8 Damen.  Weiter folgt aus der Tatsache, dass in jeder Spalte eine Dame steht und daraus,
dass es insgesamt nicht mehr als 8 Damen sind, dass in jeder Spalte h\"{o}chstens eine Dame stehen kann.

Als n\"{a}chstes \"{u}berlegen wir uns, wie wir die Variablen, die auf derselben Diagonale
stehen, charakterisieren k\"{o}nnen.  Es gibt grunds\"{a}tzlich zwei verschiedene Arten von
Diagonalen: absteigende Diagonalen und aufsteigende Diagonalen.  Wir betrachten zun\"{a}chst
die aufsteigenden Diagonalen.  Die l\"{a}ngste aufsteigende Diagonale, wir sagen dazu auch
\emph{Hauptdiagonale}, besteht im Fall eines $8 \times 8$-Bretts aus den
Variablen \\[0.2cm]
\hspace*{1.3cm} 
$\texttt{Var}(8,1),\; \texttt{Var}(7,2),\; \texttt{Var}(6,3),\; \texttt{Var}(5,4),\; \texttt{Var}(4,5),\; \texttt{Var}(3,6),\; 
 \texttt{Var}(2,7),\; \texttt{Var}(1,8)$. 
\\[0.2cm]
Die Indizes $i$ und $j$ der Variablen $\mathtt{Var}(i,j)$ erf\"{u}llen offenbar
die Gleichung \\[0.2cm]
\hspace*{1.3cm} $i + j = 9$. \\[0.2cm]
Allgemein erf\"{u}llen die Indizes der Variablen einer aufsteigenden Diagonale die Gleichung \\[0.2cm]
\hspace*{1.3cm} $i + j = k$, \\[0.2cm]
wobei $k$ einen Wert aus der Menge $\{3, \cdots, 15 \}$ annimmt.  Diesen Wert $k$ geben
wir nun als Argument bei der Prozedur \texttt{atMostOneInUpperDiagonal} mit.  Diese
Prozedur ist in Abbildung \ref{fig:atMostOneInUpperDiagonal} gezeigt.

\begin{figure}[!ht]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm
                ]
    atMostOneInUpperDiagonal := procedure(k, n) {
        s := { Var(r, c) : c in [1..n], r in [1..n] | r + c == k };
        return atMostOne(s);
    };
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{Die Prozedur \texttt{atMostOneInUpperDiagonal}.}
  \label{fig:atMostOneInUpperDiagonal}
\end{figure}

Um zu sehen, wie die Variablen einer fallenden Diagonale
charakterisiert werden k\"{o}nnen, betrachten wir die fallende Hauptdiagonale, die aus den
Variablen \\[0.2cm]
\hspace*{1.3cm} 
$\texttt{Var}(1,1),\; \texttt{Var}(2,2),\; \texttt{Var}(3,3),\; \texttt{Var}(4,4),\; \texttt{Var}(5,5),\; 
 \texttt{Var}(6,6),\; \texttt{Var}(7,7),\; \texttt{Var}(8,8)$ 
\\[0.2cm]
besteht. Die Indizes  $i$ und $j$ dieser Variablen erf\"{u}llen offenbar
die Gleichung \\[0.2cm]
\hspace*{1.3cm} $i - j = 0$. \\[0.2cm]
Allgemein erf\"{u}llen die Indizes der Variablen einer absteigenden Diagonale die Gleichung \\[0.2cm]
\hspace*{1.3cm} $i - j = k$, \\[0.2cm]
wobei $k$ einen Wert aus der Menge $\{-6, \cdots, 6 \}$ annimmt.  Diesen Wert $k$ geben
wir nun als Argument bei der Prozedur \texttt{atMostOneInLowerDiagonal} mit.
Diese Prozedur ist in Abbildung \ref{fig:atMostOneInLowerDiagonal} gezeigt.

\begin{figure}[!ht]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm
                ]
    atMostOneInLowerDiagonal := procedure(k, n) {
        s := { Var(r, c) : c in [1..n], r in [1..n] | r - c == k };
        return atMostOne(s);
    };
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{Die Prozedur \texttt{atMostOneInLowerDiagonal}.}
  \label{fig:atMostOneInLowerDiagonal}
\end{figure}

Jetzt sind wir in der Lage, unsere Ergebnisse zusammen zu fassen:  Wir k\"{o}nnen eine
Menge von Klauseln konstruieren, die das 8-Damen-Problem vollst\"{a}ndig beschreibt.
Abbildung \ref{fig:allClauses} zeigt die Implementierung der Prozedur \texttt{allClauses}.
Der Aufruf \\[0.2cm]
\hspace*{1.3cm} $\mathtt{allClauses}(n)$ \\[0.2cm]
rechnet f\"{u}r ein Schach-Brett der Gr\"{o}\3e $n$ eine Menge von Klauseln aus, die
genau dann erf\"{u}llt sind, wenn auf dem Schach-Brett
\begin{enumerate}
\item in jeder Zeile h\"{o}chstens eine Dame steht (Zeile 2),
\item in jeder absteigenden Diagonale h\"{o}chstens eine Dame steht (Zeile 3),
\item in jeder aufsteigenden Diagonale h\"{o}chstens eine Dame steht (Zeile 4) und
\item in jeder Spalte mindestens eine Dame steht (Zeile 5).
\end{enumerate}
Die Ausdr\"{u}cke in den einzelnen Zeilen liefern Mengen, deren Elemente
Klausel-Mengen sind.  Was wir als Ergebnis brauchen ist aber eine Klausel-Menge
und keine Menge von Klausel-Mengen.  Daher bilden wir mit dem Operator ``\texttt{+/}''
die Vereinigung dieser Mengen.

\begin{figure}[!ht]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm
                ]
    allClauses := procedure(n) {
        return   +/ { atMostOneInRow(row, n)         : row in {1..n}        }
               + +/ { atMostOneInLowerDiagonal(k, n) : k in {-(n-2) .. n-2} }
               + +/ { atMostOneInUpperDiagonal(k, n) : k in {3 .. 2*n - 1}  }
               + +/ { oneInColumn(column, n)         : column in {1 .. n}   };
    };
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{Die Prozedur \texttt{allClauses}.}
  \label{fig:allClauses}
\end{figure}

Als letztes zeigen wir in Abbildung \ref{fig:davisPutnam:solve} die Prozedur
\texttt{solve}, mit der wir das 8-Damen-Problem l\"{o}sen k\"{o}nnen.
Hierbei ist $\texttt{printBoard}()$ eine Prozedur, welche die L\"{o}sung in lesbarere Form als Schachbrett
ausdruckt.  Das funktioniert allerdings nur, wenn ein Font verwendet wird, bei dem alle Zeichen die
selbe Breite haben.  Diese Prozedur ist der Vollst\"{a}ndigkeit halber in Abbildung \ref{fig:printBoard}
gezeigt, wir wollen die Implementierung aber nicht weiter diskutieren.
Das vollst\"{a}ndige Programm finden Sie auf meiner Webseite unter dem Namen
\href{https://github.com/karlstroetmann/Logik/blob/master/SetlX/queens.stlx}{\texttt{queens.stlx}}.


\begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  firstnumber   = 1,
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm,
                ]
    solve := procedure(n) {
        clauses  := allClauses(n);
        solution := davisPutnam(clauses, {});
        if (solution != { {} }) {
            printBoard(solution, n);
        } else {
            print("The problem is not solvable for " + n + " queens!");
            print("Try to increase the number of queens.");
        }
    };
\end{Verbatim}
\vspace*{-0.3cm}
\caption{Die Prozedur \texttt{solve}.}
\label{fig:davisPutnam:solve}
\end{figure}


\begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm,
                ]
    printBoard := procedure(i, n) {
        if (i == { {} }) {
            return;
        }
        print( "        " + ((8*n+1) * "-") );
        for (row in [1..n]) {
            line := "        |";
            for (col in [1..n]) {
                line += "       |";
            }
            print(line);
            line := "        |";
            for (col in [1..n]) {
                if ({ Var(row, col) } in i) {
                    line += "   Q   |";
                } else {
                    line += "       |";
                }
            }
            print(line);
            line := "        |";
            for (col in [1..n]) {
                line += "       |";
            }
            print(line);
            print( "        " + ((8*n+1) * "-") );
        }
    };
\end{Verbatim}
\vspace*{-0.3cm}
\caption{Die Prozedur $\texttt{printBoard}()$.}
\label{fig:printBoard}
\end{figure}



 Die durch den Aufruf $\mathtt{davisPutnam}(\textsl{clauses}, \{\})$ 
berechnete Menge \texttt{solution} enth\"{a}lt f\"{u}r jede der Variablen $\mathtt{Var}(i,j)$
entweder die Unit-Klausel $\{\mathtt{Var}(i,j)\}$  (falls auf diesem Feld eine Dame steht) oder
aber die Unit-Klausel  $\{ \mathtt{!Var}(i,j)\}$ (falls das Feld leer bleibt).
Eine graphische Darstellung des durch die berechnete Belegung dargestellten Schach-Bretts
sehen Sie in Abbildung \ref{fig:queens-solution}. 

\begin{figure}[!ht]
  \centering
\hspace*{0.0cm}
\vbox{\offinterlineskip
   \hrule height1pt
   \hbox{\vrule width1pt\bigchess
         \vbox{\hbox{0Z0L0Z0Z}
               \hbox{Z0Z0Z0ZQ}
               \hbox{QZ0Z0Z0Z}
               \hbox{Z0L0Z0Z0}
               \hbox{0Z0Z0L0Z}
               \hbox{ZQZ0Z0Z0}
               \hbox{0Z0Z0ZQZ}
               \hbox{Z0Z0L0Z0}}%
         \vrule width1pt}
   \hrule height1pt}

  \caption{Eine L\"{o}sung des 8-Damen-Problems.}
  \label{fig:queens-solution}
\end{figure}


Das 8-Damen-Problem ist nat\"{u}rlich nur eine spielerische Anwendung der Aussagen-Logik.
Trotzdem zeigt es die Leistungsf\"{a}higkeit des Algorithmus von Davis
und Putnam sehr gut, denn die Menge der Klauseln, die von der Prozedur \texttt{allClauses}
berechnet wird, f\"{u}llt unformatiert f\"{u}nf Bildschirm-Seiten, falls diese  eine Breite von 80
Zeichen haben.  In dieser Klausel-Menge kommen 64 verschiedene Variablen vor.
Der Algorithmus von Davis und Putnam ben\"{o}tigt zur Berechnung einer Belegung, die diese
Klauseln erf\"{u}llt, auf meinem iMac weniger als f\"{u}nf Sekunden.

In der Praxis gibt es viele Probleme, die sich in ganz \"{a}hnlicher Weise auf die L\"{o}sung einer
Menge von Klauseln zur\"{u}ckf\"{u}hren lassen.  Dazu geh\"{o}rt zum Beispiel das Problem, einen
Stundenplan zu erstellen, der gewissen Nebenbedingungen gen\"{u}gt.  Verallgemeinerungen des
Stundenplan-Problems werden in der Literatur als \emph{Scheduling-Problemen} bezeichnet.
Die effiziente L\"{o}sung solcher Probleme ist Gegenstand der aktuellen Forschung.


%\input{compact-barwise}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "logik"
%%% End: 
